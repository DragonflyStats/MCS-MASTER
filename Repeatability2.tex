\subsection{Repeatability coefficient}
\citet{BA99} introduces the repeatability coefficient for a method, which is defined as the upper limits of a prediction interval for the absolute difference between two measurements by the same
method on the same item under identical circumstances \citep{BXC2008}.

$\sigma^2_{x}$ is the within-subject variance of method $x$. The repeatability coefficient is $2.77 \sigma_{x}$ (i.e. $1.96 \times \sqrt{2} \sigma_{x}$). For $95\%$ of subjects, two replicated measurement by the same method will be within this repeatability coefficient.

\newpage
\section{Repeatability}
\subsection{Repeatability and gold standards}
Currently the phrase `gold standard' describes the most accurate method of measurement available. No other criteria are set out. Further to \citet{dunnSEME}, various gold standards have a varying levels of repeatability. Dunn cites the example of the sphygmomanometer, which is prone to measurement error. Consequently it can be said that a measurement method can be the `gold standard', yet have poor repeatability. Some authors, such as [cite] and [cite] have recognized this problem. Hence, if the most accurate method is considered to have poor repeatability, it is referred to as a 'bronze standard'.  Again, no formal definition of a 'bronze standard' exists.

The coefficient of repeatability may provide the basis of formulation a formal definition of a `gold standard'. For example, by determining the ratio of $CR$ to the sample mean $\bar{X}$. Further to [Lin], it is preferable to have a sample size specified in advance. A gold standard may be defined as the method with the lowest value of $\lambda = CR /\bar{X}$ with $\lambda < 0.1\%$. Similarly, a silver standard may be defined as the method with the lowest value of $\lambda $ with $0.1\% \leq \lambda < 1\%$. Such thresholds are solely for expository purposes.

\section{Repeatability}
A measurement method can be said to have a good level of repeatability if there is consistency in repeated measurements on the same subject using that method. Conversely, a method has poor repeatability if there is considerable variation in repeated measurements.

This is relevant to method comparison studies because the `repeatabilities' of the two methods of measurement affects the level of agreement of those methods. Poor repeatability in one method would result in poor agreement. More so if there is poor repeatability in both methods.

\subsection{Relevance of Repeatability} Repeatability of two method limit the amount of agreement that is possible.If one method has poor repeatability, the agreement is bound to be poor. If both methods have poor repeatability, agreement is even worse.

The British standards Insitute [$1979$] define a coefficient of
repeatability  as \emph{the value below which the difference
between two single test results....may be expected to lie within a
specified probability.} Unless otherwise instructed, the
probability is assumed to be $95\%$.

The Bland Altman method offers the analyst a measurement on the repeatability of the methods. The \emph{Coefficient of Repeatability} (CR) can be calculated as 1.96 (or 2) times the standard deviations of the differences between the two measurements (d2 and d1).


\citet{BA99} strongly recommends the simultaneous estimation of repeatability and agreement be collecting replicated data. \citet{ARoy2009} notes the lack of convenience in such calculations.


If one method has poor repeatability in the sense of considerable variability, then agreement between two methods is bound to be poor \citep{ARoy2009}.

It is important to report repeatability when assessing measurement, because it measures the purest form of random error not influenced by other factors \citep{Barnhart}.
