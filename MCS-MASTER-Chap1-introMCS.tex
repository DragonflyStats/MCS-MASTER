
\documentclass[12pt, a4paper]{report}
\usepackage{epsfig}
\usepackage{subfigure}
%\usepackage{amscd}
\usepackage{amssymb}
\usepackage{graphicx}
%\usepackage{amscd}
\usepackage{amssymb}
\usepackage{subfiles}
\usepackage{framed}
\usepackage{subfiles}
\usepackage{amsthm, amsmath}
\usepackage{amsbsy}
\usepackage{framed}
\usepackage[usenames]{color}
\usepackage{listings}
\lstset{% general command to set parameter(s)
	basicstyle=\small, % print whole listing small
	keywordstyle=\color{red}\itshape,
	% underlined bold black keywords
	commentstyle=\color{blue}, % white comments
	stringstyle=\ttfamily, % typewriter type for strings
	showstringspaces=false,
	numbers=left, numberstyle=\tiny, stepnumber=1, numbersep=5pt, %
	frame=shadowbox,
	rulesepcolor=\color{black},
	,columns=fullflexible
} %
%\usepackage[dvips]{graphicx}
\usepackage{natbib}
\bibliographystyle{chicago}
\usepackage{vmargin}
% left top textwidth textheight headheight
% headsep footheight footskip
\setmargins{3.0cm}{2.5cm}{15.5 cm}{22cm}{0.5cm}{0cm}{1cm}{1cm}
\renewcommand{\baselinestretch}{1.5}
\pagenumbering{arabic}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{ill}[theorem]{Example}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{axiom}{Axiom}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{notation}{Notation}
\theoremstyle{remark}
\newtheorem{remark}{Remark}[section]
\newtheorem{example}{Example}[section]
\renewcommand{\thenotation}{}
\renewcommand{\thetable}{\thesection.\arabic{table}}
\renewcommand{\thefigure}{\thesection.\arabic{figure}}
\title{Research notes: linear mixed effects models}
\author{ } \date{ }


\begin{document}
	\author{Kevin O'Brien}
	\title{Mixed Models for Method Comparison Studies}
	\tableofcontents
	
	%----------------------------------------------------------------------------------------%
\newpage
\chapter{Method Comparison Studies}
	
\section{What is a method comparison study?}


The question of properly assessing ``agreement" between two or more methods of measurement is ubiquitous, and is commonly referred to as a `method comparison study'. Published examples of method comparison studies can be found in disciplines
as diverse as pharmacology \citep{ludbrook97}, anaesthesia \citep{Myles}, and cardiac imaging methods \citep{Krumm}.
	
Historically comparison of two methods of measurement was carried out by use of paired sample $t-$test, correlation coefficients or simple bivariate methods. Statisticians Martin Bland and Douglas Altman recognized the inadequacies of these approaches for comparing two methods of measurement, and proposed their own framework with this application in mind \citep{BA83,BA86}. Although the authors acknowledge the opportunity to apply other, more complex approaches, they argue that simpler approaches are preferable, especially when the results must be `explained to non-statisticians'.

% The approach proposed by Roy deals with the question of agreement, and indeed interchangeability, as developed by Bland and Altman's corpus of work.

A method of measurement should ideally be both accurate and
precise. The precision of a method is indicated by how tightly measurements obtained under identical conditions are distributed
around their mean measurement value. A precise and accurate method
will yield results consistently close to the true value. Of course
a method may be accurate, but not precise, if the average of its
measurements is close to the true value, but those measurements
are highly dispersed. Conversely a method that is not accurate may
be quite precise, as it consistently indicates the same level of
inaccuracy. The tendency of a method of measurement to
consistently give results above or below the true value is a
source of systematic bias. The smaller the systematic bias, the
greater the accuracy of the method. \citet{Barnhart} describes agreement as being a broader
term that contains both of those qualities. An accurate
measurement method will give results close to the unknown `true
value'.

% The FDA define precision as the closeness of agreement (degree of
% scatter) between a series of measurements obtained from multiple
% sampling of the same homogeneous sample under prescribed
% conditions. \citet{Barnhart} describes precision as being further
% subdivided as either within-run, intra-batch precision or
% repeatability (which assesses precision during a single analytical
% run), or between-run, inter-batch precision or repeatability
%(which measures precision over time).

In the context of the agreement of two methods, there is also a
tendency of one measurement method to consistently give results
above or below the other method. Lack of agreement is a
consequence of the existence of `inter-method bias'. For two
methods to be considered in good agreement, the inter-method bias
should be in the region of zero.

	\subsection{Purpose of Method Comparison Studies}
	Different authors focus on different aspects of comparison problem. \citet{BXC2010} provides a review of many descriptions of the purpose of method comparison studies, several of which are reproduced here.
	
\begin{itemize}
%\item 		``The question being answered is not always clear, but is usually epxressed as an attempt to quantify the agreement
%		between two methods" \citep{BA95}.
		
\item	``Some lack of agreement between different methods of measurement is inevitable. What matters is the amount by which they disagree. We want to know by how much the new method is likely to differ from the old, so that it is not enough to cause problems in the mathematical interpretation we can preplace the old method by the new, or even use the two interchangeably" \citep{BA99}.
		
		
\item ``It often happens that the same physical and chemical property can be measured in different ways. For example, one can determine For example, one can determine sodium in serum by flame atomic emission spectroscopy or by isotope dilution mass spectroscopy. The question arises as to which method is better" (Mandel, 1991).
		
%		``In areas of inter-laboratory quality control, method comparisons, assay validations and individual bio-equivalence, etc, the agreement between observations and target (reference) values is
%		of interest" \citep{lin2002}.
		
\item 	``The purpose of comparing two methods of measurement of a continuous biological variable is to uncover systematic differences, not to point to
		similarities`" \citep{ludbrook97}.
		
\item 	``In the pharmaceutical industry, measurement methods that measure the quantity of prdocuts are regulated. The FDA (U.S. Food and Drug Administration) requires that the manufacturer show equivalency prior to approving the new or alternatice method in quality control" (Tan \& Inglewicz, 1999). 
%citep{tan1999}
\end{itemize}
	
While several major commonalities are present in each definitions, there is a different emphasis for each, which will inevitably give rise to confusion. In the view of \citet{DunnSEME}, a question relevant to many practitioners is which of the two methods is more precise. \citet{BXC2010} seems to endorse a simple phrasing of the research question that is proposed by \citet{BA83}, i.e. ``\textit{do the two methods of measurement agree sufficiently closely?}" with \citet{BXC2010} expressing the view that other considerations (for example, the ``equivalence" of two methods) to be treated as separate research questions. As such, we will focus on on agreement and repeatability of methods, reverting later to other research questions such as ``equivalence of methods".
	
In many cases the purpose of the study is to calibrate a new method of measurement against a ``Gold Standard"â€™ method, a known method that is considered most precise in its measurement. For example, in medicine, new methods or devices that are cheaper, easier to use, or less invasive, are routinely developed. Agreement between a new method and either a traditional reference or gold standard must be evaluated before the new one is put into practice. Various approaches have been proposed for this purpose in recent years. It must be noted that absence of measurement error should not be assumed for gold standard methods.
	
	
\subsection{Grubbs' Artillery Round Data}	

	To illustrate the characteristics of a typical method comparison
	study consider the data in Table 1.1 \citep{Grubbs73}. In each of
	twelve experimental trials, a single round of ammunition was fired
	from a 155mm artillery piece and its velocity was measured simultaneously (and
	independently) by three chronographs devices, identified here by
	the labels `Fotobalk', `Counter' and `Terma'.
	\smallskip
	\begin{table}[ht]
		\begin{center}
			\begin{tabular}{|c|c|c|c|}
				\hline
				Round& Fotobalk [F] & Counter [C]& Terma [T]\\
				\hline
				1 & 793.8 & 794.6 & 793.2 \\
				2 & 793.1 & 793.9 & 793.3 \\
				3 & 792.4 & 793.2 & 792.6 \\
				4 & 794.0 & 794.0 & 793.8 \\
				5 & 791.4 & 792.2 & 791.6 \\
				6 & 792.4 & 793.1 & 791.6 \\
				7 & 791.7 & 792.4 & 791.6 \\
				8 & 792.3 & 792.8 & 792.4 \\
				9 & 789.6 & 790.2 & 788.5 \\
				10 & 794.4 & 795.0 & 794.7 \\
				11 & 790.9 & 791.6 & 791.3 \\
				12 & 793.5 & 793.8 & 793.5 \\
			\phantom{makespace} & \phantom{makespace} & \phantom{makespace} & \phantom{makespace} \\ \hline 
			\end{tabular}
			\caption{Velocity measurement from the three chronographs (Grubbs
				1973).}
		\end{center}
		\label{FCTdata}
	\end{table}
	
	An important aspect of the these data is that all three methods of
	measurement are assumed to have an attended measurement error, and
	the velocities reported in Table 1.1 can not be assumed to be
	`true values' in any absolute sense.
	
	%While lack of
	%agreement between two methods is inevitable, the question , as
	%posed by \citet{BA83}, is 'do the two methods of measurement agree
	%sufficiently closely?'
	 A simple estimate of the
	inter-method bias is given by the differences between pairs of measurements, for example, in Table 1.2 shows possible inter-method bias; the `Fotobalk' consistently recording
	smaller velocities than the `Counter' method. 
	
	The absence of inter-method bias is, by itself, not sufficient to
	establish that two measurement methods agree. The two methods
	must also have equivalent levels of precision. Should one method
	yield results considerably more variable than those of the other,
	they can not be considered to be in agreement. 
	Hence, method comparison studies are required to take account of both inter-method bias and difference in the precision of measurements.
	% latex table generated in R 2.6.0 by xtable 1.5-5 package
	% Wed Aug 26 15:22:41 2009
	\begin{table}[h!]
		
		\begin{center}
			\phantom{MAKESPACE}
			\begin{tabular}{cccc}
				\hline
				Round & Fotobalk (F) & Counter (C) & Difference (F-C) \\
				\hline
				1 & 793.8& 794.6 & -0.8 \\
				2 & 793.1 & 793.9 & -0.8 \\
				3 & 792.4 & 793.2 & -0.8 \\
				4 & 794.0 & 794.0 & 0.0 \\
				5 & 791.4 & 792.2 & -0.8 \\
				6 & 792.4 & 793.1 & -0.7 \\
				7 & 791.7 & 792.4 & -0.7 \\
				8 & 792.3 & 792.8 & -0.5 \\
				9 & 789.6 & 790.2 & -0.6 \\
				10 & 794.4 & 795.0 & -0.6 \\
				11 & 790.9 & 791.6 & -0.7 \\
				12 & 793.5 & 793.8 & -0.3 \\
				\phantom{MAKESPACE} & \phantom{MAKESPACE} &\phantom{MAKESPACE} & \phantom{MAKESP}\\
			\end{tabular}
			\caption{Difference between Fotobalk and Counter measurements.}
		\end{center}
	\end{table}
	
	
	
	%=============================================================== %
	
	%While lack of
	%agreement between two methods is inevitable, the question , as
	%posed by \citet{BA83}, is 'do the two methods of measurement agree
	%sufficiently closely?'
	
	
	
	% The FDA define precision as the closeness of agreement (degree of
	% scatter) between a series of measurements obtained from multiple
	% sampling of the same homogeneous sample under prescribed
	% conditions. \citet{Barnhart} describes precision as being further
	% subdivided as either within-run, intra-batch precision or
	% repeatability (which assesses precision during a single analytical
	% run), or between-run, inter-batch precision or repeatability
	%(which measures precision over time).
\subsection{Agreement}
	% % - WHERE IS THIS COMING FROM?
\citet{BA86} defined perfect agreement as the case where all of the pairs of measurement data, when plotted on a conventional scatter-plot, lie along the line of equality, where the line of equality is defined as the 45 degree line passing through the origin, (i.e. the line $X=Y$ on the Cartesian plane). 
	
%	To carry their idea a step further, we define a specific numerical measure of agreement as twice the expected squared perpendicular distance of the pair of random variables ($X_1$, $X_2$) to the line of equality or agreement in the $(X_1,X_2)$-plane, that is, $E(X_1 - X_2)/2$, where $X_1$ and $X_2$ denote the continuous measurements of method 1 and method 2, respectively. Obviously, other $L_p$ norms may be considered for the purpose of numerically measuring agreement and warrant future consideration. 
	
	%Note that we will use the term rater and measuring device interchangeably throughout this article.
	
Agreement is the extent to which the measure of the variable of interest, under a constant set of experimental conditions, yields the same result on repeated trials \citep{sanchez1999}. The more consistent the results, the more reliable the measuring procedure.
	
	
\citet{BA83} define bias (referred to hereafter as inter-method bias) as a \emph{a consistent tendency for one method to exceed the other} and propose estimating its value by determining the mean of the case-wise differences. The variation about this mean shall be estimated by the  standard deviation of the case-wise differences. Bland and Altman remark that these estimates are based on the assumption that bias and variability are constant throughout the range of measures.
	%----------------------------------------------------------------------------%
	
	
	
	
	
	

	\section{The Identity Plot}
	\citet{BA83} states that regression analysis can offer useful insights, and recommending an `Identity Plot', a simple graphical approach that yields a cursory examination of how well the measurement methods agree. In the case of good agreement, the co-variates of the Identity plot accord closely with the $X=Y$ line. This plot is not useful for a thorough examination of the data. \citet{BritHypSoc} notes that data points will tend to cluster around the line of equality,
	obscuring interpretation. An identity plot shall complement demonstrations of commonly used approaches in the next chapter.
	
	
	\subsubsection*{Decomposition of Inter-Method Bias}
Regression approaches are useful for a making a detailed examination of the biases across the range of measurements, allowing inter-method bias to be decomposed into constant bias and proportional bias. Regression methods can determine the presence of inter-method bias, and the levels of constant bias and proportional bias thereof \cite{ludbrook97,ludbrook02}. 

Constant bias describes the case where one method gives values that are consistently different to the other across the whole range. Using a naive estimation of bias, such as the mean of differences, it may incorrectly indicate absence of bias, by yielding a mean difference close to zero. This would be caused by positive differences in the measurements at one end of the range of measurements being canceled out by negative differences at the other end of the scale. Proportional Bias exists when two methods agree on average, but exhibit differences over a range of measurements, i.e. the differences are proportional to the scale of the measurement.	A measurement method may be subject to any combination of fixed bias or proportional bias, or both \citep{ludbrook02}. 
	
	Constant or proportional bias using linear regression can be detected by an individual test on the intercept or the slope of the line regressed from the results of the two methods to be compared. If there is no constant bias, the intercept is equal to zero and, similarly, if there is no proportional bias, the slope is equal to one. Thus, carrying out hypothesis tests on these coefficients (where the null hypotheses are $\beta_0=0$ and $\beta_1=1$) allow us to test for the presence of both types of bias.

	
		If the basic assumptions underlying linear regression are not met, the regression equation, and consequently the estimations of bias are undermined. 
%Outliers are a source of error in regression estimates.
		

	\section{Replicate Measurements and Repeatability}
Thus far, the formulation for comparison of two measurement
methods is one where one measurement by each method is taken on
each subject. Repeated measurements on several subjects can be used to quantify measurement error; the variation between measurements of the same quantity on the same individual. Measurements taken in quick succession, so that no real systemic changes can take place on each item,  by the same observer using the same instrument on the same item can be considered true replicates \citep{BA99}. \citet{ARoy2009} accords with Bland and Altman's definition, but notes that some measurements may not be `true' replicates.
 \citet{BXC2008} recommends the use of replicate measurements, but acknowledges the additional computational complexity posed by replicate measurements . \citet*{BA86} address the additional complexity by offering two different approaches. The premise of the first approach is that replicate measurements can be treated as independent measurements. The second approach is based upon using the mean of the each group of
		replicates as a representative value of that group. Using either of these approaches will allow an analyst to properly estimate the inter-method bias. However, \citet{BXC2008} is critical of both approaches, offering an alternative approach that shall be introduced later.
		
\citet{BA99} also remark that an important feature of replicate observations is that they should be independent
of each other. This issue is addressed by \citet{BXC2010}, in terms of exchangeability and linkage. Carstenen advises that repeated measurements come in two \emph{substantially different} forms, depending on the circumstances of their measurement: exchangable and linked.
		
%		
%		
%	 If the paired measurements are taken in a short period of time , they can be considered true replicates.
%	
%	Further to \citet{BA99}, a formal definition is required of what exactly replicate measurements are
	
%	\emph{By replicates we mean two or more measurements on the same
%		individual taken in identical conditions. In general this requirement means that the
%		measurements are taken in quick succession.}
%	
%	Roy accords with Bland and Altman's definition of a replicate, as being two or more measurements on the same individual under identical conditions. 
% Roy allows the assumption that replicated measurements are equi-correlated. 
% Roy allows unequal numbers of replicates.
	
%	Replicate measurements are linked over time. However the method can be easily extended to cover situations where they are not linked over time.
%	
%	 Should enough time elapse for systemic changes, linked repeated measurements can not be treated as true replicates. Should there be two or more measurements by each
%	methods, these measurement are known as `replicate measurements'.
%	

	
	%\subsection{Mean of Replicates Limits of Agreement}
	
%	However, because of the removal of the effects of the replicate
%	measurements error, this would cause the estimation of the
%	standard deviation of the differences to be unduly small.
%	\citet*{BA86} propose a correction for this.
	
%
%	
%	Bland and Altman attend to the issue of repeated measures in
%	$1996$.
%
%	
%	Bland and Altman discuss two metrics for measurement error; the 	within-subject standard deviation, and the correlation
%	coefficient.
%	
%	The above plot incorporates both the conventional limits of agreement (the inner pair of dashed lines), the `$t-$' limits of
%	agreement (the outer pair of dashed lines) centred around the inter-method bias (indicated by the full line). This plot is
%	intended for expository purposes only, as the sample size is small.
%
%	
%
%
%	
%
%	
%	
%	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	
%	In this model, the variances of the random effects must depend on
%	$m$, since the different methods do not necessarily measure on the 	same scale, and different methods naturally must be assumed to have different variances. \citet{BXC2004} attends to the issue of comparative variances.
%	
%	
%	
%	
%	
%
%	
%	Roy's approach assumes the use of `true replicates'. However data may not be collected in this way. In such cases, the correlation matrix on the replicates may require a different structure, such as the autoregressive order one $AR(1)$ structure. However determining MLEs with such a structure would be computational intense, if possible at all.
%	
%	\emph{
%		One important feature of replicate observations is that they should be independent
%		of each other. In essence, this is achieved by ensuring that the observer makes each
%		measurement independent of knowledge of the previous value(s). This may be difficult
%		to achieve in practice} \citep{BA99}.

	\subsection{Exchangeable and Linked measurements}
	
	Repeated measurements are said to be linked if a direct correspondence exists between successive measurements across measurements, i.e. pairing. Such measurements are commonly made with a time interval between them, but simultaneously for both methods. Paired measurements are exchangeable, but individual measurements are not.
	
	Repeated measurements are said to be exchangeable if no relationship exists between successive measurements across measurements. If the condition of exchangeability exists, a group of measurement of the same item determined by the same method can be re-arranged in any permutation without prejudice to proper analysis. There is no reason to believe that the true value of the underlying variable has changed over the course of the measurements.
	
	Exchangeable repeated measurements can be treated as true replicates. For the purposes of method comparison studies the following remarks can be made. The $r-$th measurement made by method $1$ has no special correspondence to the $r-$th measurement made by method $2$, and consequently any pairing of repeated measurements are as good as each other.
	
	

	
		
	
	
	
	
	

	
	
	
	\section{Repeatability}
%-- Definition of Repeatability
	Repeatability describes the variation in measurements taken by a single method of measurement on the same item and under the same conditions. A measurement method can be said to have a good level of repeatability if there is consistency in repeated measurements on the same subject using that method. Conversely, a method has poor repeatability if there is considerable variation in repeated measurements.
		
		Repeatability is defined by the \citet{IUPAC} as `\textit{the closeness of agreement between independent results obtained with the same method on identical test material, under the same conditions (same
			operator, same apparatus, same laboratory and after short intervals of time)}'  and is determined by taking multiple measurements on a series of subjects.	A similar set of criteria is described in the \textit{Guidelines for Evaluating and Expressing the Uncertainty of NIST Measurement Results}.
%		 the following conditions need to be fulfilled in the establishment of repeatability:
%		\begin{itemize}
%			\item	the same measurement procedure
%			\item	the same observer
%			\item	the same measuring instrument, used under the same conditions
%			\item	the same location
%			\item	repetition over a short period of time.
%			\item  same objectives
%		\end{itemize}
%		
		% %	Test-retest variability is practically used, for example, in medical monitoring of conditions.

%-Importance in MCS-----------------------------------------%


\citet{Barnhart} emphasizes the importance of repeatability as part of an overall method comparison study, a view endorsed by \citet{BXC2008}. The repeatability of two methods influence the amount of agreement which is possible between those methods. Before there can be good agreement between two methods, a method must have good agreement with itself. If one method has poor repeatability in the sense of considerable variability, then agreement between two methods is bound to be poor \citep{BA99, ARoy2009}.
\citet{BA99} strongly recommends the simultaneous estimation of repeatability and agreement be collecting replicated data.
However \citet{ARoy2009} notes the lack of convenience in such calculations. 

% 
% \citet{Barnhart} and \citet{ARoy2009} highlight the importance of % reporting repeatability in method comparison, because it measures % the purest random error not influenced by any external factors. 

	
%-REPORTING-----------------------------------------%

	\citet{Barnhart} remarks that it is important to report repeatability when assessing
	measurement, because it measures the purest form of random error
	not influenced by other factors, while further remarking `\textit{curiously replicate measurements are rarely made in method comparison studies, so that an important aspect of comparability is often overlooked}. 
	
	
		
Statistical procedures on within-item variances of two methods are equivalent to tests on their respective repeatability coefficients. A formal test is introduced by \citet{ARoy2009}, which will discussed in chapter three.
		
%============================================ %
	
	If replicate measurements by a method are available, it is simple to estimate the measurement error for a method, using a model with fixed effects for item, then taking the residual standard deviation as measurement error standard deviation. However, if replicates are linked, this may produce an estimate that biased upwards.
	

	

	\section{Outline of Thesis}
	Thus, the basic concepts of, and need for method comparison are introduced. The intention of this thesis is to develop the theory of method comparison studies using Linear Mixed Effects models. Chapter two will provide a review of the prevalent methods, highlighting particular flaws where relevant. Chapter three shall describe Linear Mixed effects models, and how the use of the linear mixed
	effects models can be extended to method comparison studies. Implementations of important existing work is presented using the \texttt{R} programming language.
	
		
	Chapter three shall describe linear mixed effects models, and how the use of the linear mixed effects models have so far extended to method comparison studies. Implementations of important existing work shall be presented again, using the \texttt{R} programming language.
	
	Model diagnostics are an integral component of a complete statistical analysis.
	In chapter four model diagnostics are described in depth, with particular
	emphasis on linear mixed effects models.
	
	In the fifth chapter, important linear mixed effects model diagnostic methods shall be extended to method comparison studies, and proposed methods are demonstrated on data sets that have become well known in literature on method comparison. The purpose is to both calibrate these methods and to demonstrate applications for them.
	The last chapter deals with robust measures of important parameters such as agreement.
	
	\bibliographystyle{chicago}
	\bibliography{2017bib}
\end{document}
