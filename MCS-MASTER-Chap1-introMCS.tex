
\documentclass[12pt, a4paper]{report}
\usepackage{epsfig}
\usepackage{subfigure}
%\usepackage{amscd}
\usepackage{amssymb}
\usepackage{graphicx}
%\usepackage{amscd}
\usepackage{amssymb}
\usepackage{subfiles}
\usepackage{framed}
\usepackage{subfiles}
\usepackage{amsthm, amsmath}
\usepackage{amsbsy}
\usepackage{framed}
\usepackage[usenames]{color}
\usepackage{listings}
\lstset{% general command to set parameter(s)
	basicstyle=\small, % print whole listing small
	keywordstyle=\color{red}\itshape,
	% underlined bold black keywords
	commentstyle=\color{blue}, % white comments
	stringstyle=\ttfamily, % typewriter type for strings
	showstringspaces=false,
	numbers=left, numberstyle=\tiny, stepnumber=1, numbersep=5pt, %
	frame=shadowbox,
	rulesepcolor=\color{black},
	,columns=fullflexible
} %
%\usepackage[dvips]{graphicx}
\usepackage{natbib}
\bibliographystyle{chicago}
\usepackage{vmargin}
% left top textwidth textheight headheight
% headsep footheight footskip
\setmargins{3.0cm}{2.5cm}{15.5 cm}{22cm}{0.5cm}{0cm}{1cm}{1cm}
\renewcommand{\baselinestretch}{1.5}
\pagenumbering{arabic}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{ill}[theorem]{Example}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{axiom}{Axiom}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{notation}{Notation}
\theoremstyle{remark}
\newtheorem{remark}{Remark}[section]
\newtheorem{example}{Example}[section]
\renewcommand{\thenotation}{}
\renewcommand{\thetable}{\thesection.\arabic{table}}
\renewcommand{\thefigure}{\thesection.\arabic{figure}}
\title{Research notes: linear mixed effects models}
\author{ } \date{ }


\begin{document}
	\author{Kevin O'Brien}
	\title{Mixed Models for Method Comparison Studies}
	\tableofcontents
	
	%----------------------------------------------------------------------------------------%
	\newpage
	\chapter{Method Comparison Studies}

	

	\section{Introduction}
	The problem of assessing the agreement between two or more methods
	of measurement is ubiquitous in scientific research, and is
	commonly referred to as a `method comparison study'. Published
	examples of method comparison studies can be found in disciplines
	as diverse as pharmacology \citep{ludbrook97}, anaesthesia
	\citep{Myles}, and cardiac imaging methods \citep{Krumm}.
	\smallskip
	
	To illustrate the characteristics of a typical method comparison
	study consider the data in Table I \citep{Grubbs73}. In each of
	twelve experimental trials, a single round of ammunition was fired
	from a 155mm gun and its velocity was measured simultaneously (and
	independently) by three chronographs devices, identified here by
	the labels `Fotobalk', `Counter' and `Terma'.
	\smallskip
	
	
	\newpage
	
	\begin{table}[ht]
		\begin{center}
			\begin{tabular}{rrrr}
				\hline
				Round& Fotobalk [F] & Counter [C]& Terma [T]\\
				\hline
				1 & 793.8 & 794.6 & 793.2 \\
				2 & 793.1 & 793.9 & 793.3 \\
				3 & 792.4 & 793.2 & 792.6 \\
				4 & 794.0 & 794.0 & 793.8 \\
				5 & 791.4 & 792.2 & 791.6 \\
				6 & 792.4 & 793.1 & 791.6 \\
				7 & 791.7 & 792.4 & 791.6 \\
				8 & 792.3 & 792.8 & 792.4 \\
				9 & 789.6 & 790.2 & 788.5 \\
				10 & 794.4 & 795.0 & 794.7 \\
				11 & 790.9 & 791.6 & 791.3 \\
				12 & 793.5 & 793.8 & 793.5 \\
				\hline
			\end{tabular}
			\caption{Velocity measurement from the three chronographs (Grubbs
				1973).}
		\end{center}
	\end{table}
	
	An important aspect of the these data is that all three methods of
	measurement are assumed to have an attended measurement error, and
	the velocities reported in Table 1.1 can not be assumed to be
	`true values' in any absolute sense.
	
	%While lack of
	%agreement between two methods is inevitable, the question , as
	%posed by \citet{BA83}, is 'do the two methods of measurement agree
	%sufficiently closely?'
	
	A method of measurement should ideally be both accurate and
	precise. \citet{Barnhart} describes agreement as being a broader
	term that contains both of those qualities. An accurate
	measurement method will give results close to the unknown `true
	value'. The precision of a method is indicated by how tightly
	measurements obtained under identical conditions are distributed
	around their mean measurement value. A precise and accurate method
	will yield results consistently close to the true value. Of course
	a method may be accurate, but not precise, if the average of its
	measurements is close to the true value, but those measurements
	are highly dispersed. Conversely a method that is not accurate may
	be quite precise, as it consistently indicates the same level of
	inaccuracy. The tendency of a method of measurement to
	consistently give results above or below the true value is a
	source of systematic bias. The smaller the systematic bias, the
	greater the accuracy of the method.
	
	% The FDA define precision as the closeness of agreement (degree of
	% scatter) between a series of measurements obtained from multiple
	% sampling of the same homogeneous sample under prescribed
	% conditions. \citet{Barnhart} describes precision as being further
	% subdivided as either within-run, intra-batch precision or
	% repeatability (which assesses precision during a single analytical
	% run), or between-run, inter-batch precision or repeatability
	%(which measures precision over time).
	
	In the context of the agreement of two methods, there is also a
	tendency of one measurement method to consistently give results
	above or below the other method. Lack of agreement is a
	consequence of the existence of `inter-method bias'. For two
	methods to be considered in good agreement, the inter-method bias
	should be in the region of zero. A simple estimation of the
	inter-method bias can be calculated using the differences of the
	paired measurements. The data in Table 1.2 are a good example of
	possible inter-method bias; the `Fotobalk' consistently recording
	smaller velocities than the `Counter' method. Consequently one
	would conclude that there is lack of agreement between the two
	methods.
	
	The absence of inter-method bias by itself is not sufficient to
	establish whether two measurement methods agree. The two methods
	must also have equivalent levels of precision. Should one method
	yield results considerably more variable than those of the other,
	they can not be considered to be in agreement. With this in mind a
	methodology is required that allows an analyst to estimate the
	inter-method bias, and to compare the precision of both methods of
	measurement.
	\newpage
	% latex table generated in R 2.6.0 by xtable 1.5-5 package
	% Wed Aug 26 15:22:41 2009
	\begin{table}[h!]
		
		\begin{center}
			
			\begin{tabular}{rrrr}
				\hline
				Round& Fotobalk (F) & Counter (C) & F-C \\
				\hline
				1 & 793.8& 794.6 & -0.8 \\
				2 & 793.1 & 793.9 & -0.8 \\
				3 & 792.4 & 793.2 & -0.8 \\
				4 & 794.0 & 794.0 & 0.0 \\
				5 & 791.4 & 792.2 & -0.8 \\
				6 & 792.4 & 793.1 & -0.7 \\
				7 & 791.7 & 792.4 & -0.7 \\
				8 & 792.3 & 792.8 & -0.5 \\
				9 & 789.6 & 790.2 & -0.6 \\
				10 & 794.4 & 795.0 & -0.6 \\
				11 & 790.9 & 791.6 & -0.7 \\
				12 & 793.5 & 793.8 & -0.3 \\
				\hline
			\end{tabular}
			\caption{Difference between Fotobalk and Counter measurements.}
		\end{center}
	\end{table}
	
	\bigskip
	

	
	A precise and accurate method should yield results consistently
	close to the true value. However a method may be accurate, but not
	precise. The average of its measurements is close to the true
	value, but those measurements are highly dispersed. Conversely an
	inaccurate method may be quite precise , as it consistently
	indicates the same level of inaccuracy.
	
	The tendency of a method of measurement to consistently give
	results above or below the true value is a source of systematic
	bias. The lesser the systematic bias, the greater the accuracy of
	the method.
	
	In the context of the agreement of two methods, there is also a
	tendency of one measurement method to consistently give results
	above or below the other method. Lack of agreement is a
	consequence of the existence of `inter-method bias'. For two
	methods to be considered in good agreement, the inter-method bias
	should be in the region of zero.
	
	A simple estimation of the inter-method bias can be calculated
	using the differences of the paired measurements. The data in
	Table 1.2 are a good example of possible inter-method bias; the
	`Fotobalk' consistently recording smaller velocities than the
	`Counter' method. Consequently there is lack of agreement between
	the two methods.
	\newpage
	% latex table generated in R 2.6.0 by xtable 1.5-5 package
	% Wed Aug 26 15:22:41 2009
	\begin{table}[h!]
		\begin{center}
			
			\begin{tabular}{rrrr}
				\hline
				Round& Fotobalk (F) & Counter (C) & F-C \\
				\hline
				1 & 793.80 & 794.60 & -0.80 \\
				2 & 793.10 & 793.90 & -0.80 \\
				3 & 792.40 & 793.20 & -0.80 \\
				4 & 794.00 & 794.00 & 0.00 \\
				5 & 791.40 & 792.20 & -0.80 \\
				6 & 792.40 & 793.10 & -0.70 \\
				7 & 791.70 & 792.40 & -0.70 \\
				8 & 792.30 & 792.80 & -0.50 \\
				9 & 789.60 & 790.20 & -0.60 \\
				10 & 794.40 & 795.00 & -0.60 \\
				11 & 790.90 & 791.60 & -0.70 \\
				12 & 793.50 & 793.80 & -0.30 \\
				\hline
			\end{tabular}
			\caption{Difference between Fotobalk and Counter measurements}
		\end{center}
	\end{table}
	
	\bigskip
	
	\noindent The absence of inter-method bias by itself is not
	sufficient to establish whether two measurement methods agree or
	not. These methods must also have equivalent levels of precision.
	Should one method yield results considerably more variable than
	that of the other, they can not be considered to be in agreement.
	
	Therefore a methodology must be introduced that allows an analyst
	to estimate the inter-method bias, and to compare the precision of
	both methods of measurement.
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\newpage
	\section{What is a method comparison study?}
	
	% Include Somewhere: An assay is a procedure where a property is measured.
	
	The problem of assessing the agreement between two or more methods
	of measurement is ubiquitous in scientific research, and is
	commonly referred to as a `method comparison study'. \citet{ludbrook97} states that the purpose of comparing two measurements "of a continuous biological variable" is to uncover systematic differences, not to point to similarities". The need to compare the results of two different measurement techniques is common in medical statistics. Published
	examples of method comparison studies can be found in disciplines
	as diverse as pharmacology \citep{ludbrook97}, anaesthesia
	\citep{Myles}, and cardiac imaging methods \citep{Krumm}.
	\smallskip
	
	To illustrate the characteristics of a typical method comparison
	study consider the data in Table I \citep{Grubbs73}. In each of
	twelve experimental trials, a single round of ammunition was fired
	from a 155mm gun and its velocity was measured simultaneously (and
	independently) by three chronographs devices, identified here by
	the labels `Fotobalk', `Counter' and `Terma'.
	\smallskip
	
	
	\newpage
	
	\begin{table}[ht]
		\begin{center}
			\begin{tabular}{rrrr}
				\hline
				Round& Fotobalk [F] & Counter [C]& Terma [T]\\
				\hline
				1 & 793.8 & 794.6 & 793.2 \\
				2 & 793.1 & 793.9 & 793.3 \\
				3 & 792.4 & 793.2 & 792.6 \\
				4 & 794.0 & 794.0 & 793.8 \\
				5 & 791.4 & 792.2 & 791.6 \\
				6 & 792.4 & 793.1 & 791.6 \\
				7 & 791.7 & 792.4 & 791.6 \\
				8 & 792.3 & 792.8 & 792.4 \\
				9 & 789.6 & 790.2 & 788.5 \\
				10 & 794.4 & 795.0 & 794.7 \\
				11 & 790.9 & 791.6 & 791.3 \\
				12 & 793.5 & 793.8 & 793.5 \\
				\hline
			\end{tabular}
			\caption{Velocity measurement from the three chronographs (Grubbs
				1973).}
		\end{center}
	\end{table}
	
	An important aspect of the these data is that all three methods of
	measurement are assumed to have an attended measurement error, and
	the velocities reported in Table 1.1 can not be assumed to be
	`true values' in any absolute sense.
	
	%While lack of
	%agreement between two methods is inevitable, the question , as
	%posed by \citet{BA83}, is 'do the two methods of measurement agree
	%sufficiently closely?'
	
	A method of measurement should ideally be both accurate and precise. \citet{Barnhart} describes agreement as being a broader term that contains both of those qualities. An accurate measurement method will give results close to the unknown `true value'. The precision of a method is indicated by how tightly measurements obtained under identical conditions are distributed around their mean measurement value. A precise and accurate method
	will yield results consistently close to the true value. Of course 	a method may be accurate, but not precise, if the average of its measurements is close to the true value, but those measurements
	are highly dispersed. Conversely a method that is not accurate may be quite precise, as it consistently indicates the same level of inaccuracy. The tendency of a method of measurement to consistently give results above or below the true value is a source of systematic bias. The smaller the systematic bias, the
	greater the accuracy of the method.
	
	% The FDA define precision as the closeness of agreement (degree of
	% scatter) between a series of measurements obtained from multiple
	% sampling of the same homogeneous sample under prescribed
	% conditions. \citet{Barnhart} describes precision as being further
	% subdivided as either within-run, intra-batch precision or
	% repeatability (which assesses precision during a single analytical
	% run), or between-run, inter-batch precision or repeatability
	%(which measures precision over time).
	
	In the context of the agreement of two methods, there is also a tendency of one measurement method to consistently give results above or below the other method. Lack of agreement is a consequence of the existence of `inter-method bias'. For two methods to be considered in good agreement, the inter-method bias should be in the region of zero. A simple estimation of the inter-method bias can be calculated using the differences of the
	paired measurements. The data in Table 1.2 are a good example of
	possible inter-method bias; the `Fotobalk' consistently recording
	smaller velocities than the `Counter' method. Consequently one
	would conclude that there is lack of agreement between the two
	methods.
	
	The absence of inter-method bias by itself is not sufficient to
	establish whether two measurement methods agree. The two methods
	must also have equivalent levels of precision. Should one method
	yield results considerably more variable than those of the other,
	they can not be considered to be in agreement. With this in mind a
	methodology is required that allows an analyst to estimate the
	inter-method bias, and to compare the precision of both methods of
	measurement.
	\newpage
	% latex table generated in R 2.6.0 by xtable 1.5-5 package
	% Wed Aug 26 15:22:41 2009
	\begin{table}[h!]
		
		\begin{center}
			
			\begin{tabular}{rrrr}
				\hline
				Round& Fotobalk (F) & Counter (C) & F-C \\
				\hline
				1 & 793.8& 794.6 & -0.8 \\
				2 & 793.1 & 793.9 & -0.8 \\
				3 & 792.4 & 793.2 & -0.8 \\
				4 & 794.0 & 794.0 & 0.0 \\
				5 & 791.4 & 792.2 & -0.8 \\
				6 & 792.4 & 793.1 & -0.7 \\
				7 & 791.7 & 792.4 & -0.7 \\
				8 & 792.3 & 792.8 & -0.5 \\
				9 & 789.6 & 790.2 & -0.6 \\
				10 & 794.4 & 795.0 & -0.6 \\
				11 & 790.9 & 791.6 & -0.7 \\
				12 & 793.5 & 793.8 & -0.3 \\
				\hline
			\end{tabular}
			\caption{Difference between Fotobalk and Counter measurements.}
		\end{center}
	\end{table}
	
	%----------------------------------------------------------------------------%
	\section{Agreement}
	Bland and Altman (1986) defined perfect agreement as the case where all of the pairs of rater data lie along the line of equality, where the line of equality is defined as the 45 degree line passing through the origin. To carry their idea a step further, we define a specific numerical measure of agreement as twice the expected squared perpendicular distance of the pair of random variables ($X1$, $X2$) to the line of equality or agreement in the $(X1,X2)$-plane, that is, $E(X1 - X2)2$, where X1 and X2 denote the continuous measurements of rater 1 and rater 2, respectively.\\
	
	Obviously, other $L_p$ norms may be considered for the purpose of numerically measuring agreement and warrant future consideration. Note that we will use the term rater and measuring device interchangeably throughout this article.
	
	\citet{BA86} define perfect agreement as 'The case where all of the pairs of rater data lie
	along the line of equality'. The Line of Equality is defined as the 45 degree line passing through the origin, or X=Y on a XY plane.
	
	Agreement is the extent to which the measure of the variable of interest, under a constant set of experimental conditions, yields the same result on repeated trials (Sanchez et al). The more consistent the results, the more reliable the measuring procedure.
	
	In particular, in medicine, new methods or devices that are cheaper, easier to use, or less invasive, are routinely developed. Agreement between a new method and either a traditional reference or gold standard must be evaluated before the new one is put into practice. Various methodologies have been proposed for this purpose in recent years.


	\section{Purpose of Method Comparison Studies}
	\citet{BXC2010} provides a review of many descriptions of the purpose of Method Comparison studies, several of which are reproduced here.
	
	\begin{quote}
		``The question being answered is not always clear, but is usually epxressed as an attempt to quantify the agreement
		between two methods" \citep{BA95}.
		
		``Some lack of agreement between different methods of measurement is inevitable. What matters is the amount by which they disagree. We want to know by how much the new method is likely to differ from the old, so that it is not enough to cause problems in the mathematical interpretation we can preplace the old method by the new, or even use the two interchangeably" \citep{BA99}.
		
		
		``It often happens that the same physical and chemical property can be measured in different ways. For example, one can determine For example, one can determine sodium in serum by flame atomic emission spectroscopy or by isotope dilution mass spectroscopy. The question arises as to which method is better" (Mandel, 1991).
		
		``In areas of inter-laboratory quality control, method comparisons, assay validations and individual bio-equivalence, etc, the agreement between observations and target (reference) values is
		of interest" \citep{lin2002}.
		
		``The purpose of comparing two methods of measurement of a continuous biological variable is to uncover systematic differences, not to point to
		similarities`" \citep{ludbrook97}.
		
		``In the pharmaceutical industry, measurement methods that measure the quantity of prdocuts are regulated. The FDA (U.S. Food and Drug Administration) requires that the manufacturer show equivalency prior to approving the new or alternatice method in quality control" (Tan \& Inglewicz, 1999). 
	\end{quote}
	
	While several major commonalities are present in each definitions, there is a different emphasis for each, which will inevitably give rise to confusion. \citet{BXC2010} seems to endorse a simple phrasing of the research question that is proposed by \citet{BA83}, i.e. ``\textit{do the two methods of measurement agree sufficiently closely?}" with \citet{BXC2010} expressing the view that other considerations (for example, the ``equivalence" of two methods) to be treated as separate research questions. As such, we will revert to other research questions, such as ``equivalence of methods" later, focussing on agreement and repeatability of methods.

	

	\section{Equivalence and Interchangeability}
	Limits of agreement are intended to analyse equivalence. How this
	is assessed is the considered judgement of the practitioner. In
	\citet{BA86} an example of good agreement is cited. For two
	methods of measuring `oxygen saturation', the limits of agreement
	are calculated as (-2.0,2.8).A practitioner would ostensibly find
	this to be sufficiently narrow.
	
	If the limits of agreement are not clinically important, which is
	to say that the differences tend not to be substantial, the two
	methods may be used interchangeably. \citet{DunnSEME} takes issue
	with the notion of `equivalence', remarking that while agreement
	indicated equivalence, equivalence does not reflect agreement.
	
	
	

	\section{Discussion on Method Comparison Studies}
	
	The need to compare the results of two different measurement
	techniques is common in medical statistics.
	\\
	\\
	In particular, in medicine, new methods or devices that are
	cheaper, easier to use, or less invasive, are routinely developed.
	Agreement between a new method and a traditional reference or gold
	standard must be evaluated before the new one is put into
	practice. Various methodologies have been proposed for this
	purpose in recent years.
	
	Indications on how to deal with outliers in Bland Altman plots
	\\
	We wish to determine how outliers should be treated in a Bland
	Altman Plot
	\\
	In their 1983 paper they merely state that the plot can be used to
	'spot outliers'.
	\\
	In  their 1986 paper, Bland and Altman give an example of an
	outlier. They state that it could be omitted in practice, but make
	no further comments on the matter.
	\\
	In Bland and Altmans 1999 paper, we get the clearest indication of
	what Bland and Altman suggest on how to react to the presence of
	outliers. Their recommendation is to recalculate the limits
	without them, in order to test the difference with the calculation
	where outliers are retained.\\
	
	The span has reduced from 77 to 59 mmHg, a noticeable but not
	particularly large reduction.
	\\
	However, they do not recommend removing outliers. Furthermore,
	they say:
	\\
	We usually find that this method of analysis is not too sensitive
	to one or two large outlying differences.
	\\
	We ask if this would be so in all cases. Given that the limits of
	agreement may or may not be disregarded, depending on their
	perceived suitability, we examine whether it would possible that
	the deletion of an outlier may lead to a calculation of limits of
	agreement that are usable in all cases?
	\\
	Should an Outlying Observation be omitted from a data set? In
	general, this is not considered prudent.
	\\
	Also, it may be required that the outliers are worthy of
	particular attention themselves.
	\\
	Classifying outliers and recalculating We opted to examine this
	matter in more detail. The following points have to be considered
	\\how to suitably identify an outlier (in a generalized sense)
	\\Would a recalculation of the limits of agreement generally
	results in  a compacted range between the upper and lower limits
	of agreement?


	\section{Paired sample \emph{t} test}
	
	\citet{Bartko} discusses the use of the well known paired sample
	$t$ test to test for inter-method bias; $H: \mu_{d}=0$. The test
	statistic is distributed a $t$ random variable with $n-1$ degrees
	of freedom and is calculated as follows,
	
	\begin{equation}
		t^{*} = \frac{\bar{d}}{ \frac{s_{d}}{\sqrt{n}}}
	\end{equation}
	
	where $\bar{d}$ and $s_{d}$ is the average of the differences of
	the $n$ observations. Only if the two methods show comparable
	precision then the paired sample student t-test is appropriate for
	assessing the magnitude of the bias.
	\begin{eqnarray}
		t^{*} = \frac{\bar{d}}{s_{d}/\sqrt{n}}
	\end{eqnarray}
	

	\section{Identifiability}
	\citet{DunnSEME} highlights an important issue regarding using
	models such as these, the identifiability problem. This comes as a
	result of there being too many parameters to be estimated.
	Therefore assumptions about some parameters, or estimators used,
	must be made so that others can be estimated. For example in literature the variance
	ratio $\lambda=\frac{\sigma^{2}_{1}}{\sigma^{2}_{2}}$
	must often be assumed to be equal to $1$ \citep{linnet98}.\citet{DunnSEME} considers methodologies based on two methods with single measurements on each subject as inadequate for a serious
	study on the measurement characteristics of the methods. This is
	because there would not be enough data to allow for a meaningful
	analysis. There is, however, a contrary argument that in many
	practical settings it is very difficult to get replicate
	observations when the measurement method requires invasive medical
	procedure.
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Bartko's BB
	\citet{BB89} offers a formal simultaneous hypothesis test for the
	mean and variance of two paired data sets. Using simple linear
	regression of the differences of each pair against the sums, a
	line is fitted to the model, with estimates for intercept and
	slope ($\hat{\beta}_{0}$ and $\hat{\beta}_{1}$). The null
	hypothesis of this test is that the mean ($\mu$) and variance
	($\sigma^{2}$) of both data sets are equal if the slope and
	intercept estimates are equal to zero(i.e $\sigma^{2}_{1} =
	\sigma^{2}_{2}$ and $\mu_{1}=\mu_{2}$ if and only if $\beta_{0}=
	\beta_{1}=0$ )
	
	A test statistic is then calculated from the regression analysis
	of variance values \citep{BB89} and is distributed as `$F$' random
	variable. The degrees of freedom are $\nu_{1}=2$ and $\nu_{1}=n-2$
	(where $n$ is the number of pairs). The critical value is chosen
	for $\alpha\%$ significance with those same degrees of freedom.
	\citet{Bartko} amends this methodology for use in method
	comparison studies, using the averages of the pairs, as opposed to
	the sums, and their differences. This approach can facilitate
	simultaneous usage of test with the Bland-Altman methodology.
	Bartko's test statistic take the form:
	\[ F.test = \frac{(\Sigma d^{2})-SSReg}{2MSReg}
	\]
	% latex table generated in R 2.6.0 by xtable 1.5-5 package
	% Mon Aug 31 15:53:51 2009
	\begin{table}[ht]
		\begin{center}
			\begin{tabular}{lrrrrr}
				\hline
				& Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
				\hline
				Averages & 1 & 0.04 & 0.04 & 0.74 & 0.4097 \\
				Residuals & 10 & 0.60 & 0.06 &  &  \\
				\hline
			\end{tabular}
			\caption{Regression ANOVA of case-wise differences and averages
				for Grubbs Data}
		\end{center}
	\end{table}
	%(calculate using R code $qf(0.95,2,10)$).
	
	For the Grubbs data, $\Sigma d^{2}=5.09 $, $SSReg = 0.60$ and
	$MSreg=0.06$ Therefore the test statistic is $37.42$, with a
	critical value of $4.10$. Hence the means and variance of the
	Fotobalk and Counter chronometers are assumed to be simultaneously
	equal.
	
	Importantly, this methodology determines whether there is both
	inter-method bias and precision present, or alternatively if there
	is neither present. It has previously been demonstrated that there
	is a inter-method bias present, but as this procedure does not
	allow for separate testing, no conclusion can be drawn on the
	comparative precision of both methods.
	
	
	
	%This application of the
	%Grubbs method presumes the existence of this condition, and necessitates
	%replication of observations by means external to and independent of the first
	%means. The Grubbs estimators method is based on the laws of propagation of
	%error. By making three independent simultaneous measurements on the same
	%physical material, it is possible by appropriate mathematical manipulation of
	%the sums and differences of the associated variances to obtain a valid
	%estimate of the precision of the primary means. Application of the Grubbs
	%estimators procedure to estimation of the precision of an apparatus uses
	%the results of a physical test conducted in such a way as to obtain a series
	%of sets of three independent observations.
	
	






	\section{Normality of Case-wise Differences}
	
	The difference are assumed to be normally distributed, although the measurements themselves are not assumed to follow any distribution.Therefore the authors argue that the 95\% of differences are expected to lie within these limits. This assumption is justified because variation between subjects has been removed, leaving only measurement error \citep{BA86}. There are formal methodologies to test whether this assumption holds.
	
	
	The problem of assessing the agreement between two or more methods
	of measurement is ubiquitous in scientific research, and is
	commonly referred to as a `method comparison study'. Published
	examples of method comparison studies can be found in disciplines
	as diverse as Pharmacology \citep{ludbrook97}, Anaesthesia
	\citep{Myles}, and cardiac imaging methods \citep{Krumm}.
	\smallskip
	
	To illustrate the characteristics of a typical method comparison
	study consider the data in Table I, taken from \citet{Grubbs73}.
	In each of twelve experimental trials a single round of ammunition
	was fired from a 155mm gun, and its velocity was measured
	simultaneously (and independently) by three chronographs devices,
	referred to here as `Fotobalk', `Counter' and `Terma'.
	\smallskip
	
	
	\newpage
	
	\begin{table}[ht]
		\begin{center}
			\begin{tabular}{rrrr}
				\hline
				Round& Fotobalk [F] & Counter [C]& Terma [T]\\
				\hline
				1 & 793.8 & 794.6 & 793.2 \\
				2 & 793.1 & 793.9 & 793.3 \\
				3 & 792.4 & 793.2 & 792.6 \\
				4 & 794.0 & 794.0 & 793.8 \\
				5 & 791.4 & 792.2 & 791.6 \\
				6 & 792.4 & 793.1 & 791.6 \\
				7 & 791.7 & 792.4 & 791.6 \\
				8 & 792.3 & 792.8 & 792.4 \\
				9 & 789.6 & 790.2 & 788.5 \\
				10 & 794.4 & 795.0 & 794.7 \\
				11 & 790.9 & 791.6 & 791.3 \\
				12 & 793.5 & 793.8 & 793.5 \\
				\hline
			\end{tabular}
			\caption{Measurement of the three chronographs (Grubbs 1973)}
		\end{center}
	\end{table}
	
	An important aspect of the these data is that all three methods of
	measurement are assumed to have an attended measurement error, and
	the velocities reported in Table I can not be assumed to be `true
	values' in any absolute sense. For expository purposes only the
	first two methods `Fotobalk' and `Counter' will enter in the
	immediate discussion.
	
	%While lack of
	%agreement between two methods is inevitable, the question , as
	%posed by \citet{BA83}, is 'do the two methods of measurement agree
	%sufficiently closely?'
	
	A method of measurement should ideally be both accurate and precise.An accurate measurement methods shall give a result close to the `true value'. Precision of a method is indicated by how tightly clustered its measurements are around their mean measurement value.
	
	A precise and accurate method should yield results consistently close to the true value. However a method may be accurate, but not precise. The average of its measurements is close to the true
	value, but those measurements are highly dispersed. Conversely an inaccurate method may be quite precise , as it consistently indicates the same level of inaccuracy.
	
	The tendency of a method of measurement to consistently give results above or below the true value is a source of systematic bias. The lesser the systematic bias, the greater the accuracy of the method.
	
	In the context of the agreement of two methods, there is also a tendency of one measurement method to consistently give results above or below the other method. Lack of agreement is a consequence of the existence of `inter-method bias'. For two methods to be considered in good agreement, the inter-method bias should be in the region of zero.
	
	A simple estimation of the inter-method bias can be calculated using the differences of the paired measurements. The data in Table 1.2 are a good example of possible inter-method bias; the `Fotobalk' consistently recording smaller velocities than the `Counter' method. Consequently there is lack of agreement between the two methods.
	\newpage
	% latex table generated in R 2.6.0 by xtable 1.5-5 package
	% Wed Aug 26 15:22:41 2009
	\begin{table}[h!]
		\begin{center}
			
			\begin{tabular}{rrrr}
				\hline
				Round& Fotobalk (F) & Counter (C) & F-C \\
				\hline
				1 & 793.80 & 794.60 & -0.80 \\
				2 & 793.10 & 793.90 & -0.80 \\
				3 & 792.40 & 793.20 & -0.80 \\
				4 & 794.00 & 794.00 & 0.00 \\
				5 & 791.40 & 792.20 & -0.80 \\
				6 & 792.40 & 793.10 & -0.70 \\
				7 & 791.70 & 792.40 & -0.70 \\
				8 & 792.30 & 792.80 & -0.50 \\
				9 & 789.60 & 790.20 & -0.60 \\
				10 & 794.40 & 795.00 & -0.60 \\
				11 & 790.90 & 791.60 & -0.70 \\
				12 & 793.50 & 793.80 & -0.30 \\
				\hline
			\end{tabular}
			\caption{Difference between Fotobalk and Counter measurements}
		\end{center}
	\end{table}
	
	\bigskip
	
	\noindent The absence of inter-method bias by itself is not sufficient to establish whether two measurement methods agree or not. These methods must also have equivalent levels of precision. Should one method yield results considerably more variable than that of the other, they can not be considered to be in agreement.
	
	Therefore a methodology must be introduced that allows an analyst to estimate the inter-method bias, and to compare the precision of both methods of measurement.
	
	
	%Also the variances of the results from both methods should not be
	%significantly different. There are well established methods for
	%determining whether variance of two data sets are equal ,such as
	%the Pitman-Morgan test \citep{Pitman} \citep{Morgan}.
	
	%Precision  may be defined as as the quality that results of two
	%methods shall have similar variance , consistently throughout the
	%range of measurement.
	
	\section{Inappropriate assessment of Agreement}
	\section{Paired T tests} This method can be applied to test for
	statistically significant deviations in bias. This method can be
	potentially misused for method comparison studies.
	\\It is a poor measure of agreement when the rater's measurements
	are perpendicular to the line of equality[Hutson et al]. In this
	context, an average difference of zero between the two raters, yet
	the scatter plot displays strong negative correlation.


	\section{Inferences on Bland-Altman estimates}
	\citet*{BA99}advises on how to calculate confidence intervals for the inter-method bias and limits of agreement.
	For the inter-method bias, the confidence interval is a simply that of a mean: $\bar{d} \pm t_{(0.5\alpha,n-1)} S_{d}/\sqrt{n}$.
	The confidence
	intervals and standard error for the limits of agreement follow from the variance of the limits of agreement, which is shown to be
	
	\[
	\mbox{Var}(LoA) = (\frac{1}{n}+\frac{1.96^{2}}{2(n-1)})s_{d}^{2}.
	\]
	
	If $n$ is sufficiently large this can be following approximation
	can be used
	\[
	\mbox{Var}(LoA) \approx 1.71^{2}\frac{s_{d}^{2}}{n}.
	\]
	Consequently the standard errors of both limits can be
	approximated as $1.71$ times the standard error of the
	differences.
	
	A $95\%$ confidence interval can be determined, by means of the
	\emph{t} distribution with $n-1$ degrees of freedom. However \citet*{BA99} comment that such calculations  may be `somewhat optimistic' on account of the associated assumptions not being realized.
	
	%\section{Small Sample Sizes} The limits of agreement are
	%estimates derived from the sample studied, and will differ from
	%values relevant to the whole population, hence the importance of a
	%suitably large sample size. A different sample would give
	%different limits of agreement. Student's t-distribution is a well
	%known probability distribution used in statistical inference for
	%normally distributed populations when the sample size is small
	%\citep{student,Fisher3}. Consequently, using 't' quantiles , as
	%opposed to standard normal quantiles, may give a more appropriate
	%calculation for limits of agreement when the sample size is small.
	%For sample size $n=12$ the `t' quantile is 2.2 and the limits of
	%agreement are (-0.074,-1.143).
	

	\section{Lack Of Agreement}
	
	
	\section*{Constant Bias} This is a form of systematic
	deviations estimated as the average difference between the test
	and the reference method
	
	
	\section*{Proportional Bias} Two methods may agree on
	average, but they may exhibit differences over a range of
	measurements.
	
	


	\section{Statement of a Model}
	\citet{BXC2010} presents a useful formulation for comparing two methods $X$ and $Y$, in their measurement of item $i$, where the unknown `true value' is $\tau_i$. Other authors, such as \citet{kinsella}, present similar formulations of the same model, as well as modified models to account for multiple measurements by each methods on each item, known as replicate measurements.
	
	\begin{eqnarray} X_i = \tau_i + \delta_i , \phantom{spacin} \delta_i \sim \mathcal{N}(0,\sigma^2_\delta)\\ Y_i = \alpha + \beta \tau_i + \epsilon_i, \phantom{spaci}  \epsilon_i \sim \mathcal{N}(0,\sigma^2_\epsilon)\end{eqnarray}
	
	In some types of analysis, such as the conversion problems described by \citet{lewis}, an estimate for 
	the scaling factor $\beta$ may also be sought. For the time being, we will restrict ourselves to problems where $\beta$ is assumed to be 1. 
	
	\begin{eqnarray}
		X_i = \tau_i + \delta_i , \phantom{spacin} \delta_i \sim \mathcal{N}(0,\sigma^2_\delta)\\
		Y_i = \alpha + \beta \tau_i + \epsilon_i, \phantom{spaci}  \epsilon_i \sim \mathcal{N}(0,\sigma^2_\epsilon)
	\end{eqnarray}
	
	In this formulation, $\alpha$ represents the inter-method bias, and can be estimated as $E(X-Y)$. That is to say, a simple estimate of the inter-method bias is given by the differences between pairs of measurements.  Table~\ref{FCTdata} is a good example of possible inter-method bias; the `Fotobalk' consistently recording
	smaller velocities than the `Counter' method. A cursory inspection of the table will indicate a systematic tendency for the Counter method to result in higher measurements than the Fotobalk method. % Consequently one would conclude that there is lack of agreement % between the two methods.
	
	The absence of inter-method bias is, by itself, not sufficient to establish that two measurement methods agree. The two methods must also have equivalent levels of precision. Should one method yield results considerably more variable than those of the other, they can not be considered to be in agreement. Hence, method comparison studies are required to take account of both inter-method bias and difference in precision of measurements.
	
	% latex table generated in R 2.6.0 by xtable 1.5-5 package
	% Wed Aug 26 15:22:41 2009
	\begin{table}[h!]
		
		\begin{center}
			
			\begin{tabular}{rrrr}
				\hline
				Round& Fotobalk (F) & Counter (C) & Difference (F-C) \\
				\hline
				1 & 793.8& 794.6 & -0.8 \\
				2 & 793.1 & 793.9 & -0.8 \\
				3 & 792.4 & 793.2 & -0.8 \\
				4 & 794.0 & 794.0 & 0.0 \\
				5 & 791.4 & 792.2 & -0.8 \\
				6 & 792.4 & 793.1 & -0.7 \\
				7 & 791.7 & 792.4 & -0.7 \\
				8 & 792.3 & 792.8 & -0.5 \\
				9 & 789.6 & 790.2 & -0.6 \\
				10 & 794.4 & 795.0 & -0.6 \\
				11 & 790.9 & 791.6 & -0.7 \\
				12 & 793.5 & 793.8 & -0.3 \\
				\hline
			\end{tabular}
			\caption{Difference between Fotobalk and Counter measurements.}
			\label{FCTdata}\end{center}
	\end{table}
	Even without computing the mean difference, a cursory examination of the table will indicate that one method consistently provides a measurement less than the other.
	\newpage

	
	\chapter{Review of Current Methodologies:Bland-Altman Methodology}
	\section{Bland-Altman methodology}
	The issue of whether two measurement methods comparable to the
	extent that they can be used interchangeably with sufficient
	accuracy is encountered frequently in scientific research.
	Historically comparison of two methods of measurement was carried
	out by use of paired sample $t-$test, correlation coefficients or
	simple linear regression. Simple linear regression is unsuitable for method comparison studies because of the required assumption that one variable is measured without error. In comparing two methods, both methods are assume to have attendant random error.
	
	Statisticians Martin Bland and Douglas Altman recognized the inadequacies of these analyzes and
	articulated quite thoroughly the basis on which of which they are unsuitable for comparing two methods of measurement \citep*{BA83}. Furthermore they proposed their simple methodology specifically
	constructed for method comparison studies. They acknowledge the opportunity to apply other valid, but complex, methodologies, but argue that a simple approach is preferable, especially when the
	results must be `explained to non-statisticians'.
	
	Notwithstanding previous remarks about linear regression, the first step recommended, which the authors argue should be mandatory, is construction of a simple scatter plot of the data. The line of equality should also be shown, as it is necessary to give the correct interpretation of how both methods compare. In the case of good agreement, the observations would be distributed closely along the line of equality. A scatter plot of the Grubbs data is shown in Figure 1.1. Visual inspection confirms the previous conclusion that there is an inter-method bias present, i.e. Fotobalk device has a tendency to record a lower velocity.
	
	%\begin{figure}[h!]
	%	\begin{center}
	%		\includegraphics[width=125mm]{GrubbsScatter.jpeg}
	%		\caption{Scatter plot For Fotobalk and Counter Methods.}\label{GrubbsScatter}
	%	\end{center}
	%\end{figure}
	
	\citet{Dewitte} notes that scatter plots were very seldom
	presented in the Annals of Clinical Biochemistry. This apparently
	results from the fact that the `Instructions for Authors' dissuade
	the use of regression analysis, which conventionally is
	accompanied by a scatter plot.
	
	\newpage
	\section{Bland-Altman Approach}
	The issue of whether two measurement methods comparable to the
	extent that they can be used interchangeably with sufficient
	accuracy is encountered frequently in scientific research.
	Historically, comparison of two methods of measurement was carried
	out by use of paired sample $t-$test, correlation coefficients or
	simple linear regression. However, simple linear regression is unsuitable for method comparison studies due to the assumption that one variable is measured without error. In comparing two methods, both methods are assume to have attendant random error.
	
	\citet{BA83} highlighted the inadequacies of these approaches for comparing two methods of measurement, and proposed methodologies with this specific application in mind. Although the authors also acknowledge the opportunity to apply other, more complex, approaches, but argue that simpler approaches is preferable, especially when the
	results must be `explained to non-statisticians'.
	
	Notwithstanding previous remarks about linear regression, the first step recommended, which the authors argue should be mandatory, is the construction of a scatter plot of the data. Scatterplots can facilitate an initial judgement and
	helping to identify potential outliers, with the addition of the line of equality. In the case of good agreement, the observations would be distributed closely along this line. However, they are not useful for a thorough examination of the data. \citet{BritHypSoc} notes that
	data points will tend to cluster around the line of equality, obscuring interpretation.
	
	
	A scatter plot of the Grubbs data is shown in Figure 1.1. Visual inspection confirms the previous conclusion that inter-method bias is present, i.e. the Fotobalk device has a tendency to record a lower velocity.
	
	\begin{figure}[h!]
		\begin{center}
			\includegraphics[width=125mm]{images/GrubbsScatter.jpeg}
			\caption{Scatter plot for Fotobalk and Counter methods.}\label{GrubbsScatter}
		\end{center}
	\end{figure}
	
	\citet{Dewitte} notes that scatter plots were very seldom
	presented in the Annals of Clinical Biochemistry. This apparently
	results from the fact that the `Instructions for Authors' dissuade
	the use of regression analysis, which conventionally is
	accompanied by a scatter plot.
	

	\section*{Rendering a Bland-Altma plot}
	Construction of a Bland-Altman plot can be implemented easily with \texttt{R} packages such as Bendix Carstensen's \texttt{MethComp} package, which is designed to \textit{provide computational tools to manipulate, display and analyze data from method comparison studies} \citep{BXC2010}.
	
	\section{Bland-Altman plots for the Grubbs data}
	
	In the case of the Grubbs data the inter-method bias is $-0.61$ metres per second, and is indicated by the dashed line on Figure 1.2. By inspection of the plot, it is also possible to compare the precision of each method. Noticeably the differences tend to increase as the averages increase.
	
	
	The Bland-Altman plot for comparing the `Fotobalk' and `Counter'
	methods, which shall henceforth be referred to as the `F vs C'
	comparison,  is depicted in Figure 1.2, using data from Table 1.3.
	The presence and magnitude of the inter-method bias is indicated
	by the dashed line.
	\newpage
	
	%Later it will be shown that case-wise differences are the sole
	%component of the next part of the methodology, the limits of
	%agreement.
	
	
	\begin{table}[h!]
		\renewcommand\arraystretch{0.7}%
		\begin{center}
			\begin{tabular}{|c||c|c||c|c|}
				\hline
				Round & Fotobalk  & Counter  & Differences  & Averages  \\
				&  [F] & [C] & [F-C] &  [(F+C)/2] \\
				\hline
				1 & 793.8 & 794.6 & -0.8 & 794.2 \\
				2 & 793.1 & 793.9 & -0.8 & 793.5 \\
				3 & 792.4 & 793.2 & -0.8 & 792.8 \\
				4 & 794.0 & 794.0 & 0.0 & 794.0 \\
				5 & 791.4 & 792.2 & -0.8 & 791.8 \\
				6 & 792.4 & 793.1 & -0.7 & 792.8 \\
				7 & 791.7 & 792.4 & -0.7 & 792.0 \\
				8 & 792.3 & 792.8 & -0.5 & 792.5 \\
				9 & 789.6 & 790.2 & -0.6 & 789.9 \\
				10 & 794.4 & 795.0 & -0.6 & 794.7 \\
				11 & 790.9 & 791.6 & -0.7 & 791.2 \\
				12 & 793.5 & 793.8 & -0.3 & 793.6 \\
				\hline
			\end{tabular}
			\caption{Fotobalk and Counter methods: differences and averages.}
		\end{center}
	\end{table}
	
	\begin{table}[h!]
		\renewcommand\arraystretch{0.7}%
		\begin{center}
			\begin{tabular}{|c||c|c||c|c|}
				\hline
				Round & Fotobalk  & Terma  & Differences  & Averages  \\
				&  [F] & [T] & [F-T] &  [(F+T)/2] \\
				\hline
				1 & 793.8 & 793.2 & 0.6 & 793.5 \\
				2 & 793.1 & 793.3 & -0.2 & 793.2 \\
				3 & 792.4 & 792.6 & -0.2 & 792.5 \\
				4 & 794.0 & 793.8 & 0.2 & 793.9 \\
				5 & 791.4 & 791.6 & -0.2 & 791.5 \\
				6 & 792.4& 791.6 & 0.8 & 792.0 \\
				7 & 791.7 & 791.6 & 0.1 & 791.6 \\
				8 & 792.3 & 792.4 & -0.1 & 792.3 \\
				9 & 789.6 & 788.5 & 1.1 & 789.0 \\
				10 & 794.4 & 794.7 & -0.3 & 794.5 \\
				11 & 790.9 & 791.3 & -0.4 & 791.1 \\
				12 & 793.5 & 793.5 & 0.0 & 793.5 \\
				
				\hline
			\end{tabular}
			\caption{Fotobalk and Terma methods: differences and averages.}
		\end{center}
	\end{table}
	
	\newpage
	
	\begin{figure}[h!]
		\begin{center}
			\includegraphics[width=120mm]{images/GrubbsBAplot-noLOA.jpeg}
			\caption{Bland-Altman plot For Fotobalk and Counter methods.}\label{GrubbsBA-noLOA}
		\end{center}
	\end{figure}
	
	
	
	In Figure 1.3 Bland-Altman plots for the `F vs C' and `F vs T'
	comparisons are shown, where `F vs T' refers to the comparison of
	the `Fotobalk' and `Terma' methods. Usage of the Bland-Altman plot
	can be demonstrate in the contrast between these comparisons. By inspection, there exists a larger inter-method bias in the `F vs C' comparison than in the `F vs T' comparison. Conversely there
	appears to be less precision in `F vs T' comparison, as indicated
	by the greater dispersion of covariates.
	
	\begin{figure}[h!]
		\begin{center}
			\includegraphics[height=90mm]{images/GrubbsDataTwoBAplots.jpeg}
			\caption{Bland-Altman plots for Grubbs' F vs C and F vs T comparisons.}\label{GrubbsDataTwoBAplots}
		\end{center}
	\end{figure}
	
	\newpage
	
	
	%\subfile{TechAcceptModel.tex}

	\section{Inspecting the Data}
	Bland-Altman plots are a powerful graphical methodology for making
	a visual assessment of the data. \citet*{BA83} express the
	motivation for this plot thusly:
	\begin{quote}
		"From this type of plot it is much easier to assess the magnitude
		of disagreement (both error and bias), spot outliers, and see
		whether there is any trend, for example an increase in
		(difference) for high values. This way of plotting the data is a
		very powerful way of displaying the results of a method comparison
		study."
	\end{quote}
	
	
	Figures 1.3 1.4 and 1.5 are three Bland-Altman plots derived from
	simulated data, each for the purpose of demonstrating how the plot
	would inform an analyst of trends that would adversely affect use
	of the recommended methodology. Figure 1.3 demonstrates how the
	Bland Altman plot would indicate increasing variance of
	differences over the measurement range. Figure 1.4 is an example
	of cases where the inter-method bias changes over the measurement
	range. This is known as proportional bias \citep{ludbrook97}.
	
	
	\begin{figure}[h!]
		\begin{center}
			\includegraphics[width=125mm]{images/BAFanEffect.jpeg}
			\caption{Bland-Altman Plot demonstrating the increase of variance over the range}\label{BAFanEffect}
		\end{center}
	\end{figure}
	
	\begin{figure}[h!]
		\begin{center}
			\includegraphics[width=125mm]{images/PropBias.jpeg}
			\caption{Bland-Altman Plot indicating the presence of proportional bias}\label{PropBias}
		\end{center}
	\end{figure}
	
	\newpage
	Figure 1.4 is an example of cases where the inter-method bias
	changes over the measurement range. This is known as proportional
	bias (Ludbrook, 1997). Both of these cases violate the assumptions
	necessary for further analysis using limits of agreement ,which
	shall be discussed later. The plot also can be used to identify
	outliers. An outlier is an observation that is numerically distant
	from the rest of the data. Classification thereof is a subjective
	decision in any analysis, but must be informed by the logic of the
	formulation. Figure 1.5 is a Bland Altman plot with two
	conspicuous observations, at the extreme left and right of the
	plot respectively.
	
	
	\begin{figure}[h!]
		\begin{center}
			\includegraphics[width=125mm]{images/BAOutliers.jpeg}
			\caption{Bland-Altman Plot indicating the presence of Outliers}\label{PropBias}
		\end{center}
	\end{figure}
	
	In the Bland-Altman plot, the horizontal displacement of any
	observation is supported by two independent measurements. Hence
	any observation , such as the one on the extreme right of figure
	1.5, should not be considered an outlier on the basis of a
	noticeable horizontal displacement from the main cluster. The one
	on the extreme left should be considered an outlier, as it has a
	noticeable vertical displacement from the rest of the
	observations.
	
	\citet*{BA99} do not recommend excluding outliers from analyses.
	However recalculation of the inter-method bias estimate , and
	further calculations based upon that estimate, are useful for
	assessing the influence of outliers.\citep{BA99} states that
	\emph{"We usually find that this method of analysis is not too
		sensitive to one or two large outlying differences."}


	\section{The Bland Altman Plot}
	In 1986 Bland and Altman published a paper in the Lancet proposing
	the difference plot for use for method comparison purposes. It has
	proved highly popular ever since. This is a simple, and widely
	used , plot of the differences of each data pair, and the
	corresponding average value. An important requirement is that the
	two measurement methods use the same scale of measurement.

	\section{Bland Altman Plot}
	Bland Altman have recommended the use of graphical techniques to
	assess agreement. Principally their method is calculating , for
	each pair of corresponding two methods of measurement of some
	underlying quantity, with no replicate measurements, the
	difference and mean. Differences are then plotted against the
	mean.
	
	\textbf{\textit{Hopkins}} argued that the bias in a subsequent Bland-Altman plot was
	due, in part, to using least-squares regression at the calibration
	phase.
	
	
	%This page also shows the standard deviation (SD) of the
	%differences between the two assay methods. The SD value is used to
	%calculate the limits of agreement, computed as the mean bias plus
	%or minus 1.96 times its SD.
	%----------------------------------------------------------------------------%


	measurements\section{Bland Altman Plot} Bland Altman have
	recommended the use of graphical techniques to assess agreement.
	Principally their method is calculating , for each pair of
	corresponding two methods of measurement of some underlying
	quantity, with no replicate measurements, the difference and mean.
	Differences are then plotted against the mean.
	\\
	Hopkins argued that the bias in a subsequent Bland-Altman plot was
	due, in part, to using least-squares regression at the calibration
	phase.

	\section{Bland-Altman plots}
	
	In light of shortcomings associated with scatterplots,
	\citet*{BA83} recommend a further analysis of the data. Firstly
	case-wise differences of measurements of two methods $d_{i} =
	y_{1i}-y_{2i} \mbox{ for }i=1,2,\dots,n$ on the same subject
	should be calculated, and then the average of those measurements
	($a_{i} = (y_{1i} + y_{2i})/2 \mbox{ for }i=1,2,\dots, n$).
	
	\citet{BA83} proposes a scatterplot of the case-wise averages and differences of two methods of measurement. This scatterplot has since become widely known as the Bland-Altman plot. \citet*{BA83} express the
	motivation for this plot thusly:
	\begin{quote}
		``From this type of plot it is much easier to assess the magnitude
		of disagreement (both error and bias), spot outliers, and see
		whether there is any trend, for example an increase in (difference) for high values. This way of plotting the data is a very powerful way of displaying the results of a method comparison study."
	\end{quote}
	
	The case wise-averages capture several aspects of the data, such as expressing the range over which the values were taken, and assessing whether the assumptions of constant variance holds.
	Case-wise averages also allow the case-wise differences to be presented on a two-dimensional plot, with better data visualization qualities than a one dimensional plot. \citet{BA86}
	cautions that it would be the difference against either measurement value instead of their average, as the difference relates to both value. This methodology has proved very popular, and the Bland-Altman plots is widely regarded as powerful graphical methodology for making a visual assessment of the data.
	
	The magnitude of the inter-method bias between the two methods is simply the average of the differences $\bar{d}$. This inter-method bias is represented with a line on the Bland-Altman plot. As the objective of the Bland-Altman plot is to advise on the agreement of two methods, it is the case-wise differences that are also particularly relevant. The variances around this bias is estimated by the standard deviation of these differences $S_{d}$.
	
	\section{Bland Altman Plots}
	The issue of whether two measurement methods comparable to the
	extent that they can be used interchangeably with sufficient
	accuracy is encountered frequently in scientific research.
	Historically comparison of two methods of measurement was carried
	out by use of correlation coefficients or simple linear
	regression. Bland and Altman recognized the inadequacies of these
	analyses and articulated quite thoroughly the basis on which of
	which they are unsuitable for comparing two methods of measurement
	\citep*{BA83}.
	
	
	Furthermore they proposed their simple methodology specifically
	constructed for method comparison studies. They acknowledge that
	there are other valid, but complex, methodologies, and argue that
	a simple approach is preferable to this complex approaches,
	\emph{especially when the results must be explained to
		non-statisticians} \citep*{BA83}.
	
	\smallskip
	
	Notwithstanding previous remarks about regression, the first step
	recommended ,which the authors argue should be mandatory,is
	construction of a simple scatter plot of the data. The line of
	equality ($X=Y$) should also be shown, as it is necessary to give
	the correct interpretation of how both methods compare. A scatter
	plot of the Grubbs data is shown in figure 2.1. A visual
	inspection thereof confirms the previous conclusion that there is
	an inter method bias present, i.e. Fotobalk device has a tendency
	to record a lower velocity.
	
	\begin{figure}[h!]
		\begin{center}
			\includegraphics[width=130mm]{images/GrubbsScatter.jpeg}
			\caption{Scatter plot For Fotobalk and Counter Methods}\label{GrubbsScatter}
		\end{center}
	\end{figure}
	
	In light of shortcomings associated with scatterplots,
	\citet*{BA83} recommend a further analysis of the data. Firstly
	differences of measurements of two methods on the same subject
	should  be calculated, and then the average of those measurements
	(Table 2.1). These differences and averages are then plotted
	(Figure 2.2).
	
	
	
	
	The dashed line in Figure 2.2 alludes to the inter method bias
	between the two methods, as mentioned previously. Bland and Altman
	recommend the estimation of inter method bias by calculating the
	average of the differences. In the case of Grubbs data the inter
	method bias is $-0.6083$ metres per second.
	\newpage
	
	% latex table generated in R 2.6.0 by xtable 1.5-5 package
	% Thu Aug 27 16:31:52 2009
	\begin{table}[tbh]
		\begin{center}
			
			\begin{tabular}{rrrrr}
				\hline
				Round & Fotobalk [F] & Counter [C] & Differences [F-C] & Averages [(F+C)/2] \\
				\hline
				1 & 793.80 & 794.60 & -0.80 & 794.20 \\
				2 & 793.10 & 793.90 & -0.80 & 793.50 \\
				3 & 792.40 & 793.20 & -0.80 & 792.80 \\
				4 & 794.00 & 794.00 & 0.00 & 794.00 \\
				5 & 791.40 & 792.20 & -0.80 & 791.80 \\
				6 & 792.40 & 793.10 & -0.70 & 792.80 \\
				7 & 791.70 & 792.40 & -0.70 & 792.00 \\
				8 & 792.30 & 792.80 & -0.50 & 792.50 \\
				9 & 789.60 & 790.20 & -0.60 & 789.90 \\
				10 & 794.40 & 795.00 & -0.60 & 794.70 \\
				11 & 790.90 & 791.60 & -0.70 & 791.20 \\
				12 & 793.50 & 793.80 & -0.30 & 793.60 \\
				\hline
			\end{tabular}
			\caption{Fotobalk and Counter Methods: Differences and Averages}
		\end{center}
	\end{table}
	
	
	%\begin{figure}[h!]
	%\begin{center}
	%  \includegraphics[width=120mm]{GrubbsBAplot.jpeg}
	%  \caption{Bland Altman Plot For Fotobalk and Counter Methods}\label{GrubbsBA}
	%\end{center}
	%\end{figure}
	
	\newpage
	By inspection of the plot, it is also possible to compare the
	precision of each method. Noticeably the differences tend to
	increase as the averages increase.
	
	

	\section{Bland-Altman Plots}
	
	In light of shortcomings associated with scatterplots,
	\citet*{BA83} recommend a further analysis of the data. Firstly
	case-wise differences of measurements of two methods $d_{i} =
	y_{1i}-y_{2i}, \mbox{ for }i=1,2,\dots,n$, on the same subject
	should be calculated, and then the average of those measurements, 
	($a_{i} = (y_{1i} + y_{2i})/2 \mbox{ for }i=1,2,\dots, n$.
	
	Following a technique known as the Tukey mean-difference plot, as noted by \citet{kozak2014including}
	\citet{BA83} proposed that $a_i$ should be plotted against $d_i$, a plot now widely known as the Bland-Altman plot, and motivated this plot as follows:
	\begin{quote}
		``From this type of plot it is much easier to assess the magnitude
		of disagreement (both error and bias), spot outliers, and see
		whether there is any trend, for example an increase in (difference) for high values. This way of plotting the data is a very powerful way of displaying the results of a method comparison study."
	\end{quote}
	
	The case wise-averages capture several aspects of the data, such as expressing the range over which the values were taken, and assessing whether the assumptions of constant variance holds.
	Case-wise averages also allow the case-wise differences to be presented on a two-dimensional plot, with better data visualization qualities than a one dimensional plot. \citet{BA86}
	cautions that it would be the difference against either measurement value instead of their average, as the difference relates to both value. This approach has proved very popular, and the Bland-Altman plots is widely regarded as powerful graphical tool for making a visual assessment of the data.
	
	The magnitude of the inter-method bias between the two methods is simply the average of the differences $\bar{d}$. This inter-method bias is represented with a line on the Bland-Altman plot. As the objective of the Bland-Altman plot is to advise on the agreement of two methods, the individual case-wise differences are also particularly relevant. The variances around this bias is estimated by the standard deviation of these differences $S_{d}$.

	\section{Bland-Altman plots for the Grubbs data}
	
	In the case of the Grubbs data the inter-method bias is $-0.61$ metres per second, and is indicated by the dashed line on Figure 1.2. By inspection of the plot, it is also possible to compare the precision of each method. Noticeably the differences tend to increase as the averages increase.
	
	
	The Bland-Altman plot for comparing the `Fotobalk' and `Counter'
	methods, which shall henceforth be referred to as the `F vs C'
	comparison,  is depicted in Figure 1.2, using data from Table 1.3.
	The presence and magnitude of the inter-method bias is indicated
	by the dashed line.
	\newpage
	
	%Later it will be shown that case-wise differences are the sole
	%component of the next part of the methodology, the limits of
	%agreement.
	
	
	\begin{table}[h!]
		\renewcommand\arraystretch{0.7}%
		\begin{center}
			\begin{tabular}{|c||c|c||c|c|}
				\hline
				Round & Fotobalk  & Counter  & Differences  & Averages  \\
				&  [F] & [C] & [F-C] &  [(F+C)/2] \\
				\hline
				1 & 793.8 & 794.6 & -0.8 & 794.2 \\
				2 & 793.1 & 793.9 & -0.8 & 793.5 \\
				3 & 792.4 & 793.2 & -0.8 & 792.8 \\
				4 & 794.0 & 794.0 & 0.0 & 794.0 \\
				5 & 791.4 & 792.2 & -0.8 & 791.8 \\
				6 & 792.4 & 793.1 & -0.7 & 792.8 \\
				7 & 791.7 & 792.4 & -0.7 & 792.0 \\
				8 & 792.3 & 792.8 & -0.5 & 792.5 \\
				9 & 789.6 & 790.2 & -0.6 & 789.9 \\
				10 & 794.4 & 795.0 & -0.6 & 794.7 \\
				11 & 790.9 & 791.6 & -0.7 & 791.2 \\
				12 & 793.5 & 793.8 & -0.3 & 793.6 \\
				\hline
			\end{tabular}
			\caption{Fotobalk and Counter methods: differences and averages.}
		\end{center}
	\end{table}
	
	\begin{table}[h!]
		\renewcommand\arraystretch{0.7}%
		\begin{center}
			\begin{tabular}{|c||c|c||c|c|}
				\hline
				Round & Fotobalk  & Terma  & Differences  & Averages  \\
				&  [F] & [T] & [F-T] &  [(F+T)/2] \\
				\hline
				1 & 793.8 & 793.2 & 0.6 & 793.5 \\
				2 & 793.1 & 793.3 & -0.2 & 793.2 \\
				3 & 792.4 & 792.6 & -0.2 & 792.5 \\
				4 & 794.0 & 793.8 & 0.2 & 793.9 \\
				5 & 791.4 & 791.6 & -0.2 & 791.5 \\
				6 & 792.4& 791.6 & 0.8 & 792.0 \\
				7 & 791.7 & 791.6 & 0.1 & 791.6 \\
				8 & 792.3 & 792.4 & -0.1 & 792.3 \\
				9 & 789.6 & 788.5 & 1.1 & 789.0 \\
				10 & 794.4 & 794.7 & -0.3 & 794.5 \\
				11 & 790.9 & 791.3 & -0.4 & 791.1 \\
				12 & 793.5 & 793.5 & 0.0 & 793.5 \\
				
				\hline
			\end{tabular}
			\caption{Fotobalk and Terma methods: differences and averages.}
		\end{center}
	\end{table}
	
	\newpage
	
	%\begin{figure}[h!]
	%	\begin{center}
	%		\includegraphics[width=120mm]{GrubbsBAplot-noLOA.jpeg}
	%		\caption{Bland-Altman plot For Fotobalk and Counter methods.}\label{GrubbsBA-noLOA}
	%	\end{center}
	%\end{figure}
	
	
	
	In Figure 1.3 Bland-Altman plots for the `F vs C' and `F vs T'
	comparisons are shown, where `F vs T' refers to the comparison of
	the `Fotobalk' and `Terma' methods. Usage of the Bland-Altman plot
	can be demonstrate in the contrast between these comparisons. By inspection, there exists a larger inter-method bias in the `F vs C' comparison than in the `F vs T' comparison. Conversely there
	appears to be less precision in `F vs T' comparison, as indicated
	by the greater dispersion of covariates.
	
	%\begin{figure}[h!]
	%	\begin{center}
	%		\includegraphics[height=90mm]{GrubbsDataTwoBAplots.jpeg}
	%		\caption{Bland-Altman plots for Grubbs' F vs C and F vs T comparisons.}\label{GrubbsDataTwoBAplots}
	%	\end{center}
	%\end{figure}
	
	\newpage
	


	\section{Limits of Agreement}
	% introduces
	A third element of the Bland-Altman approach, an interval known
	as `limits of agreement' is introduced in \citet*{BA86}
	(sometimes referred to in literature as 95\% limits of agreement).
	Limits of agreement are used to assess whether the two methods of
	measurement can be used interchangeably. \citet{BA86} refer to
	this as the `equivalence' of two measurement methods. The specific question to which limits of
	agreement are intended as the answer to must be
	established clearly. \citet*{BA95} comment that the limits of agreement show `how
	far apart measurements by the two methods were likely to be for
	most individuals', a definition echoed in their 1999 paper:
	
	\begin{quote}``We can then say that nearly all pairs
		of measurements by the two methods will be closer together than
		these extreme values, which we call 95\% limits of agreement.
		These values define the range within which most differences
		between measurements by the two methods will lie."
	\end{quote}
	
	The limits of agreement (LoA) are computed by the following
	formula:
	\[
	LoA = \bar{d} \pm 1.96 s_{d}
	\]
	with $\bar{d}$ as the estimate of the inter method bias, $s_{d}$
	as the standard deviation of the differences and 1.96 (sometimes rounded to 2) is the 95\%
	quantile for the standard normal distribution. The limits of agreement methodology assumes a constant level of bias throughout the range of measurements. Importantly the authors recommend prior determination of what would constitute acceptable
	agreement, and that sample sizes should be predetermined to give an accurate conclusion. However \citet{mantha} highlight inadequacies in the correct application of limits of agreement, resulting in contradictory estimates of limits of agreement in various papers.
	
	%\begin{quote}
	%``How far apart measurements can be without causing difficulties
	%will be a question of judgment. Ideally, it should be defined in
	%advance to help in the interpretation of the method comparison and
	%to choose the sample size \citep{BA86}".
	%\end{quote}
	
	
	For the Grubbs `F vs C' comparison, these limits
	of agreement are calculated as -0.132 for the upper bound, and
	-1.08 for the lower bound. Figure 1.9 shows the resultant
	Bland-Altman plot, with the limits of agreement shown in dashed
	lines.
	
	
	\begin{figure}[h!]
		\begin{center}
			\includegraphics[width=125mm]{images/GrubbsBAplot-LOA.jpeg}
			\caption{Bland-Altman plot with limits of agreement}\label{GrubbsBAplot-noLOA}
		\end{center}
	\end{figure}
	
	%But as \citet*{BA86} point out this may not be the case. Variants of the limits of agreement that overcome this
	% problem shall be introduced in due course.
	
	
	\section{Limits of Agreement}
	\citet{BA86} introduces an elaboration of the plot, adding to the
	plot `limits of agreement' to the plot. These limits are based
	upon the standard deviation of the differences. The discussion
	shall be reverted to these limits of agreement in due course.

	\section{Limits Of Agreement}
	Bland and Altman proposed a pair of Limits of agreement. These
	limits are intended to demonstrate the range in which 95\% of the
	sample data should lie. The Limits of agreement centre on the
	average difference line and are 1.96 times the standard deviation
	above and below the average difference line.
	
	How this relates the overall population is unclear. It seems that
	it depends on an expert to decide whether or not the range of
	differences is acceptable. In a study A Bland-Altman plots compare
	two assay methods. It plots the difference between the two
	measurements on the Y axis, and the average of the two
	measurements on the X axis.
	
	The bias is computed as the average of the difference of paired
	assays.
	
	If one method is sometimes higher, and sometimes the other method
	is higher, the average of the differences will be close to zero.
	If it is not close to zero, this indicates that the two assay
	methods are producing different results systematically.

	\section{Limits of Agreement}
	% introduces
	A third element of the Bland-Altman methodology, an interval known
	as `limits of agreement' is introduced in \citet*{BA86}
	(sometimes referred to in literature as 95\% limits of agreement).
	Limits of agreement are used to assess whether the two methods of
	measurement can be used interchangeably. \citet{BA86} refer to
	this as the `equivalence' of two measurement methods. The specific purpose of the limits of
	agreement must be
	established clearly. \citet*{BA95} comment that the limits of agreement `how
	far apart measurements by the two methods were likely to be for
	most individuals', a definition echoed in their 1999 paper:
	
	\begin{quote}"We can then say that nearly all pairs
		of measurements by the two methods will be closer together than
		these extreme values, which we call 95\% limits of agreement.
		These values define the range within which most differences
		between measurements by the two methods will lie."
	\end{quote}
	
	The limits of agreement (LoA) are computed by the following
	formula:
	\[
	LoA = \bar{d} \pm 1.96 s_{d}
	\]
	with $\bar{d}$ as the estimate of the inter method bias, $s_{d}$
	as the standard deviation of the differences and 1.96 is the 95\%
	quantile for the standard normal distribution. (Some accounts of
	Bland-Altman plots use a multiple of 2 standard deviations instead
	for simplicity.)
	
	The limits of agreement methodology assumes a constant level of bias throughout the range of measurements. Importantly the authors recommend prior determination of what would and would constitute acceptable
	agreement, and that sample sizes should be predetermined to give an accurate conclusion. However \citet{mantha} highlights inadequacies in the correct application of limits of agreement, resulting in contradictory estimates limits of agreement in various papers.
	
	\begin{quote}
		``How far apart measurements can be without causing difficulties
		will be a question of judgment. Ideally, it should be defined in
		advance to help in the interpretation of the method comparison and
		to choose the sample size \citep{BA86}".
	\end{quote}
	
	
	For the Grubbs `F vs C' comparison, these limits
	of agreement are calculated as -0.132 for the upper bound, and
	-1.08 for the lower bound. Figure 1.9 shows the resultant
	Bland-Altman plot, with the limits of agreement shown in dashed
	lines.
	
	
	%\begin{figure}[h!]
	%	\begin{center}
	%		\includegraphics[width=125mm]{GrubbsBAplot-LOA.jpeg}
	%		\caption{Bland-Altman plot with limits of agreement}\label{GrubbsBAplot-noLOA}
	%	\end{center}
	%\end{figure}
	
	%But as \citet*{BA86} point out this may not be the case. Variants of the limits of agreement that overcome this
	% problem shall be introduced in due course.


	\section{Appropriate Use of Limits of Agreement}
	Importantly \citet{BA99} makes the following point:
	\begin{quote}These estimates are meaningful only if we can assume
		bias and variability are uniform throughout the range of
		measurement, assumptions which can be checked graphically.
	\end{quote}
	
	The import of this statement is that , should the Bland Altman
	plot indicate that these assumptions are not met, then their
	entire methodology, as posited thus far, is inappropriate for use
	in a method comparison study. Again, in the context of potential
	outlier in the Grubbs data (figure 1.2), this raises the question
	on how to correctly continue.
	
	Carstensen attends to the issue of repeated data, using the
	expression replicate to express a repeated measurement on a
	subject by the same methods. Carstensen formulates the data as
	follows Repeated measurement - Arrangement of data into groups,
	based on the series of results of each subject.
	
	
	
	%----------------------------------------------------------------------------%
	\section{Formal definition of limits of agreement}
	\citet{BA99} note the similarity of limits of agreement to
	confidence intervals, but are clear that they are not the same
	thing. Interestingly, they describe the limits as `being like a
	reference interval'.
	
	Limits of agreement have very similar construction to Shewhart
	control limits. The Shewhart chart is a well known graphical
	methodology used in statistical process control. Consequently
	there is potential for misinterpreting the limits of agreement as
	they were Shewhart control limits. 
	%Importantly the
	%parameters used to determine the Shewhart limits are time ordered, based on the process's historical values, a key difference with Bland-Altman limits of agreement.
	
	\citet{BXC2008} regards the limits of agreement as a prediction
	interval for the difference between future measurements with the
	two methods on a new individual, but states that it does not fit
	the formal definition of a prediction interval, since the
	definition does not consider the errors in estimation of the
	parameters. Prediction intervals, which are often used in
	regression analysis, are estimates of an interval in which future
	observations will fall, with a certain probability, given what has
	already been observed. \citet{BXC2008} offers an alternative
	formulation, a $95\%$ prediction interval for the difference
	\[
	\bar{d} \pm t_{(0.025, n-1)}s_{d} \sqrt{1+\frac{1}{n}}
	\]
	
	\noindent where $n$ is the number of subjects. Carstensen is
	careful to consider the effect of the sample size on the interval
	width, adding that only for 61 or more subjects is the
	quantile less than 2.
	
	\citet{luiz} offers an alternative description of limits of
	agreement, this time as tolerance limits. A tolerance interval for
	a measured quantity is the interval in which a specified fraction
	of the population's values lie, with a specified level of
	confidence. \citet{Barnhart} describes them as a probability
	interval, and offers a clear description of how they should be
	used; `if the absolute limit is less than an acceptable difference
	$d_{0}$, then the agreement between the two methods is deemed
	satisfactory'.
	
	The prevalence of contradictory definitions of what limits of agreement strictly are will inevitably attenuate the poor standard of reporting using limits of agreement, as mentioned by \citet{mantha}.
	
	%At least 100 historical
	%values must be used to determine the acceptable value (i.e the
	%process mean) and the process standard deviation. The principle
	%that the mean and variance of a large sample of a homogeneous
	%population is a close approximation of the population's mean and
	%variance justifies this.
	
	%\begin{figure}[h!]
	%\begin{center}
	%  \includegraphics[width=125mm]{GrubbsLOAwCIs.jpeg}
	%  \caption{Limits of agreement with confidence intervals}\label{LOAwCIs}
	%\end{center}
	%\end{figure}
	
	%\newpage
	%\section{Agreement Indices}
	%\citet{Barnhart} provided an overview of several agreement
	%indices, including the limits of agreement. Other approaches, such
	%as mean squared deviation, the tolerance deviation index and
	%coverage probability are also discussed.
	

	\section{Formal definition of limits of agreement}
	\citet{BA99} note the similarity of limits of agreement to
	confidence intervals, but are clear that they are not the same
	thing. Interestingly, they describe the limits as `being like a
	reference interval'.
	
	Limits of agreement have very similar construction to Shewhart
	control limits. The Shewhart chart is a well known graphical
	methodology used in statistical process control. Consequently
	there is potential for misinterpreting the limits of agreement as
	if equivalent to Shewhart control limits. Importantly the
	parameters used to determine the Shewhart limits are not based on any sample used for an analysis, but
	on the process's historical values, a key difference with
	Bland-Altman limits of agreement.
	
	\citet{BXC2008} regards the limits of agreement as a prediction
	interval for the difference between future measurements with the
	two methods on a new individual, but states that it does not fit
	the formal definition of a prediction interval, since the
	definition does not consider the errors in estimation of the
	parameters. Prediction intervals, which are often used in
	regression analysis, are estimates of an interval in which future
	observations will fall, with a certain probability, given what has
	already been observed. \citet{BXC2008} offers an alternative
	formulation, a $95\%$ prediction interval for the difference
	\[
	\bar{d} \pm t_{(0.975, n-1)}s_{d} \sqrt{1+\frac{1}{n}}
	\]
	
	\noindent where $n$ is the number of subjects. Carstensen is
	careful to consider the effect of the sample size on the interval
	width, adding that only for 61 or more subjects is there a
	quantile less than 2.
	
	\citet{luiz} offers an alternative description of limits of
	agreement, this time as tolerance limits. A tolerance interval for
	a measured quantity is the interval in which a specified fraction
	of the population's values lie, with a specified level of
	confidence. \citet{Barnhart} describes them as a probability
	interval, and offers a clear description of how they should be
	used;`if the absolute limit is less than an acceptable difference
	$d_{0}$, then the agreement between the two methods is deemed
	satisfactory'.
	
	The prevalence of contradictory definitions of what limits of agreement strictly are will inevitably attenuate the poor standard of reporting using limits of agreement, as mentioned by \citet{mantha}.
	
	%At least 100 historical
	%values must be used to determine the acceptable value (i.e the
	%process mean) and the process standard deviation. The principle
	%that the mean and variance of a large sample of a homogeneous
	%population is a close approximation of the population's mean and
	%variance justifies this.
	
	%\begin{figure}[h!]
	%\begin{center}
	%  \includegraphics[width=125mm]{GrubbsLOAwCIs.jpeg}
	%  \caption{Limits of agreement with confidence intervals}\label{LOAwCIs}
	%\end{center}
	%\end{figure}
	


	\section{Inferences on Bland-Altman estimates}
	\citet*{BA99} advises on how to calculate confidence intervals for the inter-method bias and limits of agreement.
	For the inter-method bias, the confidence interval is a simply that of a mean: $\bar{d} \pm t_{(\alpha/2,n-1)} S_{d}/\sqrt{n}$.
	The confidence
	intervals and standard error for the limits of agreement follow from the variance of the limits of agreement, which is shown to be
	
	\[
	\mbox{Var}(LoA) = (\frac{1}{n}+\frac{1.96^{2}}{2(n-1)})s_{d}^{2}.
	\]
	
	If $n$ is sufficiently large this can be following approximation
	can be used
	\[
	\mbox{Var}(LoA) \approx 1.71^{2}\frac{s_{d}^{2}}{n}.
	\]
	Consequently the standard errors of both limits can be
	approximated as $1.71$ times the standard error of the
	differences.
	
	A $95\%$ confidence interval can be determined, by means of the
	\emph{t} distribution with $n-1$ degrees of freedom. However, \citet*{BA99} comment that such calculations  may be `somewhat optimistic' on account of the associated assumptions not being realized.
	
	%\section{Small Sample Sizes} The limits of agreement are
	%estimates derived from the sample studied, and will differ from
	%values relevant to the whole population, hence the importance of a
	%suitably large sample size. A different sample would give
	%different limits of agreement. Student's t-distribution is a well
	%known probability distribution used in statistical inference for
	%normally distributed populations when the sample size is small
	%\citep{student,Fisher3}. Consequently, using 't' quantiles , as
	%opposed to standard normal quantiles, may give a more appropriate
	%calculation for limits of agreement when the sample size is small.
	%For sample size $n=12$ the `t' quantile is 2.2 and the limits of
	%agreement are (-0.074,-1.143).
	
	


	\section{Adverse features}
	
	Estimates for inter-method bias and variance of differences are only meaningful if there is uniform inter-bias and variability throughout the range of measurements. Fulfilment of these assumptions can be checked by visual inspection of the plot.The prototype Bland-Altman plots depicted in Figures 1.4, 1.5 and 1.6 are derived from simulated data, for the purpose of demonstrating how the plot would inform an analyst of features that would adversely affect use of the recommended methodology.
	
	Figure 1.4 demonstrates how the Bland-Altman plot would indicate
	increasing variance of differences over the measurement range.
	Fitted regression lines, for both the upper and lower half of the
	plot, has been added to indicate the trend. Figure 1.5 is an
	example of cases where the inter-method bias changes over the
	measurement range. This is known as proportional bias, and is
	defined by \citet{ludbrook97} as meaning that `one method gives
	values that are higher (or lower) than those from the other by an
	amount that is proportional to the level of the measured
	variable'. In both Figures 1.4 and 1.5, the assumptions necessary
	for further analysis using the limits of agreement are violated.
	
	Application of regression techniques to the Bland-Altman plot, and
	subsequent formal testing for the constant variability of
	differences is informative. The data set may be divided into two
	subsets, containing the observations wherein the difference values
	are less than and greater than the inter-method bias respectively.
	For both of these fits, hypothesis tests for the respective slopes
	can be performed. While both tests can be considered separately,
	multiple comparison procedures, such as the Benjamini-Hochberg
	\citep{BH} test, should be also be used.
	
	%\begin{figure}[h!]
	%	\begin{center}
	%		\includegraphics[height=90mm]{BAFanEffect.jpeg}
	%		\caption{Bland-Altman plot demonstrating the increase of variance over the range.}\label{BAFanEffect}
	%	\end{center}
	%\end{figure}
	
	%\begin{figure}[h!]
	%	\begin{center}
	%		\includegraphics[height=90mm]{PropBias.jpeg}
	%		\caption{Bland-Altman plot indicating the presence of proportional bias.}\label{PropBias}
	%	\end{center}
	%\end{figure}
	
	%\begin{figure}[h!]
	%	\begin{center}
	%		\includegraphics[width=125mm]{BAOutliers.jpeg}
	%		\caption{Bland-Altman plot indicating the presence of potential outliers.}\label{Outliers}
	%	\end{center}
	%\end{figure}
	
	\newpage
	
	
	The Bland-Altman plot also can be used to identify outliers. An
	outlier is an observation that is conspicuously different from the
	rest of the data that it arouses suspicion that it occurs due to a
	mechanism, or conditions, different to that of the rest of the
	observations. \citet*{BA99} do not recommend excluding outliers from analyzes,
	but remark that recalculation of the inter-method bias estimate,
	and further calculations based upon that estimate, are useful for
	assessing the influence of outliers. The authors remark that `we
	usually find that this method of analysis is not too sensitive to
	one or two large outlying differences'. Figure 1.6 demonstrates how the Bland-Altman
	plot can be used to visually inspect the presence of potential
	outliers.
	
	As a complement to the Bland-Altman plot, \citet{Bartko} proposes
	the use of a bivariate confidence ellipse, constructed for a
	predetermined level. \citet{AltmanEllipse} provides the relevant calculations for the
	ellipse. This ellipse is intended as a visual
	guidelines for the scatter plot, for detecting outliers and to
	assess the within- and between-subject variances.
	
	The minor axis relates to the between subject variability, whereas
	the major axis relates to the error mean square, with the ellipse
	depicting the size of both relative to each other.
	Consequently Bartko's ellipse provides a visual aid to determining the
	relationship between variances. If $\mbox{var}(a)$ is greater than $\mbox{var}(d)$, the orientation of the ellipse is horizontal. Conversely if $\mbox{var}(a)$ is less than $\mbox{var}(d)$, the orientation of the ellipse is vertical.
	
	
	%(Furthermore \citet{Bartko}
	%proposes formal testing procedures, that shall be discussed in due
	%course.)
	
	The Bland-Altman plot for the Grubbs data, complemented by Bartko's ellipse, is depicted in Figure 1.7.
	The fourth observation is shown to be outside the bounds of the ellipse, indicating that it is a potential outlier.
	
	
	%\begin{figure}[h!]
	%	% Requires \usepackage{graphicx}
	%	\includegraphics[width=130mm]{GrubbsBartko.jpeg}
	%	\caption{Bartko's Ellipse For Grubbs' Data.}\label{GrubbsBartko}
	%\end{figure}
	
	The limitations of using bivariate approaches to outlier detection
	in the Bland-Altman plot can demonstrated using Bartko's ellipse.
	A covariate is added to the `F vs C' comparison that has a
	difference value equal to the inter-method bias, and an average
	value that markedly deviates from the rest of the average values
	in the comparison, i.e. 786. Table 1.8 depicts a $95\%$ confidence
	ellipse for this manipulated data set. By inspection of the
	confidence interval, a conclusion would be reached that this extra
	covariate is an outlier, in spite of the fact that this
	observation is wholly consistent with the conclusion of the
	Bland-Altman plot.
	
	%\begin{figure}[h!]
	%	% Requires \usepackage{graphicx}
	%	\includegraphics[width=130mm]{GrubbsBartko2.jpeg}
	%	\caption{Bartko's Ellipse For Grubbs' Data, with an extra covariate.}\label{GrubbsBartko2}
	%\end{figure}
	
	
	Importantly, outlier classification must be informed by the logic of the
	data's formulation. In the Bland-Altman plot, the horizontal displacement of any
	observation is supported by two independent measurements. Any
	observation should not be considered an outlier on the basis of a
	noticeable horizontal displacement from the main cluster, as in
	the case with the extra covariate. Conversely, the fourth
	observation, from the original data set, should be considered an
	outlier, as it has a noticeable vertical displacement from the
	rest of the observations.
	
	%Grubbs' test is a statistical test used for detecting outliers in a
	%univariate data set that is assumed to be normally distributed.
	
	%\citet{Grubbs} defined an outlier as a co-variate that appears to
	%deviate markedly from other members of the sample in which it
	%occurs.
	
	In classifying whether a observation from a univariate data set is
	an outlier, many formal tests are available, such as the Grubbs test for outliers. In assessing
	whether a covariate in a Bland-Altman plot is an outlier, this
	test is useful when applied to the case-wise difference values treated as a
	univariate data set. The null hypothesis of the Grubbs test procedure is the absence
	of any outliers in the data set. Conversely, the alternative hypotheses is that there is at least one outlier
	present.
	
	The test statistic for the Grubbs test ($G$) is the largest
	absolute deviation from the sample mean divided by the standard
	deviation of the differences,
	\[
	G =  \displaystyle\max_{i=1,\ldots, n}\frac{\left \vert d_i -
		\bar{d}\right\vert}{S_{d}}.
	\]
	
	For the `F vs C' comparison it is the fourth observation gives
	rise to the test statistic, $G = 3.64$. The critical value is
	calculated using Student's $t$ distribution and the sample size,
	\[
	U = \frac{n-1}{\sqrt{n}} \sqrt{\frac{t_{\alpha/(2n),n-2}^2}{n - 2
			+ t_{\alpha/(2n),n-2}^2}}.
	\]
	For this test $U = 0.75$. The conclusion of this test is that the fourth observation in the `F vs C' comparison is an outlier, with $p-$value = 0.003, according with the previous result using Bartko's ellipse.
	
	\newpage
	


	\section{Adverse features}
	
	Estimates for inter-method bias and variance of differences are only meaningful if there is uniform inter-bias and variability throughout the range of measurements. Fulfilment of these assumptions can be checked by visual inspection of the plot.The prototype Bland-Altman plots depicted in Figures 1.4, 1.5 and 1.6 are derived from simulated data, for the purpose of demonstrating how the plot would inform an analyst of features that would adversely affect use of the recommended approach.
	
	Figure 1.4 demonstrates how the Bland-Altman plot would indicate
	increasing variance of differences over the measurement range.
	Fitted regression lines, for both the upper and lower half of the
	plot, has been added to indicate the trend. Figure 1.5 is an
	example of cases where the inter-method bias changes over the
	measurement range. This is known as proportional bias, and is
	defined by \citet{ludbrook97} as meaning that `one method gives
	values that are higher (or lower) than those from the other by an
	amount that is proportional to the level of the measured variable'. In both Figures 1.4 and 1.5, the assumptions necessary
	for further analysis using the limits of agreement are violated.
	
	Application of regression techniques to the Bland-Altman plot, and
	subsequent formal testing for the constant variability of
	differences is informative. The data set may be divided into two
	subsets, containing the observations wherein the difference values
	are less than and greater than the inter-method bias respectively.
	For both of these fits, hypothesis tests for the respective slopes
	can be performed. While both tests could be considered separately,
	multiple comparison procedures, such as the Benjamini-Hochberg
	\citep{BH} test, are advisable.
	
	\begin{figure}[h!]
		\begin{center}
			\includegraphics[height=90mm]{images/BAFanEffect.jpeg}
			\caption{Bland-Altman plot demonstrating the increase of variance over the range.}\label{BAFanEffect}
		\end{center}
	\end{figure}
	
	\begin{figure}[h!]
		\begin{center}
			\includegraphics[height=90mm]{images/PropBias.jpeg}
			\caption{Bland-Altman plot indicating the presence of proportional bias.}\label{PropBias}
		\end{center}
	\end{figure}
	
	\begin{figure}[h!]
		\begin{center}
			\includegraphics[width=125mm]{images/BAOutliers.jpeg}
			\caption{Bland-Altman plot indicating the presence of potential outliers.}\label{Outliers}
		\end{center}
	\end{figure}
	
	\newpage
	
	
	The Bland-Altman plot also can be used to identify outliers. An
	outlier is an observation that is conspicuously different from the
	rest of the data that it arouses suspicion that it occurs due to a
	mechanism, or conditions, different to that of the rest of the
	observations. \citet*{BA99} do not recommend excluding outliers from analyses,
	but remark that recalculation of the inter-method bias estimate,
	and further calculations based upon that estimate, are useful for
	assessing the influence of outliers. The authors remark that `we
	usually find that this method of analysis is not too sensitive to
	one or two large outlying differences'. Figure 1.6 demonstrates how the Bland-Altman
	plot can be used to visually inspect the presence of potential
	outliers.
	
	As a complement to the Bland-Altman plot, \citet{Bartko} proposes
	the use of a bivariate confidence ellipse, constructed for a
	predetermined level. \citet{AltmanEllipse} provides the relevant calculations for the
	ellipse. This ellipse is intended as a visual
	guidelines for the scatter plot, for detecting outliers and to
	assess the within- and between-subject variances.
	
	The minor axis relates to the between subject variability, whereas
	the major axis relates to the error mean square, with the ellipse
	depicting the size of both relative to each other.
	Consequently Bartko's ellipse provides a visual aid to determining the
	relationship between variances. If $\mbox{var}(a)$ is greater than $\mbox{var}(d)$, the orientation of the ellipse is horizontal. Conversely if $\mbox{var}(a)$ is less than $\mbox{var}(d)$, the orientation of the ellipse is vertical.
	
	
	%(Furthermore \citet{Bartko}
	%proposes formal testing procedures, that shall be discussed in due
	%course.)
	
	The Bland-Altman plot for the Grubbs data, complemented by Bartko's ellipse, is depicted in Figure 1.7.
	The fourth observation is shown to be outside the bounds of the ellipse, indicating that it is a potential outlier.
	
	
	\begin{figure}[h!]
		% Requires \usepackage{graphicx}
		\includegraphics[width=130mm]{images/GrubbsBartko.jpeg}
		\caption{Bartko's Ellipse for Grubbs' data.}\label{GrubbsBartko}
	\end{figure}
	
	The limitations of using bivariate approaches to outlier detection
	in the Bland-Altman plot can demonstrated using Bartko's ellipse.
	A covariate is added to the `F vs C' comparison that has a
	difference value equal to the inter-method bias, and an average
	value that markedly deviates from the rest of the average values
	in the comparison, i.e. 786. Table 1.8 depicts a $95\%$ confidence
	ellipse for this manipulated data set. By inspection of the
	confidence interval, we would conclude that this extra
	covariate is an outlier, in spite of the fact that this
	observation is very close to the inter-method bias as determined by this approach.
	
	\begin{figure}[h!]
		% Requires \usepackage{graphicx}
		\includegraphics[width=130mm]{images/GrubbsBartko2.jpeg}
		\caption{Bartko's Ellipse for Grubbs' data, with an extra covariate.}\label{GrubbsBartko2}
	\end{figure}
	
	
	Importantly, outlier classification must be informed by the logic of the
	mechanism that produces the data. In the Bland-Altman plot, the horizontal displacement (i.e. the average) of any
	observation is supported by two separate measurements. Any
	observation should not be considered an outlier on the basis of a
	noticeable horizontal displacement from the main cluster, as in
	the case with the extra covariate. Conversely, the fourth
	observation, from the original data set, should be considered an
	outlier, as it has a noticeable vertical displacement from the
	rest of the observations.
	
	%Grubbs' test is a statistical test used for detecting outliers in a
	%univariate data set that is assumed to be normally distributed.
	
	%\citet{Grubbs} defined an outlier as a co-variate that appears to
	%deviate markedly from other members of the sample in which it
	%occurs.
	
	In classifying whether a observation from a univariate data set is
	an outlier, many formal tests are available, such as the Grubbs test for outliers. In assessing
	whether a covariate in a Bland-Altman plot is an outlier, this
	test is useful when applied to the case-wise difference values treated as a
	univariate data set. The null hypothesis of the Grubbs test procedure is the absence
	of any outliers in the data set. Conversely, the alternative hypotheses is that there is at least one outlier
	present.
	
	The test statistic for the Grubbs test ($G$) is the largest
	absolute deviation from the sample mean divided by the standard
	deviation of the differences,
	\begin{equation}
	G =  \displaystyle\max_{i=1,\ldots, n}\frac{\left \vert d_i -
		\bar{d}\right\vert}{S_{d}}.
	\end{equation}
	
	For the `F vs C' comparison it is the fourth observation gives
	rise to the test statistic, $G = 3.64$. The critical value is
	calculated using Student's $t$ distribution and the sample size,
	\[
	U = \frac{n-1}{\sqrt{n}} \sqrt{\frac{t_{\alpha/(2n),n-2}^2}{n - 2
			+ t_{\alpha/(2n),n-2}^2}}.
	\]
	For this test $U = 0.75$. The conclusion of this test is that the fourth observation in the `F vs C' comparison is an outlier, with $p-$value = 0.003, in accordance with the previous result of Bartko's ellipse.
	

	\section{Agreement} Bland and Altman (1986) defined perfect
	agreement as the case where all of the pairs of rater data lie
	along the line of equality, where the line of equality is defined
	as the $45$ degree line passing through the origin(i.e. the $X=Y$
	line).
	
	Bland and Altman (1986)expressed this in the terms \emph{we want
		to know by how much the new method is likely to differ from the
		old; if this is not enough to cause problems in clinical
		interpretation we can replace the old method by the new or use the
		two interchangeably. How far apart measurements can be without
		causing difficulties will be a question of judgment. Ideally, it
		should be defined in advance to help in the interpretation of the
		method comparisonand to choose the sample size .}
	%----------------------------------------------------------------------------%
	\section{Bias}
	Bland and Altman define bias a \emph{a consistent tendency for one
		method to exceed the other} and propose estimating its value
	by determining the mean of the differences. The variation about
	this mean shall be estimated by the  standard deviation of the
	differences. Bland and Altman remark that these estimates are based on the
	assumption that bias and variability are constant throughout the
	range of measures.
	%----------------------------------------------------------------------------%




	\section{scatter plots} The authors advise the
	use of scatter plots to identify outliers, and to determine if
	there is curvilinearity present. In the region of linearity
	,simple linear regression may yield results of interest.
	
	\section{Effect of Outliers} Another argument against
	the use of model I regression is based on outliers. Outliers can
	adversely influence the fitting of a regression model. Cornbleet
	and Cochrane compare a regression model influenced by an outlier
	with a model for the same data set, with the outlier excluded from
	the data set. A demonstration of the effect of outliers was made
	in Bland Altman's 1986 paper. However they discourage the
	exclusion of outliers.
	
	%----------------------------------------------------------------------------%

	\section{Precision of Limits of Agreement}
	The limits of agreement are estimates derived from the sample
	studied, and will differ from values relevant to the whole
	population. A different sample would give different limits of
	agreement. \citet*{BA86} advance a formulation for confidence
	intervals of the inter-method bias and the limits of agreement.
	These calculations employ quantiles of the `t' distribution with
	$n -1$ degrees of freedom.
	
	%This page also shows the standard deviation (SD) of the
	%differences between the two assay methods. The SD value is used to
	%calculate the limits of agreement, computed as the mean bias plus
	%or minus 1.96 times its SD.
	%----------------------------------------------------------------------------%

	\section{Variations of the Bland-Altman Plot} Referring to the
	assumption that bias and variability are constant across the range
	of measurements, \citet{BA99} address the case where there is an
	increase in variability as the magnitude increases. They remark
	that it is possible to ignore the issue altogether, but the limits
	of agreement would wider apart than necessary when just lower
	magnitude measurements are considered. Conversely the limits would
	be too narrow should only higher magnitude measurements be used.
	To address the issue, they propose the logarithmic transformation
	of the data. The plot is then formulated as the difference of
	paired log values against their mean. Bland and Altman acknowledge
	that this is not easy to interpret, and may not be suitable in
	all cases.
	
	\citet{BA99} offers two variations of the Bland-Altman plot that
	are intended to overcome potential problems that the conventional
	plot would inappropriate for. The first variation is a plot of
	case-wise differences as percentage of averages, and is
	appropriate when there is an increase in variability of the
	differences as the magnitude increases. The second variation is a
	plot of case-wise ratios as percentage of averages. This will
	remove the need for $log$ transformation. This approach is useful
	when there is an increase in variability of the differences as the
	magnitude of the measurement increases. \citet{Eksborg} proposed
	such a ratio plot, independently of Bland and Altman.
	\citet{Dewitte} commented on the reception of this article by
	saying `Strange to say,this report has been overlooked'.

	
	% When selecting this option the differences will be expressed as
	% percentage of the averages. This option is useful when there is an
	% increase in variability of the differences as the magnitude of the
	% measurement increases.
	
	
	
	
	% Plot ratios When this option is selected then the ratios of the
	% measurements will be plotted instead of the differences (avoiding
	% the need for log transformation). This option as well is useful
	% when there is an increase in variability of the differences as the
	% magnitude of the measurement increases.

	\section{The Bland Altman Plot - Variations}
	Variations of the Bland Altman plot is the use of ratios, in the
	place of differences.
	\begin{equation}
		D_{i} = X_{i} - Y_{i}   \label{BA01}
	\end{equation}
	Altman and Bland suggest plotting the within subject differences $
	D = X_{1} - X_{2} $ on the ordinate versus the average of $x_{1}$
	and  $x_{2}$ on the abscissa.
		\section{Variants of the Bland-Altman Plot}
		In light of some potential pitfalls associated with the conventional difference plot, a series of alternative formulations for the Bland-Altman approach have been proposed.
		
		Referring to the assumption that bias and variability are constant across the range
		of measurements, \citet{BA99} address the case where there is an increase in variability as the magnitude increases. They remark 	that it is possible to ignore the issue altogether, but the limits of agreement would be wider apart than necessary when just lower magnitude measurements are considered. Conversely the limits would be too narrow should only higher magnitude measurements be used.	To address the issue, they propose the logarithmic transformation of the data. The plot is then formulated as the difference of paired log values against their mean. Bland and Altman acknowledge that this is not easy to interpret, and may not be suitable in all cases.
		%----------------------------------------------------------------------------%


	\section{Prevalence of the Bland-Altman plot}
	%---------------------------------------------%
	
	\citet*{BA86}, which further develops the Bland-Altman methodology,
	was found to be the sixth most cited paper of all time by the
	\citet{BAcite}. \cite{Dewitte} describes the rate at which
	prevalence of the Bland-Altman plot has developed in scientific
	literature. \citet{Dewitte} reviewed the use of Bland-Altman plots
	by examining all articles in the journal `Clinical Chemistry'
	between 1995 and 2001. This study concluded that use of the
	Bland-Altman plot increased over the years, from 8\% in 1995 to
	14\% in 1996, and 31-36\% in 2002.
	
	The Bland-Altman Plot has since become expected, and
	often obligatory, approach for presenting method comparison
	studies in many scientific journals \citep{hollis}. Furthermore
	\citet{BritHypSoc} recommend its use in papers pertaining to
	method comparison studies for the journal of the British
	Hypertension Society.
	

	\section{Bland Altman Plots In Literature}
	\citet{mantha} contains a study the use of Bland Altman plots of
	44 articles in several named journals over a two year period. 42
	articles used Bland Altman's limits of agreement, wit the other
	two used correlation and regression analyses. \citet{mantha}
	remarks that 3 papers, from 42 mention predefined maximum width
	for limits of agreement which would not impair medical care.
	
	The conclusion of \citet{mantha} is that there are several
	inadequacies and inconsistencies in the reporting of results ,and
	that more standardization in the use of Bland Altman plots is
	required. The authors recommend the prior determination of limits
	of agreement before the study is carried out. This contention is
	endorsed by \citet{lin}, which makes a similar recommendation for
	the sample size, noting that\emph{sample sizes required either was
		not mentioned or no rationale for its choice was given}.
	
	\begin{quote}
		In order to avoid the appearance of "data dredging", both the
		sample size and the (limits of agreement) should be specified and
		justified before the actual conduct of the trial. \citep{lin}
	\end{quote}
	
	\citet{Dewitte} remarks that the limits of agreement should be
	compared to a clinically acceptable difference in measurements.
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	%----------------------------------------------------------------------------%
	\section{Alternative Agreement Indices}
	As an alternative to limits of agreement, \citet{lin2002} proposes the use of
	the mean square deviation in assessing agreement. The mean square
	deviation is defined as the expectation of the squared differences
	of two readings. The MSD is usually used for the case of two
	measurement methods $X$ and $Y$, each making one measurement for
	the same subject, and is given by
	\[
	MSDxy = E[(x - y)^2]  = (\mu_{x} - \mu_{y})^2 + (\sigma_{x} -
	\sigma_{y})^2 + 2\sigma_{x}\sigma_{y}(1-\rho_{xy}).
	\]
	
	
	\citet{Barnhart} advises the use of a predetermined upper limit
	for the MSD value, $MSD_{ul}$, to define satisfactory agreement.
	However, a satisfactory upper limit may not be easily
	determinable, thus creating a drawback to this methodology.
	
	
	Alternative indices, proposed by \citet{Barnhart}, are the square root of the MSD and the expected absolute difference (EAD). 
	\[
	EAD = E(|x - y|) = \frac{\sum |x_{i}- y_{i}|}{n}
	\]
	
	
	Both of these indices can be interpreted intuitively, since their units are the same as that of the original measurements. Also they can be compared to the maximum acceptable absolute difference between two methods of measurement $d_{0}$. For the sake of brevity, the EAD will be considered solely.
	
	The EAD can be used to supplement the inter-method bias in an
	initial comparison study, as the EAD is informative as a measure
	of dispersion, is easy to calculate and requires no distributional
	assumptions. A consequence of using absolute differences is that high variances would result in a higher EAD value. 
	
	% latex table generated in R 3.1.1 by xtable 1.7-4 package
	% Mon Feb 23 21:12:33 2015
	% latex table generated in R 3.1.1 by xtable 1.7-4 package
	% Mon Feb 23 21:13:45 2015
	% latex table generated in R 3.1.1 by xtable 1.7-4 package
	% Mon Feb 23 22:10:26 2015
	%\begin{table}[ht]
	%	\centering
	%	\begin{tabular}{r| rrrr}
	%		\hline
	%		\item & X & Y & U & V \\ 
	%		\hline
	%		1 & 101.83 & 102.52 & 98.05 & 99.53 \\ 
	%		2 & 101.68 & 102.69 & 99.17 & 96.53 \\ 
	%		3 & 97.89 & 99.01 & 100.31 & 97.55 \\ 
	%		4 & 98.15 & 99.57 & 100.35 & 96.03 \\ 
	%		5 & 99.94 & 100.85 & 99.51 & 99.00 \\ 
	%		6 & 98.85 & 98.86 & 98.50 & 100.76 \\ 
	%		7 & 99.86 & 97.85 & 100.66 & 99.37 \\ 
	%		8 & 101.57 & 100.21 & 99.66 & 108.87 \\ 
	%		9 & 100.12 & 99.85 & 99.70 & 105.16 \\ 
	%		10 & 99.49 & 98.77 & 101.55 & 94.31 \\ 
	%		\hline
	%	\end{tabular}
	%\end{table}
	
	
	
	
	\begin{table}[ht]
		\centering
		\begin{tabular}{|c|c|c|c|c|}
			\hline
			& U & V & $U-V$ & $|U-V|$ \\ 
			\hline
			1 & 98.05 & 99.53 & -1.49 & 1.49 \\ 
			2 & 99.17 & 96.53 & 2.64 & 2.64 \\ 
			3 & 100.31 & 97.55 & 2.75 & 2.75 \\ 
			4 & 100.35 & 96.03 & 4.32 & 4.32 \\ 
			5 & 99.51 & 99.00 & 0.51 & 0.51 \\ 
			6 & 98.50 & 100.76 & -2.26 & 2.26 \\ 
			7 & 100.66 & 99.37 & 1.29 & 1.29 \\ 
			8 & 99.66 & 108.87 & -9.21 & 9.21 \\ 
			9 & 99.70 & 105.16 & -5.45 & 5.45 \\ 
			10 & 101.55 & 94.31 & 7.24 & 7.24 \\ 
			\hline
		\end{tabular}
		\caption{Example data set}
		\label{EADdata}
	\end{table}
	
	To illustrate the use of EAD, consider table ~\ref{EADdata}. The inter-method bias is 0.03, which is quite close to zero, which is desirable in the context of agreement. However, an identity plot would indicate very poor agreement, as the points are noticeably distant from the line of equality.
	\begin{figure}
		\centering
		\includegraphics[width=0.7\linewidth]{EAD-UV}
		\caption{Identity Plot for example data}
		\label{fig:EADidentity}
	\end{figure}
	
	The limits of agreement are $[-9.61, 9.68]$, a wide interval for this data. As with the identity plot, this would indicate lack of agreement. As with inter-method bias, an EAD value close to zero is desirable. However, from table ~\ref{EADdata}, the EAD can be computed as 3.71. The Bland-Altman plot remains a useful part of the analysis. In \ref{fig:EAD1}, it is clear there is a systematic decrease in differences across the range of measurements.
	\begin{figure}
		\centering
		\includegraphics[width=0.7\linewidth]{images/EAD1}
		\caption{Bland-Altman Plot for UV comparison}
		\label{fig:EAD1}
	\end{figure}
	
	\citet{Barnhart} remarks that a comparison of EAD and MSD , using
	simulation studies, would be interesting, while further adding
	that `\textit{It will be of interest to investigate the benefits of these
		possible new unscaled agreement indices}'. For the Grubbs' `F vs C' and `F vs T' comparisons, the inter-method bias, difference variances, limits of agreement and EADs are shown
	in Table 1.5. The corresponding Bland-Altman plots for `F vs C' and `F vs T' comparisons were depicted previously on Figure 1.3. While the inter-method bias for the `F vs T' comparison is smaller, the EAD penalizes the comparison for having a greater variance of differences. Hence the EAD values for both comparisons are much closer.
	\begin{table}[ht]
		\begin{center}
			\begin{tabular}{|c|c|c|}
				\hline
				& F vs C & F vs T  \\
				\hline
				Inter-method bias & -0.61 & 0.12 \\ \hline
				Difference variance & 0.06 & 0.22  \\ \hline 
				Limits of agreement & (-1.08,	-0.13) & (-0.81,1.04) \\
				EAD & 0.61 & 0.35  \\ \hline 
				\hline
			\end{tabular}
			\caption{Agreement indices for Grubbs' data comparisons.}
		\end{center}
	\end{table}
	
	Further to  \citet{lin2000} and \citet{lin2002}, individual agreement between two measurement methods may be
	assessed using the the coverage probability (CP) criteria or the total deviation index (TDI). If $d_{0}$ is predetermined as the maximum acceptable absolute difference between two methods of measurement, the probability that the absolute difference of two measures being less than $d_{0}$ can be computed. This is known as the coverage probability (CP).
	
	\begin{equation}
	CP = P(|x_{i} - y_{i}| \leq d_{0})
	\end{equation}
	
	If $\pi_{0}$ is set as the predetermined coverage probability, the
	boundary under which the proportion of absolute differences is
	$\pi_{0}$ may be determined. This boundary is known as the `total
	deviation index' (TDI). Hence the TDI is the $100\pi_{0}$
	percentile of the absolute difference of paired observations.
	\section{Alternative agreement indices}
	As an alternative to limits of agreement, \citet{lin2002} proposes the use of
	the mean square deviation is assessing agreement. The mean square
	deviation is defined as the expectation of the squared differences
	of two readings . The MSD is usually used for the case of two
	measurement methods $X$ and $Y$ , each making one measurement for
	the same subject, and is given by
	\[
	MSDxy = E[(x - y)^2]  = (\mu_{x} - \mu_{y})^2 + (\sigma_{x} -
	\sigma_{y})^2 + 2\sigma_{x}\sigma_{y}(1-\rho_{xy}).
	\]
	
	
	\citet{Barnhart} advises the use of a predetermined upper limit
	for the MSD value, $MSD_{ul}$, to define satisfactory agreement.
	However, a satisfactory upper limit may not be properly
	determinable, thus creating a drawback to this methodology.
	
	
	\citet{Barnhart} proposes both the use of the square root of the
	MSD or the expected absolute difference (EAD) as an alternative agreement indices. Both of these indices can be interpreted intuitively, being denominated in the same units of measurements as the original
	measurements. Also they can be compare to the maximum acceptable
	absolute difference between two methods of measurement $d_{0}$.
	\[
	EAD = E(|x - y|) = \frac{\sum |x_{i}- y_{i}|}{n}
	\]
	
	The EAD can be used to supplement the inter-method bias in an
	initial comparison study, as the EAD is informative as a measure
	of dispersion, is easy to calculate and requires no distributional
	assumptions.
	
	\citet{Barnhart} remarks that a comparison of EAD and MSD , using
	simulation studies, would be interesting, while further adding
	that `It will be of interest to investigate the benefits of these
	possible new unscaled agreement indices'. For the Grubbs' `F vs C' and `F vs T' comparisons, the inter-method bias, difference variances, limits of agreement and EADs are shown
	in Table 1.5. The corresponding Bland-Altman plots for `F vs C' and `F vs T' comparisons were depicted previously on Figure 1.3. While the inter-method bias for the `F vs T' comparison is smaller, the EAD penalizes the comparison for having a greater variance of differences. Hence the EAD values for both comparisons are much closer.
	\begin{table}[ht]
		\begin{center}
			\begin{tabular}{|c|c|c|}
				\hline
				& F vs C & F vs T  \\
				\hline
				Inter-method bias & -0.61 & 0.12 3 \\
				Difference variances & 0.06 & 0.22  \\
				Limits of agreement & (-1.08,	-0.13) & (-0.81,1.04) \\
				EAD & 0.61 & 0.35  \\
				\hline
			\end{tabular}
			\caption{Agreement indices for Grubbs' data comparisons.}
		\end{center}
	\end{table}
	
	Further to  \citet{lin2000} and \citet{lin2002}, individual agreement between two measurement methods may be
	assessed using the the coverage probability (CP) criteria or the total deviation index (TDI). If $d_{0}$ is predetermined as the maximum acceptable absolute difference between two methods of measurement, the probability that the absolute difference of two measures being less than $d_{0}$ can be computed. This is known as the coverage probability (CP).
	
	\begin{equation}
	CP = P(|x_{i} - y_{i}| \leq d_{0})
	\end{equation}
	
	If $\pi_{0}$ is set as the predetermined coverage probability, the
	boundary under which the proportion of absolute differences is
	$\pi_{0}$ may be determined. This boundary is known as the `total
	deviation index' (TDI). Hence the TDI is the $100\pi_{0}$
	percentile of the absolute difference of paired observations.
	
	

	\section{Lin's Reproducibility Index} Lin proposes the use of a
	reproducibility index, called the Concordance Correlation
	Coefficent (CCC).While it is not strictly a measure of agreement
	as such, it can form part of an overall method comparision
	methodology.
	\chapter{Improper MCS Techniques}
	
	\section{Inappropriate Methodologies} Use of the Pearson
	Correlation Coefficient , although seemingly intuitive, is not
	appropriate approach to assessing agreement of two methods.
	Arguments against its usage have been made repeatedly in the
	relevant literature. It is possible for two analytical methods to
	be highly correlated, yet have a poor level of agreement.


	\section{Inappropriate assessment of Agreement}
	\section{Paired T tests} This method can be applied to test for
	statistically significant deviations in bias. This method can be
	potentially misused for method comparison studies.
	\\It is a poor measure of agreement when the rater's measurements
	are perpendicular to the line of equality[Hutson et al]. In this
	context, an average difference of zero between the two raters, yet
	the scatter plot displays strong negative correlation.
	

	
	
	%----------------------------------------------------------------------------%

	\section{Paired sample T-test} \citet{Bartko} discusses the use
	of the well known paired sample $t$ test to test for inter-method
	bias; $H: \mu_{D}=0$. The test statistic is distributed a $t$
	random variable with $n-1$ degrees of freedom and is calculated as
	follows;
	
	\begin{equation}
		t^{*} = \bar{D}/ \frac{S_{D}}{\sqrt{n}}
	\end{equation}
	
	where $\bar{D}$ and $S_{D}$ is the average of the differences of
	the $n$ observations.
	\newpage
	\begin{itemize}
		% http://www.jerrydallal.com/LHSP/compare.htm
		\item Paired t tests test only whether the mean responses are the same. Certainly, we want the means to be the same, but this is only a small part of the story. The means can be equal while the (random) differences between measurements can be huge.
		\item The correlation coefficient measures linear agreement--whether the measurements go up-and-down together. Certainly, we want the measures to go up-and-down together, but the correlation coefficient itself is deficient in at least three ways as a measure of agreement.
		The correlation coefficient can be close to 1 (or equal to 1!) even when there is considerable bias between the two methods. For example, if one method gives measurements that are always 10 units higher than the other method, the correlation will be 1 exactly, but the measurements will always be 10 units apart.
		\item The magnitude of the correlation coefficient is affected by the range of subjects/units studied. 
		\item The correlation coefficient can be made smaller by measuring samples that are similar to each other and larger by measuring samples that are very different from each other. The magnitude of the correlation says nothing about the magnitude of the differences between the paired measurements which, when you get right down to it, is all that really matters.
		\item The usual significance test involving a correlation coefficient-- whether the population value is 0--is irrelevant to the comparability problem. What is important is not merely that the correlation coefficient be different from 0. Rather, it should be close to (ideally, equal to) 1!
	\end{itemize}
	\section{Pearson's Correlation Coefficient} It is well known that
	Pearson's correlation coefficient is a measure of the linear
	association between two variables, not the agreement between two
	variables (e.g., see Bland and Altman 1986)..This is a well known
	as a measure of linear association between two
	variables.Nonetheless this is not necessarily the same as
	Agreement. This method is considered wholly inadequate to assess
	agreement because it only evaluates only the association of two
	sets of observations.


	%----------------------------------------------------------------------------%

	
	\newpage
	\section{Inappropriate use of the Correlation Coefficient}
	It is intuitive when dealing with two sets of related data, i.e
	the results of the two raters,  to calculate the correlation
	coefficient (r). Bland and Altman attend to this in their $1999$
	paper.
	
	They present a data set from two sets of meters, and an
	accompanying scatterplot. An hypothesis test on the data set leads
	us to conclude that there is a relationship between both sets of
	meter measurements. The correlation coeffiecient is determined to
	be r =0.94.However, this high correlation does not mean that the
	two methods agree. It is possible to determine from the
	scatterplot that the intercept is not zero, a requirement for
	stating both methods have high agreement. Essentially, should two
	methods have highly correlated results, it does not follow that
	they have high agreement.
	

	
	%----------------------------------------------------------------------------%
	\section*{Intra-class correlation coefficient}
	\begin{itemize}
		\item The intra-class correlation coefficient has a name guaranteed to cause the eyes to glaze over and shut the mouth of anyone who isn't an analyst. The ICC, which takes on values between 0 and 1, is based on analysis of variance techniques. It is close to 1 when the differences between paired measurements is very small compared to the differences between subjects. Of these three procedures--t test, correlation coefficient, intra-class correlation coefficient--the ICC is best because it can be large only if there is no bias and the paired measurements are in good agreement, but it suffers from the same faults ii and iii as ordinary correlation coefficients. The magnitude of the ICC can be manipulated by the choice of samples to split and says nothing about the magnitude of the paired differences.
	\end{itemize}
	\newpage
	\section*{Regression Methods}
	\begin{itemize}
		\item Regression analysis is typically misused by regressing one measurement on the other and declare them equivalent if and only if the confidence interval for the regression coefficient includes 1. Some simple mathematics shows that if the measurements are comparable, the population value of the regression coefficient will be equal to the correlation coefficient between the two methods. 
		The population correlation coefficient may be close to 1, but is never 1 in practice. Thus, the only things that can be indicated by the presence of 1 in the confidence interval for the regression coefficient is (1) that the measurements are comparable but there weren't enough observations to distinguish between 1 and the population regression coefficient, or (2) the population regression coefficient is 1 and therefore, the measurements aren't comparable.
		
		\item There is a line whose slope will be 1 if the measurements are comparable. It is known as a structural equation and is the method advanced by Kelly (1985). Altman and Bland (1987) criticize it for a reason that should come as no surprise: Knowing the data are consistent with a structural equation with a slope of 1 says something about the absence of bias but *nothing* about the variability about Y = X (the difference between the measurements), which, as has already been stated, is all that really matters.
	\end{itemize}
	%-----------------------------------------------------------------------------------------------------%
	%% TAM

	\section{Variations and Alternative Graphical Methods}
	In this section, we will look at some variations and enhancements of the Bland-Altman plot, as well as some alternative graphcial techniques. Strictly speaking, the Identity Plot is advised by Bland and Altman as a prior analysis to the Bland-Alman plot, and therefore is neither a variant nor an alternative approach. However it is worth mentioning, as it is a simple, powerful and elegant technique that is often overlooked in method comparison studies. The identity plot is a simple scatter-plot approach of measurements for both methods on either axis, with the line of equality (the $X=Y$ line, i.e. the 45 degree line through the origin). This plot can gives the analyst a cursory examination of how well the measurement methods agree. In the case of good agreement, the covariates of the plot accord closely with the line of equality.
	

	
	\section*{Bland and Altman's Percentage and Ratio Plots}
	%------------------------------------------------------------- %
	\citet{BA99} offer two variations of the Bland-Altman plot intended to overcome situations where the conventional plot is inappropriate. The first variation is a plot of casewise differences as percentage of averages, and is appropriate when the variability of the differences increase as the
	magnitude increases. 
	
	%------------------------------------------------------------- %
	% % RATIO / EKSBORG
	The second variation is a plot of casewise ratios as percentage of averages. This will remove the need for
	logarithmic transformation. This approach is useful when there is an increase in variability of the differences as the magnitude of the measurement increases. \citet{Eksborg} proposed such a ratio plot,
	independently of Bland and Altman. \citet{Dewitte} commented on
	the reception of this article by saying `\textit{Strange to say, this 
		report has been overlooked}'.
	
	
	%	%----------------------------------------------------------------%
	%	\section{Dewitte et al }
	%	\begin{quote}When the standard deviation increases with concentration, Bland and Altman recommend a logarithmic y scale, whereas others propose a percent y scale (Pollock et al, 2002). Although generally there is not much difference in effect between using percentages and using a log transformation of the data, we prefer the percent plot (except when data extend over several orders of magnitude) because numbers can be read directly from the plot without the need for back-transformation.
	%	\end{quote}
	%	
	%	\begin{verbatim}
	%	absolute - small range
	%	percentage - medium range
	%	log scale - large range
	%	\end{verbatim}
	%==================================================== %
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	

	\section{Survival-Agreement Plot}
	A graphical technique for method comparison studies, that is entirely different to the Bland-Altman plot, was proposed by \citet{luiz}. This approach, known as the survival-agreement plot, is used to determine the degree of agreement using the Kaplan-Meier method, a well known graphical technique in the area of Survival Analysis. Furthermore \citet{luiz} propose that commonly used survival analysis techniques should complement this method,\textit{ providing a new analytical insight
		for agreement}. Two survival?agreement plots are used to detect the bias between to measurements of the same variable. The presence of inter-method bias is tested with the log-rank test, and its magnitude with Cox regression.
	
	%% TOLERANCE - REWRITE THIS
	
	The degree of agreement (or disagreement) of a measure is expressed as a function of several limits of tolerance, using the Kaplan-Meier method, where the failures occur exactly at absolute values of the differences between the two methods of measurement. 
	
	According to Luiz et al, the survival-agreement plot is a step function of a typical survival analysis without censored data, where the Y axis represents the proportion of discordant cases. This is equivalent to a step function where the X axis represents the absolute  observed differences and the Y axis is the proportion of the cases with at least the observed 
	difference ($x_i$). 
	
	% % PREVALENCE
	% % Implementation
	
	
	%============================================================================================================ %
	
	
	
	
	% MCS Mountain Plot Notebook
	
	\section{Mountain Plot} Krouwer and Monti have proposed a folded empirical cumulative distribution plot, otherwise known as a Mountain plot.
	
	They argue that it is suitable for detecting large, infrequent errors. This is a non-parametric method that can be used as a complement with the Bland Altman plot.  Mountain plots are created by computing a percentile
	for each ranked difference between a new method and a reference method. (Folded plots are so called because of the following transformation is performed for all percentiles above 50: percentile = 100 - percentile.) These percentiles are then plotted against the differences between the two methods.
	
	Krouwer and Monti argue that the mountain plot offers some following advantages. It is easier to find the central $95\%$ of the data, even when the data are not normally distributed. Also, comparison on different distributions can be performed with ease.
	
	
	
	\section{Replicate Measurements}
	
	Thus far, the formulation for comparison of two measurement
	methods is based on one measurement by each method per subject. Should there be two or more measurements by each
	method, these measurements are known as `replicate measurements'.
	\citet{BXC2008} recommends the use of replicate measurements, but
	acknowledges the additional computational complexity.
	
	\citet*{BA86} address this situation via two different
	approaches. The premise of the first approach is that replicate
	measurements can be treated as independent measurements. The
	second approach is based upon using the mean of the each group of
	replicates as one single representative value. 
	
	%\section{Mean of Replicates Limits of Agreement}
	
	Although either approach may be used to estimate the inter-method bias, removal of the effects of replicate
	measurements error leads to the underestimation of the
	standard deviation of the differences.
	\citet*{BA86} propose a correction for this.
	% % STATE WHAT THIS CORRECTION IS
	
	\citet{BXC2008} take issue with the limits of agreement based on
	mean values of replicate measurements, since these must be interpreted as prediction
	limits for the difference between means of repeated measurements by
	both methods, rather than the difference of individual measurements.
	\citet{BXC2008} demonstrates how the limits of agreement
	calculated using the mean of replicates are `much too narrow as
	prediction limits for differences between future single
	measurements'. This paper also comments that, while treating the
	replicate measurements as independent will cause a downward bias
	on the limits of agreement calculation, this method is preferable
	to the `mean of replicates' approach.
	
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\newpage
	\section{Formal Models and Tests}
	While the Bland-Altman plot is useful for inspection of data, \citet{Kinsella} notes the lack of formal testing offered by
	this methodology. Furthermore, \citet{Kinsella} formulates a model for
	single measurement observations as a
	linear mixed effects model, i.e. a model that additively combines
	fixed effects and random effects:
	\[
	Y_{ij} =\quad \mu + \beta_{j} + u_{i} + \epsilon_{ij} \qquad i = 1,\dots,n
	\qquad j=1,2\]
	
	The true value of the measurement is represented by $\mu$ while the fixed effect due to method $j$ is $\beta_{j}$.
	For simplicity these terms can be combined into single terms; $\mu_{1} = \mu+ \beta_{1}$ and $\mu_{2} = \mu + \beta_{2}$. The inter-method bias is the difference of the two fixed effect terms, $\beta_{1}-\beta_{2}$. Each individual is assumed to give rise to a random error, represented by $u_{i}$. This random effects term is assumed to have mean zero and be normally distributed with variance $\sigma^2$. There is assumed to be an attendant error for each measurement on each individual, denoted $\epsilon_{ij}$. This is also assumed to have mean zero. The variance of measurement error for both methods are not assumed to be identical for both methods variance,  hence it is denoted $\sigma^2_{j}$. The set of observations ($x_{i},y_{i}$) by methods $X$ and $Y$ are assumed to follow a bivariate normal distribution with expected values $E(x_{i})= \mu_{i}$ and $E(y_{i})= \tau_{i}$ respectively. The variance covariance of the observations $\boldsymbol{\Sigma}$ is given by
	
	\[
	\boldsymbol{\Sigma} = \left[
	\begin{array}{cc}
	\sigma^{2} + \sigma^{2}_{1} & \sigma^{2} \\
	\sigma^{2} & \sigma^{2} + \sigma^{2}_{2} \\
	\end{array}
	\right]
	\] 
	% The inter-method bias is the difference of the two fixed effect terms, $\beta_{1}-\beta_{2}$.
	
	\citet{Kinsella} demonstrates the estimation of the variance terms and relative precisions relevant to a method comparison study, with attendant confidence intervals for both. The measurement model introduced by \citet{Grubbs48,Grubbs73} provides a formal procedure for estimating the variances $\sigma^2$, $\sigma^2_{1}$ and $\sigma^2_{2}$. \citet{Grubbs48} offers estimates, commonly known as Grubbs estimators, for the various variance components. These estimates are maximum likelihood estimates, which shall be revisited in due course.
	\begin{eqnarray*}
		\hat{\sigma^{2}} = \sum{\frac{(x_{i}-\bar{x})(y_{i}-\bar{y})}{n-1}} = Sxy\\
		\hat{\sigma^{2}_{1}} = \sum{\frac{(x_{i}-\bar{x})^{2}}{n-1}} =S^{2}x - Sxy  \\
		\hat{\sigma^{2}_{2}} =
		\sum{\frac{(y_{i}-\bar{y})^{2}}{n-1}} = S^{2}y - Sxy
	\end{eqnarray*}
	
	% The standard error of these variance estimates are:
	% \begin{eqnarray}
	% \mbox{var}(\sigma^{2}_{1}) = \frac{2\sigma^{4}_{1}}{n-1} +
	% \frac{\sigma^2_{S}\sigma^2_{1}+\sigma^2_{S}\sigma^2_{2}+\sigma^2_{1}\sigma^2_{2}
	% }{n-1}\\
	% \mbox{var}(\sigma^{2}_{2}) =\quad \frac{2\sigma^{4}_{2}}{n-1} +
	% \frac{\sigma^2_{S}\sigma^2_{1}+\sigma^2_{S}\sigma^2_{2}+\sigma^2_{1}\sigma^2_{2}
	% }{n-1}\nonumber
	% \end{eqnarray}
	
	\citet{Thompson} defines $\Delta_j = \sigma^2 / \sigma^2_j, j=1,2$, to be a measure of the
	relative precision of the measurement methods, and demonstrates how to make statistical inferences about $\Delta_{j}$.
	Based on the following identities,
	\begin{eqnarray*}
		C_{x}&=&(n-1)S^2_{x},\nonumber\\
		C_{xy}&=&(n-1)S_{xy},\nonumber\\
		C_{y}&=&(n-1)S^2_{y},\nonumber\\
		|A| &=& C_{x}\times C_{y} - (C_{xy})^2,\nonumber
	\end{eqnarray*}
	\noindent the confidence interval limits of $\Delta_{1}$ are
	
	\begin{eqnarray}
		\frac{C_{xy}-
			t(\frac{|A|}{n-2}))^{\frac{1}{2}}}{C_{x}-C_{xy}+
			t(\frac{|A|}{n-2}))^{\frac{1}{2}}} <
		\Delta_{1} < \frac{C_{xy}+
			t(\frac{|A|}{n-2}))^{\frac{1}{2}}}{C_{x}-C_{xy}-
			t(\frac{|A|}{n-1}))^{\frac{1}{2}}} \nonumber
	\end{eqnarray}
	\\ The value $t$ is the $100(1-\alpha/2)\%$ upper quantile of
	Student's $t$ distribution with $n-2$ degrees of freedom
	\citep{Kinsella}. The confidence limits for $\Delta_{2}$ are found by substituting $C_{y}$ for $C_{x}$ in (1.2).
	Negative lower limits are replaced by the value $0$.
	
	%For the interval estimates for the variance components,
	%\citet{Thompson} presents three relations that hold simultaneously
	%with probability $1-2\alpha$ where $2\alpha=0.01$ or $0.05$.
	
	%\begin{eqnarray*}
	%|\sigma^2-C_{xy}K| &\leqslant& M(C_{x}C_{y})^{\frac{1}{2}}\\
	%|\sigma^2_{1}-(C_{x}-C_{xy})K|&\leqslant M(C_{x}(C_{x}+C_{y}-2C_{xy}))^{\frac{1}{2}}\nonumber\\
	%|\sigma^2_{2}-(C_{y}-C_{xy})K|&\leqslant
	%M(C_{y}(C_{x}+C_{y}-2C_{xy}))^{\frac{1}{2}}\nonumber
	%\end{eqnarray*}
	
	%\citet{Thompson} contains tables for $K$ and $M$.
	
	The case-wise differences and means are calculated as $d_{i} =
	x_{i}-y_{i}$ and $a_{i} = (x_{i}+y_{i})/2$  respectively. Both
	$d_{i}$ and $a_{i}$ are assumed to follow a bivariate normal
	distribution with $E(d_{i})= \mu_{d} = \mu_{1} - \mu_{2}$ and
	$E(a_{i})= \mu_{a} = (\mu_{1} + \mu_{2})/2$, and the variance matrix
	$\Sigma_{(a,d)}$ is
	
	\begin{eqnarray}
		\Sigma_{(a,d)}= \left[\begin{matrix}
			\sigma^{2}_{1}+\sigma^{2}_{2}&\frac{1}{2}(\sigma^{2}_{1}-\sigma^{2}_{2})\\
			\frac{1}{2}(\sigma^{2}_{1}-\sigma^{2}_{2})&\sigma^{2}+
			\frac{1}{4}(\sigma^{2}_{1}+\sigma^{2}_{2})
		\end{matrix} \right].
	\end{eqnarray}
	
	\newpage
	\section{Measurement Error Models}
	\textbf{DunnSEME} proposes a measurement error model for use in
	method comparison studies. Consider n pairs of measurements
	$X_{i}$ and $Y_{i}$ for $i=1,2,...n$.
	\begin{equation}
		X_{i} = \tau_{i}+\delta_{i}\\
	\end{equation}
	\begin{equation}
		Y_{i} = \alpha +\beta\tau_{i}+\epsilon_{i} \nonumber
	\end{equation}
	
	In the above formulation is in the form of a linear structural
	relationship, with $\tau_{i}$ and $\beta\tau_{i}$ as the true
	values , and $\delta_{i}$ and $\epsilon_{i}$ as the corresponding
	measurement errors. In the case where the units of measurement are
	the same, then $\beta =1$.
	
	\begin{equation}
		E(X_{i}) = \tau_{i}\\
	\end{equation}
	\begin{equation}
		E(Y_{i}) = \alpha +\beta\tau_{i} \nonumber
	\end{equation}
	\begin{equation}
		E(\delta_{i}) = E(\epsilon_{i}) = 0 \nonumber
	\end{equation}
	
	The value $\alpha$ is the inter-method bias between the two
	methods.
	
	\begin{eqnarray}
		z_0 &=& d = 0 \\
		z_{n+1} &=& z_n^2+c
	\end{eqnarray}
	
	\section{Inappropriate assessment of Agreement}
	\chapter{Formal Testing Procedures}
	\section{Model Formulation and Formal Testing}
	
	\citet{Kinsella} formulates a model for un-replicated observations
	for a method comparison study as a mixed model.
	\begin{eqnarray}
		Y_{ij} =\quad \mu_{j} + S_{i} + \epsilon_{ij} \quad i=1,2...n\quad
		j=1,2\\
		S \sim N(0,\sigma^{2}_{s})\qquad \epsilon_{ij} \sim
		N(0,\sigma^{2}_{j}) \nonumber
	\end{eqnarray}
	
	As with all mixed models, the variance of each observation is the
	sum of all the associated variance components.
	\begin{eqnarray}
		var(Y_{ij}) =\quad \sigma^{2}_{s} + \sigma^{2}_{j} \\
		cov(Y_{i1},Y_{i2})=\quad \sigma^{2}_{s} \nonumber
	\end{eqnarray}
	
	\citet{Grubbs48} offers maximum likelihood estimators, commonly
	known as Grubbs estimators, for the various variance components:
	\begin{eqnarray}
		\hat{\sigma^{2}_{s}} \quad= \sum{\frac{(x_{i}-\bar{x})(y_{i}-\bar{y})}{n-1}}\quad=Sxy\\
		\hat{\sigma^{2}_{1}} \quad= \sum{\frac{(x_{i}-\bar{x})^{2}}{n-1}} \quad=S^{2}x-Sxy \nonumber\\
		\hat{\sigma^{2}_{2}} \quad=
		\sum{\frac{(y_{i}-\bar{y})^{2}}{n-1}}\quad=S^{2}y-Sxy \nonumber
		\nonumber
	\end{eqnarray}
	
	The standard error of these variance estimates are:
	\begin{eqnarray}
		var(\sigma^{2}_{1}) =\quad \frac{2\sigma^{4}_{1}}{n-1} +\quad
		\frac{\sigma^2_{S}\sigma^2_{1}+\sigma^2_{S}\sigma^2_{2}+\sigma^2_{1}\sigma^2_{2}
		}{n-1}\\
		var(\sigma^{2}_{2}) =\quad \frac{2\sigma^{4}_{2}}{n-1} +\quad
		\frac{\sigma^2_{S}\sigma^2_{1}+\sigma^2_{S}\sigma^2_{2}+\sigma^2_{1}\sigma^2_{2}
		}{n-1}\nonumber
	\end{eqnarray}
	
	\citet{Thompson}presents confidence intervals for the relative
	precisions of the measurement methods, $\Delta_{j}=
	\sigma^2_{S}/\sigma^2_{j}$ (where $j=1,2$), as well as the
	variances $\sigma^{2}_{S}, \sigma^{2}_{1}$ and $\sigma^{2}_{2}$.
	
	\begin{eqnarray}
		\Delta_{1} >\quad \frac{C_{xy}-
			t(|A|/n-2))^{\frac{1}{2}}}{C_{x}-C_{xy}+
			t(|A|/n-2))^{\frac{1}{2}}}
	\end{eqnarray}
	where
	
	\begin{eqnarray}
		C_{x}=\quad(n-1)S^2_{x}\nonumber\\
		C_{xy}=\quad(n-1)S_{xy}\nonumber\\
		C_{y}=\quad(n-1)S^2_{y}\nonumber\\
		A=\quad C_{x}\times C_{y} - (C_{xy})^2 \nonumber
	\end{eqnarray}
	
	$t$ is the $100(1-\alpha/2)\%$ quantile of Student's $t$
	distribution with $n-2$ degrees of freedom. $\Delta_{2}$ can be
	found by changing $C_{y}$ for $C_{x}$. A lower confidence limit
	can be found by calculating the square root. This inequality may
	also be used for hypothesis testing.
	
	For the interval estimates for the variance components,
	\citet{Thompson} presents three relations that hold simultaneously
	with probability $1-2\alpha$ where $2\alpha=0.01$ or $0.05$.
	
	\begin{eqnarray}
		|\sigma^2-C_{xy}K|\leqslant M(C_{x}C_{y})^{\frac{1}{2}}\\
		|\sigma^2_{1}-(C_{x}-C_{xy})K|\leqslant M(C_{x}(C_{x}+C_{y}-2C_{xy}))^{\frac{1}{2}}\nonumber\\
		|\sigma^2_{2}-(C_{y}-C_{xy})K|\leqslant
		M(C_{y}(C_{x}+C_{y}-2C_{xy}))^{\frac{1}{2}}\nonumber
	\end{eqnarray}
	
	The case-wise differences and means are $D_{i} = Y_{i1}-Y_{i2}$
	and $A_{i} = (Y_{i1}+Y_{i2})/2$  respectively. Both $D_{i}$ and
	$A_{i}$ follow a bivariate normal distribution with $E(D_{i})=
	\mu_{D} = \mu_{1} - \mu_{2}$ and $E(A_{i})= \mu_{A} = (\mu_{1} +
	\mu_{2})/2$. The variance matrix $\Sigma$ is
	
	\begin{equation}
		\Sigma = \left[\begin{matrix}
			\sigma^{2}_{1}+\sigma^{2}_{2}&\frac{1}{2}(\sigma^{2}_{1}-\sigma^{2}_{2})\\
			\frac{1}{2}(\sigma^{2}_{1}-\sigma^{2}_{2})&\sigma^{2}_{S}+
			\frac{1}{4}(\sigma^{2}_{1}+\sigma^{2}_{2})
		\end{matrix} \right]
	\end{equation}
	
	
	
	
	
	\citet{Kinsella} demonstrates how the Grubbs estimators for the
	error variances can be calculated using the difference values,
	providing a worked example on a data set.
	\begin{eqnarray}
		\hat{\sigma^{2}_{1}}
		\quad=\sum{(y_{i1}-\bar{y{1}})(D_{i}-\bar{D})}\\
		\hat{\sigma^{2}_{2}} \quad=
		\sum{(y_{i2}-\bar{y_{2}})(D_{i}-\bar{D})} \nonumber
	\end{eqnarray}
	
	
	\section{Morgan Pitman}
	
	The test of the hypothesis that the variance of both methods are
	equal is based on the correlation value $\rho_{D,A}$ which is
	evaluated as follows;
	
	\begin{equation}
		\rho(D,A)=\quad\frac{\sigma^{2}_{1}-\sigma^{2}_{2}}{\sqrt{(\sigma^{2}_{1}+\sigma^{2}_{2})(4\sigma^{2}_{S}+\sigma^{2}_{1}+\sigma^{2}_{2})}}
	\end{equation}
	
	The correlation constant takes the value zero if, and only if, the
	two variances are equal. Therefore a test of the hypothesis $H:
	\sigma^{2}_{1}=\sigma^{2}_{2}$ is equivalent to a test of the
	hypothesis $H: \rho(D,A) = 0$. The corresponds to the well-known
	$t$ test for a correlation coefficient with $n-2$ degrees of
	freedom.
	
	\citet{Bartko} describes the Morgan-Pitman test as identical to
	the test of the slope equal to zero in the regression of $Y_{i1}$
	on $Y_{12}$, adding that this result can be shown using
	straightforward algebra.
	
	\section{Bland-Altman correlation test}
	
	The approach proposed by \citet{BA83} is a formal test on the
	Pearson correlation coefficient of case-wise differences and means
	($\rho_{AD}$). According to the authors, this test is equivalent
	to the `Pitman Morgan Test'. For the Grubbs data, the correlation
	coefficient estimate ($r_{AD}$) is 0.2625, with a 95\% confidence
	interval of (-0.366, 0.726) estimated by Fishers `$r$ to $z$'
	transformation \citep*{Cohen}. The null hypothesis ($\rho_{AD}$ =0)
	fail to be rejected. Consequently the null hypothesis of equal
	variances of each method would also fail to be rejected. There has
	no been no further mention of this particular test in
	\citet{BA86}, although \citet{BA99} refers to Spearman's rank
	correlation coefficient. \citet{BA99} comments `we do not see a
	place for methods of analysis based on hypothesis testing'.
	\citet{BA99} also states that consider structural equation models
	to be inappropriate.



	\section{Pitman \& Morgan Test} This test assess the equality
	of population variances. Pitman's test tests for zero correlation
	between the sums and products.
	\\
	Correlation between differences and means is a test statistics for
	the null hypothesis of equal variances given bivariate normality.
	
	\section{Thompson 1963}
	
	
	
	\citet{Thompson} defines $\Delta_{j}$ to be a measure of the
	relative precision of the measurement methods, with $\Delta_{j}=
	\sigma^2_{S}/\sigma^2_{j}$(where $j=1,2$). Confidence intervals
	for $\Delta_{j}$ are also presented.
	
	\begin{eqnarray}
	\Delta_{1} > \frac{C_{xy}-
		t(\frac{|A|}{n-1}))^{\frac{1}{2}}}{C_{x}-C_{xy}+
		t(\frac{|A|}{n-1}))^{\frac{1}{2}}},
	\end{eqnarray}
	where
	
	\begin{eqnarray}
	C_{x}&=&(n-1)S^2_{x},\nonumber\\
	C_{xy}&=&(n-1)S_{xy},\nonumber\\
	C_{y}&=&(n-1)S^2_{y},\nonumber\\
	A &=& C_{x}\times C_{y} - (C_{xy})^2 . \nonumber
	\end{eqnarray}
	
	The value $t$ is the $100(1-\alpha/2)\%$ quantile of Student's $t$
	distribution with $n-2$ degrees of freedom. The ratio $\Delta_{2}$
	can be found by interchanging $C_{y}$ and $C_{x}$. A lower
	confidence limit can be found by calculating the square root. The
	inequality in equation $1.10$ may also be used for hypothesis
	testing.
	
	For the interval estimates for the variance components,
	\citet{Thompson} presents three relations that hold simultaneously
	with probability $1-2\alpha$ where $2\alpha=0.01$ or $0.05$.
	
	
	\begin{eqnarray*}
		|\sigma^2-C_{xy}K| &\leqslant& M(C_{x}C_{y})^{\frac{1}{2}}\\
		|\sigma^2_{1}-(C_{x}-C_{xy})K|&\leqslant M(C_{x}(C_{x}+C_{y}-2C_{xy}))^{\frac{1}{2}}\nonumber\\
		|\sigma^2_{2}-(C_{y}-C_{xy})K|&\leqslant
		M(C_{y}(C_{x}+C_{y}-2C_{xy}))^{\frac{1}{2}}\nonumber
	\end{eqnarray*}
	
	\citet{Thompson} contains tables for $K$ and $M$.
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Bartko's BB
	\citet{BB89} offers a formal simultaneous hypothesis test for the
	mean and variance of two paired data sets. Using simple linear
	regression of the differences of each pair against the sums, a
	line is fitted to the model, with estimates for intercept and
	slope ($\hat{\beta}_{0}$ and $\hat{\beta}_{1}$). The null
	hypothesis of this test is that the mean ($\mu$) and variance
	($\sigma^{2}$) of both data sets are equal if the slope and
	intercept estimates are equal to zero(i.e $\sigma^{2}_{1} =
	\sigma^{2}_{2}$ and $\mu_{1}=\mu_{2}$ if and only if $\beta_{0}=
	\beta_{1}=0$ )
	
	A test statistic is then calculated from the regression analysis
	of variance values \citep{BB89} and is distributed as `F' random
	variable. The degrees of freedom thereof are $\nu_{1}=2$ and
	$\nu_{1}=n-2$ (where n is the number of pairs). The critical value
	is chosen for $\alpha\%$ significance with those same degrees of
	freedom. \citet{Bartko} amends this methodology for use in method
	comparison studies, using the averages of the pairs, as opposed to
	the sums, and their differences. This approach can facilitate
	simultaneous usage of test with the Bland-Altman methodology.
	Bartko's test statistic take the form:
	\begin{equation} F.test = \frac{(\Sigma d^{2})-SSReg}{2MSReg}
	\end{equation}
	% latex table generated in R 2.6.0 by xtable 1.5-5 package
	% Mon Aug 31 15:53:51 2009
	\begin{table}[ht]
		\begin{center}
			\begin{tabular}{lrrrrr}
				\hline
				& Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
				\hline
				Averages & 1 & 0.04 & 0.04 & 0.74 & 0.4097 \\
				Residuals & 10 & 0.60 & 0.06 &  &  \\
				\hline
			\end{tabular}
			\caption{Regression ANOVA of case-wise differences and averages
				for Grubbs Data}
		\end{center}
	\end{table}
	%(calculate using R code $qf(0.95,2,10)$).
	
	For the Grubbs data, $\Sigma d^{2}=5.09 $, $SSReg = 0.60$ and
	$MSreg=0.06$ Therefore the test statistic is $37.42$, with a
	critical value of $4.10$. Hence the means and variance of the
	Fotobalk and Counter chronometers are assumed to be simultaneously
	equal.
	
	Importantly, this methodology determines whether there is both
	inter-method bias and precision present, or alternatively if there
	is neither present. It has previously been demonstrated that there
	is a inter-method bias present, but as this procedure does not
	allow for separate testing, no conclusion can be drawn on the
	comparative precision of both methods.
	


	\section{Formal Testing}
	The Bland Altman plot is a simple tool for inspection of the data,
	but in itself it offers no formal testing procedure in this
	regard. To this end, the approach proposed by \citet{BA83} is a
	formal test on the Pearson correlation coefficient  of casewise
	differences and means ($\rho_{AD}$). According to the authors,
	this test is equivalent to a well established tests for equality
	of variances, known as the `Pitman Morgan Test' \citep{Pitman,
		Morgan}.
	
	For the Grubbs data, the correlation coefficient estimate
	($r_{AD}$) is 0.2625, with a 95\% confidence interval of (-0.366,
	0.726) estimated by Fishers 'r to z' transformation \citep{Cohen}.
	The null hypothesis ($\rho_{AD}$ =0) would fail to be rejected.
	Consequently the null hypothesis of equal variances of each method
	would also fail to be rejected.
	
	There has no been no further mention of this particular test in
	the subsequent article published by Bland and Altman, although
	\citet{BA99} refers to Spearmans' rank correlation coefficient.
	
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

	\section{Formal Testing}
	The Bland Altman plot is a simple tool for inspection of the data,
	but in itself it offers no formal testing procedure in this
	regard. To this end, the approach proposed by \citet{BA83} is a
	formal test on the Pearson correlation coefficient  of casewise
	differences and means ($\rho_{AD}$). According to the authors,
	this test is equivalent to a well established tests for equality
	of variances, known as the `Pitman Morgan Test' \citep{Pitman,
		Morgan}.
	
	For the Grubbs data, the correlation coefficient estimate
	($r_{AD}$) is 0.2625, with a 95\% confidence interval of (-0.366,
	0.726) estimated by Fishers 'r to z' transformation \citep{Cohen}.
	The null hypothesis ($\rho_{AD}$ =0) would fail to be rejected.
	Consequently the null hypothesis of equal variances of each method
	would also fail to be rejected.
	
	There has no been no further mention of this particular test in
	the subsequent article published by Bland and Altman, although
	\citet{BA99} refers to Spearmans' rank correlation coefficient.
	
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\newpage
	

	\section{Formal Models and Tests}
	The Bland-Altman plot is a simple tool for inspection of data, and
	\citet{Kinsella} comments on the lack of formal testing offered by
	that methodology. \citet{Kinsella} formulates a model for
	single measurement observations for a method comparison study as a
	linear mixed effects model, i.e. model that additively combine
	fixed effects and random effects.
	\[
	Y_{ij} =\quad \mu + \beta_{j} + u_{i} + \epsilon_{ij} \qquad i = 1,\dots,n
	\qquad j=1,2\]
	
	The true value of the measurement is represented by $\mu$ while the fixed effect due to method $j$ is $\beta_{j}$.
	For simplicity these terms can be combined into single terms; $\mu_{1} = \mu+ \beta_{1}$ and $\mu_{2} = \mu + \beta_{2}$. The inter-method bias is the difference of the two fixed effect terms, $\beta_{1}-\beta_{2}$. Each of the $i$ individuals are assumed to give rise to random error, represented by $u_{i}$. This random effects terms is assumed to have mean zero and be normally distributed with variance $\sigma^2$. There is assumed to be an attendant error for each measurement on each individual, denoted $\epsilon_{ij}$. This is also assumed to have mean zero. The variance of measurement error for both methods are not assumed to be identical for both methods variance,  hence it is denoted $\sigma^2_{j}$. The set of observations ($x_{i},y_{i}$) by methods $X$ and $Y$ are assumed to follow the bivariate normal distribution with expected values $E(x_{i})= \mu_{i}$ and $E(x_{i})= \mu_{i}$ respectively. The variance covariance of the observations $\boldsymbol{\Sigma}$ is given by
	
	\[
	\boldsymbol{\Sigma} = \left[
	\begin{array}{cc}
	\sigma^{2} + \sigma^{2}_{1} & \sigma^{2} \\
	\sigma^{2} & \sigma^{2} + \sigma^{2}_{2} \\
	\end{array}
	\right]
	\]
	
	The inter-method bias is the difference of the two fixed effect terms, $\beta_{1}-\beta_{2}$.
	
	\citet{Kinsella} demonstrates the estimation of the variance terms and relative precisions relevant to a method comparison study, with attendant confidence intervals for both. The measurement model introduced by \citet{Grubbs48,Grubbs73} provides a formal procedure for estimate the variances $\sigma^2$,$\sigma^2_{1}$ and $\sigma^2_{2}$ devices. \citet{Grubbs48} offers estimates, commonly known as Grubbs estimators, for the various variance components. These estimates are maximum likelihood estimates, a statistical concept that shall be revisited in due course.
	\begin{eqnarray*}
		\hat{\sigma^{2}} = \sum{\frac{(x_{i}-\bar{x})(y_{i}-\bar{y})}{n-1}} = Sxy\\
		\hat{\sigma^{2}_{1}} = \sum{\frac{(x_{i}-\bar{x})^{2}}{n-1}} =S^{2}x - Sxy  \\
		\hat{\sigma^{2}_{2}} =
		\sum{\frac{(y_{i}-\bar{y})^{2}}{n-1}} = S^{2}y - Sxy
	\end{eqnarray*}
	
	% The standard error of these variance estimates are:
	% \begin{eqnarray}
	% \mbox{var}(\sigma^{2}_{1}) = \frac{2\sigma^{4}_{1}}{n-1} +
	% \frac{\sigma^2_{S}\sigma^2_{1}+\sigma^2_{S}\sigma^2_{2}+\sigma^2_{1}\sigma^2_{2}
	% }{n-1}\\
	% \mbox{var}(\sigma^{2}_{2}) =\quad \frac{2\sigma^{4}_{2}}{n-1} +
	% \frac{\sigma^2_{S}\sigma^2_{1}+\sigma^2_{S}\sigma^2_{2}+\sigma^2_{1}\sigma^2_{2}
	% }{n-1}\nonumber
	% \end{eqnarray}
	
	\citet{Thompson} defines $\Delta_{j}$ to be a measure of the
	relative precision of the measurement methods, with $\Delta_{j}=
	\sigma^2/\sigma^2_{j}$. Thompson also demonstrates how to make statistical inferences about $\Delta_{j}$.
	Based on the following identities,
	\begin{eqnarray*}
		C_{x}&=&(n-1)S^2_{x},\nonumber\\
		C_{xy}&=&(n-1)S_{xy},\nonumber\\
		C_{y}&=&(n-1)S^2_{y},\nonumber\\
		|A| &=& C_{x}\times C_{y} - (C_{xy})^2,\nonumber
	\end{eqnarray*}
	\noindent the confidence interval limits of $\Delta_{1}$ are
	
	\begin{eqnarray}
		\Delta_{1} > \frac{C_{xy}-
			t(\frac{|A|}{n-2}))^{\frac{1}{2}}}{C_{x}-C_{xy}+
			t(\frac{|A|}{n-2}))^{\frac{1}{2}}} \\
		\Delta_{1} > \frac{C_{xy}+
			t(\frac{|A|}{n-2}))^{\frac{1}{2}}}{C_{x}-C_{xy}-
			t(\frac{|A|}{n-1}))^{\frac{1}{2}}} \nonumber
	\end{eqnarray}
	\\ The value $t$ is the $100(1-\alpha/2)\%$ upper quantile of
	Student's $t$ distribution with $n-2$ degrees of freedom
	\citep{Kinsella}. The confidence limits for $\Delta_{2}$ are found by substituting $C_{y}$ for $C_{x}$ in (1.3).
	Negative lower limits are replaced by the value $0$.
	
	%For the interval estimates for the variance components,
	%\citet{Thompson} presents three relations that hold simultaneously
	%with probability $1-2\alpha$ where $2\alpha=0.01$ or $0.05$.
	
	%\begin{eqnarray*}
	%|\sigma^2-C_{xy}K| &\leqslant& M(C_{x}C_{y})^{\frac{1}{2}}\\
	%|\sigma^2_{1}-(C_{x}-C_{xy})K|&\leqslant M(C_{x}(C_{x}+C_{y}-2C_{xy}))^{\frac{1}{2}}\nonumber\\
	%|\sigma^2_{2}-(C_{y}-C_{xy})K|&\leqslant
	%M(C_{y}(C_{x}+C_{y}-2C_{xy}))^{\frac{1}{2}}\nonumber
	%\end{eqnarray*}
	
	%\citet{Thompson} contains tables for $K$ and $M$.
	
	The case-wise differences and means are calculated as $d_{i} =
	x_{i}-y_{i}$ and $a_{i} = (x_{i}+y_{i})/2$  respectively. Both
	$d_{i}$ and $a_{i}$ are assumed to follow a bivariate normal
	distribution with $E(d_{i})= \mu_{d} = \mu_{1} - \mu_{2}$ and
	$E(a_{i})= \mu_{a} = (\mu_{1} + \mu_{2})/2$. The variance matrix
	$\Sigma_{(a,d)}$ is
	
	\begin{eqnarray}
		\Sigma_{(a,d)}= \left[\begin{matrix}
			\sigma^{2}_{1}+\sigma^{2}_{2}&\frac{1}{2}(\sigma^{2}_{1}-\sigma^{2}_{2})\\
			\frac{1}{2}(\sigma^{2}_{1}-\sigma^{2}_{2})&\sigma^{2}+
			\frac{1}{4}(\sigma^{2}_{1}+\sigma^{2}_{2})
		\end{matrix} \right].
	\end{eqnarray}
	
	
	
	\section{Morgan Pitman Testing}
	An early contribution to formal testing in method comparison was
	made by both \citet{morgan} and \citet{pitman}, in separate
	contributions. The basis of this approach is that if the
	distribution of the original measurements is bivariate normal.
	Morgan and Pitman noted that the correlation coefficient depends
	upon the difference $\sigma^{2}_{1}- \sigma^{2}_{2}$, being zero
	if and only if $\sigma^{2}_{1}=\sigma^{2}_{2}$.
	
	The classical Pitman-Morgan test is a hypothesis test for equality
	of the variance of two data sets; $\sigma^{2}_{1} =
	\sigma^{2}_{2}$, based on the correlation value $\rho_{a,d}$ ,and
	is evaluated as follows;
	
	\begin{equation}
	\rho(a,d)=\quad\frac{\sigma^{2}_{1}-\sigma^{2}_{2}}{\sqrt{(\sigma^{2}_{1}+\sigma^{2}_{2})(4\sigma^{2}_{S}+\sigma^{2}_{1}+\sigma^{2}_{2})}}
	\end{equation}
	
	The correlation constant takes the value zero if, and only if, the two variances are equal. Therefore a test of the hypothesis $H: \sigma^{2}_{1}=\sigma^{2}_{2}$ is equivalent to a test of the hypothesis $H: \rho(D,A) = 0$. The corresponds to the well-known
	$t$ test for a correlation coefficient with $n-2$ degrees of freedom. \citet{Bartko} describes the Morgan-Pitman test as identical to
	the test of the slope equal to zero in the regression of $Y_{i1}$ on $Y_{12}$, a result that can be derived using
	straightforward algebra.
	


	
	
	\section{Model Formulation and Formal Testing}
	
	\citet{Kinsella} formulates a model for un-replicated observations
	for a method comparison study as a mixed model.
	\begin{eqnarray}
	Y_{ij} =\quad \mu_{j} + S_{i} + \epsilon_{ij} \quad i=1,2...n\quad
	j=1,2\\
	S \sim N(0,\sigma^{2}_{s})\qquad \epsilon_{ij} \sim
	N(0,\sigma^{2}_{j}) \nonumber
	\end{eqnarray}
	
	As with all mixed models, the variance of each observation is the
	sum of all the associated variance components.
	\begin{eqnarray}
	var(Y_{ij}) =\quad \sigma^{2}_{s} + \sigma^{2}_{j} \\
	cov(Y_{i1},Y_{i2})=\quad \sigma^{2}_{s} \nonumber
	\end{eqnarray}
	
	\citet{Grubbs48} offers maximum likelihood estimators, commonly
	known as Grubbs estimators, for the various variance components:
	\begin{eqnarray}
	\hat{\sigma^{2}_{s}} \quad= \sum{\frac{(x_{i}-\bar{x})(y_{i}-\bar{y})}{n-1}}\quad=Sxy\\
	\hat{\sigma^{2}_{1}} \quad= \sum{\frac{(x_{i}-\bar{x})^{2}}{n-1}} \quad=S^{2}x-Sxy \nonumber\\
	\hat{\sigma^{2}_{2}} \quad=
	\sum{\frac{(y_{i}-\bar{y})^{2}}{n-1}}\quad=S^{2}y-Sxy \nonumber
	\nonumber
	\end{eqnarray}
	
	The standard error of these variance estimates are:
	\begin{eqnarray}
	var(\sigma^{2}_{1}) =\quad \frac{2\sigma^{4}_{1}}{n-1} +\quad
	\frac{\sigma^2_{S}\sigma^2_{1}+\sigma^2_{S}\sigma^2_{2}+\sigma^2_{1}\sigma^2_{2}
	}{n-1}\\
	var(\sigma^{2}_{2}) =\quad \frac{2\sigma^{4}_{2}}{n-1} +\quad
	\frac{\sigma^2_{S}\sigma^2_{1}+\sigma^2_{S}\sigma^2_{2}+\sigma^2_{1}\sigma^2_{2}
	}{n-1}\nonumber
	\end{eqnarray}
	
	\citet{Thompson}presents confidence intervals for the relative
	precisions of the measurement methods, $\Delta_{j}=
	\sigma^2_{S}/\sigma^2_{j}$ (where $j=1,2$), as well as the
	variances $\sigma^{2}_{S}, \sigma^{2}_{1}$ and $\sigma^{2}_{2}$.
	
	\begin{eqnarray}
	\Delta_{1} >\quad \frac{C_{xy}-
		t(|A|/n-2))^{\frac{1}{2}}}{C_{x}-C_{xy}+
		t(|A|/n-2))^{\frac{1}{2}}}
	\end{eqnarray}
	where
	
	\begin{eqnarray}
	C_{x}=\quad(n-1)S^2_{x}\nonumber\\
	C_{xy}=\quad(n-1)S_{xy}\nonumber\\
	C_{y}=\quad(n-1)S^2_{y}\nonumber\\
	A=\quad C_{x}\times C_{y} - (C_{xy})^2 \nonumber
	\end{eqnarray}
	
	$t$ is the $100(1-\alpha/2)\%$ quantile of Student's $t$
	distribution with $n-2$ degrees of freedom. $\Delta_{2}$ can be
	found by changing $C_{y}$ for $C_{x}$. A lower confidence limit
	can be found by calculating the square root. This inequality may
	also be used for hypothesis testing.
	
	For the interval estimates for the variance components,
	\citet{Thompson} presents three relations that hold simultaneously
	with probability $1-2\alpha$ where $2\alpha=0.01$ or $0.05$.
	
	\begin{eqnarray}
	|\sigma^2-C_{xy}K|\leqslant M(C_{x}C_{y})^{\frac{1}{2}}\\
	|\sigma^2_{1}-(C_{x}-C_{xy})K|\leqslant M(C_{x}(C_{x}+C_{y}-2C_{xy}))^{\frac{1}{2}}\nonumber\\
	|\sigma^2_{2}-(C_{y}-C_{xy})K|\leqslant
	M(C_{y}(C_{x}+C_{y}-2C_{xy}))^{\frac{1}{2}}\nonumber
	\end{eqnarray}
	
	The case-wise differences and means are $D_{i} = Y_{i1}-Y_{i2}$
	and $A_{i} = (Y_{i1}+Y_{i2})/2$  respectively. Both $D_{i}$ and
	$A_{i}$ follow a bivariate normal distribution with $E(D_{i})=
	\mu_{D} = \mu_{1} - \mu_{2}$ and $E(A_{i})= \mu_{A} = (\mu_{1} +
	\mu_{2})/2$. The variance matrix $\Sigma$ is
	
	\begin{equation}
	\Sigma = \left[\begin{matrix}
	\sigma^{2}_{1}+\sigma^{2}_{2}&\frac{1}{2}(\sigma^{2}_{1}-\sigma^{2}_{2})\\
	\frac{1}{2}(\sigma^{2}_{1}-\sigma^{2}_{2})&\sigma^{2}_{S}+
	\frac{1}{4}(\sigma^{2}_{1}+\sigma^{2}_{2})
	\end{matrix} \right]
	\end{equation}
	
	
	
	
	
	\citet{Kinsella} demonstrates how the Grubbs estimators for the
	error variances can be calculated using the difference values,
	providing a worked example on a data set.
	\begin{eqnarray}
	\hat{\sigma^{2}_{1}}
	\quad=\sum{(y_{i1}-\bar{y{1}})(D_{i}-\bar{D})}\\
	\hat{\sigma^{2}_{2}} \quad=
	\sum{(y_{i2}-\bar{y_{2}})(D_{i}-\bar{D})} \nonumber
	\end{eqnarray}

	\section{Model Formulation and Formal Testing}
	
	\citet{Kinsella} formulates a model for un-replicated observations
	for a method comparison study as a mixed model.
	\begin{eqnarray}
		Y_{ij} =\quad \mu_{j} + S_{i} + \epsilon_{ij} \quad i=1,2...n\quad
		j=1,2\\
		S \sim N(0,\sigma^{2}_{s})\qquad \epsilon_{ij} \sim
		N(0,\sigma^{2}_{j}) \nonumber
	\end{eqnarray}
	
	As with all mixed models, the variance of each observation is the
	sum of all the associated variance components.
	\begin{eqnarray}
		var(Y_{ij}) =\quad \sigma^{2}_{s} + \sigma^{2}_{j} \\
		cov(Y_{i1},Y_{i2})=\quad \sigma^{2}_{s} \nonumber
	\end{eqnarray}
	
	\citet{Grubbs48} offers maximum likelihood estimators, commonly
	known as Grubbs estimators, for the various variance components:
	\begin{eqnarray}
		\hat{\sigma^{2}_{s}} \quad= \sum{\frac{(x_{i}-\bar{x})(y_{i}-\bar{y})}{n-1}}\quad=Sxy\\
		\hat{\sigma^{2}_{1}} \quad= \sum{\frac{(x_{i}-\bar{x})^{2}}{n-1}} \quad=S^{2}x-Sxy \nonumber\\
		\hat{\sigma^{2}_{2}} \quad=
		\sum{\frac{(y_{i}-\bar{y})^{2}}{n-1}}\quad=S^{2}y-Sxy \nonumber
		\nonumber
	\end{eqnarray}
	
	The standard error of these variance estimates are:
	\begin{eqnarray}
		var(\sigma^{2}_{1}) =\quad \frac{2\sigma^{4}_{1}}{n-1} +\quad
		\frac{\sigma^2_{S}\sigma^2_{1}+\sigma^2_{S}\sigma^2_{2}+\sigma^2_{1}\sigma^2_{2}
		}{n-1}\\
		var(\sigma^{2}_{2}) =\quad \frac{2\sigma^{4}_{2}}{n-1} +\quad
		\frac{\sigma^2_{S}\sigma^2_{1}+\sigma^2_{S}\sigma^2_{2}+\sigma^2_{1}\sigma^2_{2}
		}{n-1}\nonumber
	\end{eqnarray}
	
	\citet{Thompson}presents confidence intervals for the relative
	precisions of the measurement methods, $\Delta_{j}=
	\sigma^2_{S}/\sigma^2_{j}$ (where $j=1,2$), as well as the
	variances $\sigma^{2}_{S}, \sigma^{2}_{1}$ and $\sigma^{2}_{2}$.
	
	\begin{eqnarray}
		\Delta_{1} >\quad \frac{C_{xy}-
			t(|A|/n-2))^{\frac{1}{2}}}{C_{x}-C_{xy}+
			t(|A|/n-2))^{\frac{1}{2}}}
	\end{eqnarray}
	where
	
	\begin{eqnarray}
		C_{x}=\quad(n-1)S^2_{x}\nonumber\\
		C_{xy}=\quad(n-1)S_{xy}\nonumber\\
		C_{y}=\quad(n-1)S^2_{y}\nonumber\\
		A=\quad C_{x}\times C_{y} - (C_{xy})^2 \nonumber
	\end{eqnarray}
	
	$t$ is the $100(1-\alpha/2)\%$ quantile of Student's $t$
	distribution with $n-2$ degrees of freedom. $\Delta_{2}$ can be
	found by changing $C_{y}$ for $C_{x}$. A lower confidence limit
	can be found by calculating the square root. This inequality may
	also be used for hypothesis testing.
	
	For the interval estimates for the variance components,
	\citet{Thompson} presents three relations that hold simultaneously
	with probability $1-2\alpha$ where $2\alpha=0.01$ or $0.05$.
	
	\begin{eqnarray}
		|\sigma^2-C_{xy}K|\leqslant M(C_{x}C_{y})^{\frac{1}{2}}\\
		|\sigma^2_{1}-(C_{x}-C_{xy})K|\leqslant M(C_{x}(C_{x}+C_{y}-2C_{xy}))^{\frac{1}{2}}\nonumber\\
		|\sigma^2_{2}-(C_{y}-C_{xy})K|\leqslant
		M(C_{y}(C_{x}+C_{y}-2C_{xy}))^{\frac{1}{2}}\nonumber
	\end{eqnarray}
	
	The case-wise differences and means are $D_{i} = Y_{i1}-Y_{i2}$
	and $A_{i} = (Y_{i1}+Y_{i2})/2$  respectively. Both $D_{i}$ and
	$A_{i}$ follow a bivariate normal distribution with $E(D_{i})=
	\mu_{D} = \mu_{1} - \mu_{2}$ and $E(A_{i})= \mu_{A} = (\mu_{1} +
	\mu_{2})/2$. The variance matrix $\Sigma$ is
	
	\begin{equation}
		\Sigma = \left[\begin{matrix}
			\sigma^{2}_{1}+\sigma^{2}_{2}&\frac{1}{2}(\sigma^{2}_{1}-\sigma^{2}_{2})\\
			\frac{1}{2}(\sigma^{2}_{1}-\sigma^{2}_{2})&\sigma^{2}_{S}+
			\frac{1}{4}(\sigma^{2}_{1}+\sigma^{2}_{2})
		\end{matrix} \right]
	\end{equation}
	
	
	
	
	
	\citet{Kinsella} demonstrates how the Grubbs estimators for the
	error variances can be calculated using the difference values,
	providing a worked example on a data set.
	\begin{eqnarray}
		\hat{\sigma^{2}_{1}}
		\quad=\sum{(y_{i1}-\bar{y{1}})(D_{i}-\bar{D})}\\
		\hat{\sigma^{2}_{2}} \quad=
		\sum{(y_{i2}-\bar{y_{2}})(D_{i}-\bar{D})} \nonumber
	\end{eqnarray}
	
	

	\section{Morgan Pitman}
	
	The test of the hypothesis that the variance of both methods are
	equal is based on the correlation value $\rho_{D,A}$ which is
	evaluated as follows;
	
	\begin{equation}
		\rho(D,A)=\quad\frac{\sigma^{2}_{1}-\sigma^{2}_{2}}{\sqrt{(\sigma^{2}_{1}+\sigma^{2}_{2})(4\sigma^{2}_{S}+\sigma^{2}_{1}+\sigma^{2}_{2})}}
	\end{equation}
	
	The correlation constant takes the value zero if, and only if, the
	two variances are equal. Therefore a test of the hypothesis $H:
	\sigma^{2}_{1}=\sigma^{2}_{2}$ is equivalent to a test of the
	hypothesis $H: \rho(D,A) = 0$. The corresponds to the well-known
	$t$ test for a correlation coefficient with $n-2$ degrees of
	freedom.
	
	\citet{Bartko} describes the Morgan-Pitman test as identical to
	the test of the slope equal to zero in the regression of $Y_{i1}$
	on $Y_{12}$, adding that this result can be shown using
	straightforward algebra.

	
	

	\section{Formal Models and Tests}
	The Bland-Altman plot is a simple tool for inspection of data, and
	\citet{Kinsella} comments on the lack of formal testing offered by
	that methodology. \citet{Kinsella} formulates a model for
	single measurement observations for a method comparison study as a
	linear mixed effects model, i.e. model that additively combine
	fixed effects and random effects.
	\[
	Y_{ij} =\quad \mu + \beta_{j} + u_{i} + \epsilon_{ij} \qquad i = 1,\dots,n
	\qquad j=1,2\]
	
	The true value of the measurement is represented by $\mu$ while the fixed effect due to method $j$ is $\beta_{j}$.
	For simplicity these terms can be combined into single terms; $\mu_{1} = \mu+ \beta_{1}$ and $\mu_{2} = \mu + \beta_{2}$. The inter-method bias is the difference of the two fixed effect terms, $\beta_{1}-\beta_{2}$. Each of the $i$ individuals are assumed to give rise to random error, represented by $u_{i}$. This random effects terms is assumed to have mean zero and be normally distributed with variance $\sigma^2$. There is assumed to be an attendant error for each measurement on each individual, denoted $\epsilon_{ij}$. This is also assumed to have mean zero. The variance of measurement error for both methods are not assumed to be identical for both methods variance,  hence it is denoted $\sigma^2_{j}$. The set of observations ($x_{i},y_{i}$) by methods $X$ and $Y$ are assumed to follow the bivariate normal distribution with expected values $E(x_{i})= \mu_{i}$ and $E(x_{i})= \mu_{i}$ respectively. The variance covariance of the observations $\boldsymbol{\Sigma}$ is given by
	
	\[
	\boldsymbol{\Sigma} = \left[
	\begin{array}{cc}
	\sigma^{2} + \sigma^{2}_{1} & \sigma^{2} \\
	\sigma^{2} & \sigma^{2} + \sigma^{2}_{2} \\
	\end{array}
	\right]
	\]
	
	The inter-method bias is the difference of the two fixed effect terms, $\beta_{1}-\beta_{2}$.
	
	\citet{Kinsella} demonstrates the estimation of the variance terms and relative precisions relevant to a method comparison study, with attendant confidence intervals for both. The measurement model introduced by \citet{Grubbs48,Grubbs73} provides a formal procedure for estimate the variances $\sigma^2$,$\sigma^2_{1}$ and $\sigma^2_{2}$ devices. \citet{Grubbs48} offers estimates, commonly known as Grubbs estimators, for the various variance components. These estimates are maximum likelihood estimates, a statistical concept that shall be revisited in due course.
	\begin{eqnarray*}
		\hat{\sigma^{2}} = \sum{\frac{(x_{i}-\bar{x})(y_{i}-\bar{y})}{n-1}} = Sxy\\
		\hat{\sigma^{2}_{1}} = \sum{\frac{(x_{i}-\bar{x})^{2}}{n-1}} =S^{2}x - Sxy  \\
		\hat{\sigma^{2}_{2}} =
		\sum{\frac{(y_{i}-\bar{y})^{2}}{n-1}} = S^{2}y - Sxy
	\end{eqnarray*}
	
	% The standard error of these variance estimates are:
	% \begin{eqnarray}
	% \mbox{var}(\sigma^{2}_{1}) = \frac{2\sigma^{4}_{1}}{n-1} +
	% \frac{\sigma^2_{S}\sigma^2_{1}+\sigma^2_{S}\sigma^2_{2}+\sigma^2_{1}\sigma^2_{2}
	% }{n-1}\\
	% \mbox{var}(\sigma^{2}_{2}) =\quad \frac{2\sigma^{4}_{2}}{n-1} +
	% \frac{\sigma^2_{S}\sigma^2_{1}+\sigma^2_{S}\sigma^2_{2}+\sigma^2_{1}\sigma^2_{2}
	% }{n-1}\nonumber
	% \end{eqnarray}
	
	\citet{Thompson} defines $\Delta_{j}$ to be a measure of the
	relative precision of the measurement methods, with $\Delta_{j}=
	\sigma^2/\sigma^2_{j}$. Thompson also demonstrates how to make statistical inferences about $\Delta_{j}$.
	Based on the following identities,
	\begin{eqnarray*}
		C_{x}&=&(n-1)S^2_{x},\nonumber\\
		C_{xy}&=&(n-1)S_{xy},\nonumber\\
		C_{y}&=&(n-1)S^2_{y},\nonumber\\
		|A| &=& C_{x}\times C_{y} - (C_{xy})^2,\nonumber
	\end{eqnarray*}
	\noindent the confidence interval limits of $\Delta_{1}$ are
	
	\begin{eqnarray}
	\Delta_{1} > \frac{C_{xy}-
		t(\frac{|A|}{n-2}))^{\frac{1}{2}}}{C_{x}-C_{xy}+
		t(\frac{|A|}{n-2}))^{\frac{1}{2}}} \\
	\Delta_{1} > \frac{C_{xy}+
		t(\frac{|A|}{n-2}))^{\frac{1}{2}}}{C_{x}-C_{xy}-
		t(\frac{|A|}{n-1}))^{\frac{1}{2}}} \nonumber
	\end{eqnarray}
	\\ The value $t$ is the $100(1-\alpha/2)\%$ upper quantile of
	Student's $t$ distribution with $n-2$ degrees of freedom
	\citep{Kinsella}. The confidence limits for $\Delta_{2}$ are found by substituting $C_{y}$ for $C_{x}$ in (1.3).
	Negative lower limits are replaced by the value $0$.
	
	%For the interval estimates for the variance components,
	%\citet{Thompson} presents three relations that hold simultaneously
	%with probability $1-2\alpha$ where $2\alpha=0.01$ or $0.05$.
	
	%\begin{eqnarray*}
	%|\sigma^2-C_{xy}K| &\leqslant& M(C_{x}C_{y})^{\frac{1}{2}}\\
	%|\sigma^2_{1}-(C_{x}-C_{xy})K|&\leqslant M(C_{x}(C_{x}+C_{y}-2C_{xy}))^{\frac{1}{2}}\nonumber\\
	%|\sigma^2_{2}-(C_{y}-C_{xy})K|&\leqslant
	%M(C_{y}(C_{x}+C_{y}-2C_{xy}))^{\frac{1}{2}}\nonumber
	%\end{eqnarray*}
	
	%\citet{Thompson} contains tables for $K$ and $M$.
	
	The case-wise differences and means are calculated as $d_{i} =
	x_{i}-y_{i}$ and $a_{i} = (x_{i}+y_{i})/2$  respectively. Both
	$d_{i}$ and $a_{i}$ are assumed to follow a bivariate normal
	distribution with $E(d_{i})= \mu_{d} = \mu_{1} - \mu_{2}$ and
	$E(a_{i})= \mu_{a} = (\mu_{1} + \mu_{2})/2$. The variance matrix
	$\Sigma_{(a,d)}$ is
	
	\begin{eqnarray}
	\Sigma_{(a,d)}= \left[\begin{matrix}
	\sigma^{2}_{1}+\sigma^{2}_{2}&\frac{1}{2}(\sigma^{2}_{1}-\sigma^{2}_{2})\\
	\frac{1}{2}(\sigma^{2}_{1}-\sigma^{2}_{2})&\sigma^{2}+
	\frac{1}{4}(\sigma^{2}_{1}+\sigma^{2}_{2})
	\end{matrix} \right].
	\end{eqnarray}
	

	
	
	
	\section{Paired sample T-test} \citet{Bartko} discusses the use
	of the well known paired sample $t$ test to test for inter-method
	bias; $H: \mu_{D}=0$. The test statistic is distributed a $t$
	random variable with $n-1$ degrees of freedom and is calculated as
	follows;
	
	\begin{equation}
		t^{*} = \bar{D}/ \frac{S_{D}}{\sqrt{n}}
	\end{equation}
	
	where $\bar{D}$ and $S_{D}$ is the average of the differences of
	the $n$ observations.
	
	
	

	\section{Morgan Pitman Testing}
	An early contribution to formal testing in method comparison was
	made by both \citet{morgan} and \citet{pitman}, in separate
	contributions. The basis of this approach is that the
	distribution of the original measurements is bivariate normal.
	Morgan and Pitman noted that the correlation coefficient depends
	upon the difference $\sigma^{2}_{1}- \sigma^{2}_{2}$, being zero
	if and only if $\sigma^{2}_{1}=\sigma^{2}_{2}$.
	
	The classical Pitman-Morgan test is a hypothesis test for equality
	of the variance of two data sets; $\sigma^{2}_{1} =
	\sigma^{2}_{2}$, based on the correlation value $\rho_{a,d}$ ,and
	is evaluated as follows;
	
	\begin{equation}
	\rho(a,d)=\quad\frac{\sigma^{2}_{1}-\sigma^{2}_{2}}{\sqrt{(\sigma^{2}_{1}+\sigma^{2}_{2})(4\sigma^{2}_{S}+\sigma^{2}_{1}+\sigma^{2}_{2})}}
	\end{equation}
	
	The correlation constant takes the value zero if, and only if, the two variances are equal. Therefore a test of the hypothesis $H: \sigma^{2}_{1}=\sigma^{2}_{2}$ is equivalent to a test of the hypothesis $H: \rho(D,A) = 0$. This corresponds to the well-known
	$t$ test for a correlation coefficient with $n-2$ degrees of freedom. \citet{Bartko} describes the Morgan-Pitman test as identical to
	the test of the slope equal to zero in the regression of $Y_{i1}$ on $Y_{12}$, a result that can be derived using
	straightforward algebra.
	
	
	\section{Paired sample \emph{t}-test}
	
	\citet{Bartko} discusses the use of the well known paired sample
	$t$ test to test for inter-method bias; $H: \mu_{d}=0$. The test
	statistic is distributed a $t$ random variable with $n-1$ degrees
	of freedom and is calculated as follows,
	
	\begin{equation}
	t^{*} = \frac{\bar{d}}{ \frac{s_{d}}{\sqrt{n}}}
	\end{equation}
	
	where $\bar{d}$ and $s_{d}$ is the average of the differences of
	the $n$ observations. Only if the two methods show comparable
	precision then the paired sample student t-test is appropriate for
	assessing the magnitude of the bias.
	
	\section*{Structural Equation Modelling}
	Authors, such as a \citet{lewis}, \citet{dunnSEME} and \citet{voelkel2005center}, strongly advocate the use of \textit{Structural Equation Models} for the purposes of method comparison. Conversely \citet{BA99} also states that consider structural equation models to be inappropriate.
	
	\section{Thompson 1963}
	
	
	
	\citet{Thompson} defines $\Delta_{j}$ to be a measure of the
	relative precision of the measurement methods, with $\Delta_{j}=
	\sigma^2_{S}/\sigma^2_{j}$(where $j=1,2$). Confidence intervals
	for $\Delta_{j}$ are also presented.
	
	\begin{eqnarray}
		\Delta_{1} > \frac{C_{xy}-
			t(\frac{|A|}{n-1}))^{\frac{1}{2}}}{C_{x}-C_{xy}+
			t(\frac{|A|}{n-1}))^{\frac{1}{2}}},
	\end{eqnarray}
	where
	
	\begin{eqnarray}
		C_{x}&=&(n-1)S^2_{x},\nonumber\\
		C_{xy}&=&(n-1)S_{xy},\nonumber\\
		C_{y}&=&(n-1)S^2_{y},\nonumber\\
		A &=& C_{x}\times C_{y} - (C_{xy})^2 . \nonumber
	\end{eqnarray}
	
	The value $t$ is the $100(1-\alpha/2)\%$ quantile of Student's $t$
	distribution with $n-2$ degrees of freedom. The ratio $\Delta_{2}$
	can be found by interchanging $C_{y}$ and $C_{x}$. A lower
	confidence limit can be found by calculating the square root. The
	inequality in equation $1.10$ may also be used for hypothesis
	testing.
	
	For the interval estimates for the variance components,
	\citet{Thompson} presents three relations that hold simultaneously
	with probability $1-2\alpha$ where $2\alpha=0.01$ or $0.05$.
	
	
	\begin{eqnarray*}
		|\sigma^2-C_{xy}K| &\leqslant& M(C_{x}C_{y})^{\frac{1}{2}}\\
		|\sigma^2_{1}-(C_{x}-C_{xy})K|&\leqslant M(C_{x}(C_{x}+C_{y}-2C_{xy}))^{\frac{1}{2}}\nonumber\\
		|\sigma^2_{2}-(C_{y}-C_{xy})K|&\leqslant
		M(C_{y}(C_{x}+C_{y}-2C_{xy}))^{\frac{1}{2}}\nonumber
	\end{eqnarray*}
	
	\citet{Thompson} contains tables for $K$ and $M$.
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Bartko's BB
	\citet{BB89} offers a formal simultaneous hypothesis test for the
	mean and variance of two paired data sets. Using simple linear
	regression of the differences of each pair against the sums, a
	line is fitted to the model, with estimates for intercept and
	slope ($\hat{\beta}_{0}$ and $\hat{\beta}_{1}$). The null
	hypothesis of this test is that the mean ($\mu$) and variance
	($\sigma^{2}$) of both data sets are equal if the slope and
	intercept estimates are equal to zero(i.e $\sigma^{2}_{1} =
	\sigma^{2}_{2}$ and $\mu_{1}=\mu_{2}$ if and only if $\beta_{0}=
	\beta_{1}=0$ )
	
	A test statistic is then calculated from the regression analysis
	of variance values \citep{BB89} and is distributed as `F' random
	variable. The degrees of freedom thereof are $\nu_{1}=2$ and
	$\nu_{1}=n-2$ (where n is the number of pairs). The critical value
	is chosen for $\alpha\%$ significance with those same degrees of
	freedom. \citet{Bartko} amends this methodology for use in method
	comparison studies, using the averages of the pairs, as opposed to
	the sums, and their differences. This approach can facilitate
	simultaneous usage of test with the Bland-Altman methodology.
	Bartko's test statistic take the form:
	\begin{equation} F.test = \frac{(\Sigma d^{2})-SSReg}{2MSReg}
	\end{equation}
	% latex table generated in R 2.6.0 by xtable 1.5-5 package
	% Mon Aug 31 15:53:51 2009
	\begin{table}[ht]
		\begin{center}
			\begin{tabular}{lrrrrr}
				\hline
				& Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
				\hline
				Averages & 1 & 0.04 & 0.04 & 0.74 & 0.4097 \\
				Residuals & 10 & 0.60 & 0.06 &  &  \\
				\hline
			\end{tabular}
			\caption{Regression ANOVA of case-wise differences and averages
				for Grubbs Data}
		\end{center}
	\end{table}
	%(calculate using R code $qf(0.95,2,10)$).
	
	For the Grubbs data, $\Sigma d^{2}=5.09 $, $SSReg = 0.60$ and
	$MSreg=0.06$ Therefore the test statistic is $37.42$, with a
	critical value of $4.10$. Hence the means and variance of the
	Fotobalk and Counter chronometers are assumed to be simultaneously
	equal.
	
	Importantly, this methodology determines whether there is both
	inter-method bias and precision present, or alternatively if there
	is neither present. It has previously been demonstrated that there
	is a inter-method bias present, but as this procedure does not
	allow for separate testing, no conclusion can be drawn on the
	comparative precision of both methods.
	
	\section{Formal Testing}
	The Bland Altman plot is a simple tool for inspection of the data,
	but in itself it offers no formal testing procedure in this
	regard. To this end, the approach proposed by \citet{BA83} is a
	formal test on the Pearson correlation coefficient  of casewise
	differences and means ($\rho_{AD}$). According to the authors,
	this test is equivalent to a well established tests for equality
	of variances, known as the `Pitman Morgan Test' \citep{Pitman,
		Morgan}.
	
	For the Grubbs data, the correlation coefficient estimate
	($r_{AD}$) is 0.2625, with a 95\% confidence interval of (-0.366,
	0.726) estimated by Fishers 'r to z' transformation \citep{Cohen}.
	The null hypothesis ($\rho_{AD}$ =0) would fail to be rejected.
	Consequently the null hypothesis of equal variances of each method
	would also fail to be rejected.
	
	There has no been no further mention of this particular test in
	the subsequent article published by Bland and Altman, although
	\citet{BA99} refers to Spearmans' rank correlation coefficient.
	
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\newpage
	\chapter{Regression Procedures}
	\section{Constant and Proportional Bias}
	\begin{itemize}
		\item[Constant Bias] This is a form of systematic deviations estimated as the average difference between the test
		and the reference method.
		\item[Proportional Bias] Two methods may agree on average, but they may exhibit differences over a range of measurements.
	\end{itemize}
	
	Proportional Bias is a difference in the two measures which is proportional to the scale of the measurement. \\Using a naive estimation of bias, such as the mean of differences, it may incorrectly indicate absence of bias, by yielding a mean difference close to zero. This would be caused by positive differences in the measurements at one end of the range of measurements being canceled out by negative differences at the other end of the scale.

		\section{Regression Methods}
		Conventional regression models are estimated using the ordinary
		least squares (OLS) technique, and are referred to as `Model I
		regression' \citep{CornCoch,ludbrook97}. A key feature of Model I
		models is that the independent variable is assumed to be measured
		without error. As often pointed out in several papers
		\citep{BA83,ludbrook97}, this assumption invalidates simple linear
		regression for use in method comparison studies, as both methods
		must be assumed to be measured with error.
		
		The use of regression models that assumes the presence of error in
		both variables $X$ and $Y$ have been proposed for use instead
		\citep{CornCoch,ludbrook97}. These methodologies are collectively
		known as `Model II regression'. They differ in the method used to
		estimate the parameters of the regression.
		
		Regression estimates depend on formulation of the model. A
		formulation with one method considered as the $X$ variable will
		yield different estimates for a formulation where it is the $Y$
		variable. With Model I regression, the models fitted in both cases
		will entirely different and inconsistent. However with Model II
		regression, they will be consistent and complementary.
		
		Regression approaches are useful for a making a detailed examination of the biases across the range of measurements, allowing bias to be decomposed into fixed bias and proportional bias.
		Fixed bias describes the case where one method gives values that are consistently different
		to the other across the whole range. Proportional
		bias describes the difference in measurements getting progressively greater, or smaller, across the range of measurements. A measurement method may have either an attendant fixed bias or proportional bias, or both. \citep{ludbrook}. Determination of these biases shall be discussed in due course.
		
		

		\section{Other Types of Studies}
		\citet{lewis} categorize method comparison studies into three
		different types.  The key difference between the first two is
		whether or not a `gold standard' method is used. In situations
		where one instrument or method is known to be `accurate and
		precise', it is considered as the`gold standard' \citep{lewis}. A
		method that is not considered to be a gold standard is referred to
		as an `approximate method'. In calibration studies they are
		referred to a criterion methods and test methods respectively.
		
		
		\textbf{1. Calibration problems}. The purpose is to establish a
		relationship between methods, one of which is an approximate
		method, the other a gold standard. The results of the approximate
		method can be mapped to a known probability distribution of the
		results of the gold standard \citep{lewis}. (In such studies, the
		gold standard method and corresponding approximate method are
		generally referred to a criterion method and test method
		respectively.) \citet*{BA83} make clear that their methodology is
		not intended for calibration problems.
		
		\bigskip \textbf{2. Comparison problems}. When two approximate
		methods, that use the same units of measurement, are to be
		compared. This is the case which the Bland-Altman methodology is
		specfically intended for, and therefore it is the most relevant of
		the three.
		
		\bigskip \textbf{3. Conversion problems}. When two approximate
		methods, that use different units of measurement, are to be
		compared. This situation would arise when the measurement methods
		use 'different proxies', i.e different mechanisms of measurement.
		\citet{lewis} deals specifically with this issue. In the context
		of this study, it is the least relevant of the three.
		
		\citet[p.47]{DunnSEME} cautions that`gold standards' should not be
		assumed to be error free. `It is of necessity a subjective
		decision when we come to decide that a particular method or
		instrument can be treated as if it was a gold standard'. The
		clinician gold standard , the sphygmomanometer, is used as an
		example thereof.  The sphygmomanometer `leaves considerable room
		for improvement' \citep{DunnSEME}. \citet{pizzi} similarly
		addresses the issue of glod standards, `well-established gold
		standard may itself be imprecise or even unreliable'.
		
		
		The NIST F1 Caesium fountain atomic clock is considered to be the
		gold standard when measuring time, and is the primary time and
		frequency standard for the United States. The NIST F1 is accurate
		to within one second per 60 million years \citep{NIST}.
		
		Measurements of the interior of the human body are, by definition,
		invasive medical procedures. The design of method must balance the
		need for accuracy of measurement with the well-being of the
		patient. This will inevitably lead to the measurement error as
		described by \citet{DunnSEME}. The magnetic resonance angiogram,
		used to measure internal anatomy,  is considered to the gold
		standard for measuring aortic dissection. Medical test based upon
		the angiogram is reported to have a false positive reporting rate
		of 5\% and a false negative reporting rate of 8\%. This is
		reported as sensitivity of 95\% and a specificity of 92\%
		\citep{ACR}.
		
		In literature they are, perhaps more accurately, referred to as
		`fuzzy gold standards' \citep{phelps}. Consequently when one of the methods is
		essentially a fuzzy gold standard, as opposed to a `true' gold
		standard, the comparison of the criterion and test methods should
		be consider in the context of a comparison study, as well as of a
		calibration study.
		
		\newpage
		\section{Outline of Thesis}
		Thus the study of method comparison is introduced. The intention of this thesis is to progress the
		study of method comparison studies, using a statistical method known as Linear mixed effects models.
		Chapter two shall describe linear mixed effects models, and how the use of the linear mixed
		effects models have so far extended to method comparison studies. Implementations of important existing work shall be presented, using the \texttt{R} programming language.
		
		Model diagnostics are an integral component of a complete statistical analysis.
		In chapter three model diagnostics shall be described in depth, with particular
		emphasis on linear mixed effects models, further to chapter two.
		
		For the fourth chapter, important linear mixed effects model diagnostic methods shall be extended to method comparison studies, and proposed methods shall be demonstrated on data sets that have become well known in literature on method comparison. The purpose is to both calibrate these methods and to demonstrate applications for them.
		The last chapter shall focus on robust measures of important parameters such as agreement.
		
		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\section{Bartko's Regression and Ellipse}
	\citet{BB89} offers a formal simultaneous hypothesis test for the
	mean and variance of two paired data sets. Using simple linear
	regression of the differences of each pair against the sums, a
	line is fitted to the model, with estimates for intercept and
	slope ($\beta_{0}$ and $\beta_{1}$). The null hypothesis of this
	test is that the mean ($\mu$) and variance ($\sigma^{2}$) of both
	data sets are equal if the slope and intercept estimates are equal
	to zero(i.e $\sigma^{2}_{1} = \sigma^{2}_{2}$ and
	$\mu_{1}=\mu_{2}$ if and only if $\beta_{0}= \beta_{1}=0$ )
	
	A test statistic is then calculated from the regression analysis
	of variance values \citep{BB89} and is distributed as `F' random
	variable. The degrees of freedom thereof are $\nu_{1}=2$ and
	$\nu_{1}=n-2$ (where n is the number of pairs). The critical value
	is chosen for $\alpha\%$ significance with those same degrees of
	freedom. \citet{Bartko} amends this metholodogy for calculation
	using the from the averages of the pairs, as opposed to the sums,
	and their differences. This would facilitate simultaneous usage of
	test with the Bland Altman methodology. Bartko's test statistic
	take the form:
	\begin{equation} F.test = \frac{(\Sigma D^{2})-SSReg}{2MSReg}
	\end{equation}
	
	\newpage
	
	% latex table generated in R 2.6.0 by xtable 1.5-5 package
	% Mon Aug 31 15:53:51 2009
	\begin{table}[ht]
		\begin{center}
			\begin{tabular}{lrrrrr}
				\hline
				& Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
				\hline
				Averages & 1 & 0.04 & 0.04 & 0.74 & 0.4097 \\
				Residuals & 10 & 0.60 & 0.06 &  &  \\
				\hline
			\end{tabular}
			\caption{Regression ANOVA of case-wise differences and averages
				for Grubbs Data}
		\end{center}
	\end{table}
	
	
	
	
	For the Grubbs data, $\Sigma D^{2}=5.09 $, $SSReg = 0.60$ and
	$MSreg=0.06$ Therefore the test statistic is $37.42$, with a
	critical value of $4.102821$ (calculate using r code
	$qf(0.95,2,10)$). Hence the means and variance of the Fotobalk and
	Counter chronometers are assumed to be simultaneously equal.
	
	Importantly, this methodology determines whether there is both
	inter-method bias and precision present, or alternatively if there
	is neither present. It has previously been demonstrated that there
	is a inter-method bias present, but as this procedure does not
	allow for seperate testing, no conclusion can be drawn on the
	comparative precision of both methods.
	\newpage

	\section{Bartko's Regression and Ellipse}
	\citet{BB89} offers a formal simultaneous hypothesis test for the
	mean and variance of two paired data sets. Using simple linear
	regression of the differences of each pair against the sums, a
	line is fitted to the model, with estimates for intercept and
	slope ($\beta_{0}$ and $\beta_{1}$). The null hypothesis of this
	test is that the mean ($\mu$) and variance ($\sigma^{2}$) of both
	data sets are equal if the slope and intercept estimates are equal
	to zero(i.e $\sigma^{2}_{1} = \sigma^{2}_{2}$ and
	$\mu_{1}=\mu_{2}$ if and only if $\beta_{0}= \beta_{1}=0$ )
	
	A test statistic is then calculated from the regression analysis
	of variance values \citep{BB89} and is distributed as `F' random
	variable. The degrees of freedom thereof are $\nu_{1}=2$ and
	$\nu_{1}=n-2$ (where n is the number of pairs). The critical value
	is chosen for $\alpha\%$ significance with those same degrees of
	freedom. \citet{Bartko} amends this metholodogy for calculation
	using the from the averages of the pairs, as opposed to the sums,
	and their differences. This would facilitate simultaneous usage of
	test with the Bland Altman methodology. Bartko's test statistic
	take the form:
	\begin{equation} F.test = \frac{(\Sigma D^{2})-SSReg}{2MSReg}
	\end{equation}
	
	\newpage
	
	% latex table generated in R 2.6.0 by xtable 1.5-5 package
	% Mon Aug 31 15:53:51 2009
	\begin{table}[ht]
		\begin{center}
			\begin{tabular}{lrrrrr}
				\hline
				& Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
				\hline
				Averages & 1 & 0.04 & 0.04 & 0.74 & 0.4097 \\
				Residuals & 10 & 0.60 & 0.06 &  &  \\
				\hline
			\end{tabular}
			\caption{Regression ANOVA of case-wise differences and averages
				for Grubbs Data}
		\end{center}
	\end{table}
	
	
	
	
	For the Grubbs data, $\Sigma D^{2}=5.09 $, $SSReg = 0.60$ and
	$MSreg=0.06$ Therefore the test statistic is $37.42$, with a
	critical value of $4.102821$ (calculate using r code
	$qf(0.95,2,10)$). Hence the means and variance of the Fotobalk and
	Counter chronometers are assumed to be simultaneously equal.
	
	Importantly, this methodology determines whether there is both
	inter-method bias and precision present, or alternatively if there
	is neither present. It has previously been demonstrated that there
	is a inter-method bias present, but as this procedure does not
	allow for seperate testing, no conclusion can be drawn on the
	comparative precision of both methods.
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%  Bsartko's Ellipse       %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\section{Bartko's Ellipse}
	\citet{Bartko} offers a graphical complement to the Bland-Altman
	plot, in the form of a bivariate confidence ellipse.
	\citet{AltmanEllipse} provides the relevant calculations.
	
	\begin{figure}[h!]
		% Requires \usepackage{graphicx}
		\includegraphics[width=130mm]{images/GrubbsBartko.jpeg}
		\caption{Bartko's Ellipse For Grubbs Data}\label{GrubbsBartko}
	\end{figure}

	
	
	


		
		
		
		\section{Bartko's Ellipse}
	
	As an enhancement on the Bland Altman Plot, \citet{Bartko} has
	expounded a confidence ellipse for the covariates. \citet{Bartko} proposes
	a bivariate confidence ellipse as a boundary for dispersion. The stated purpose is to `amplify dispersion', which presumably is for  the purposes of outlier detection. The orientation of the the ellipse is key to interpreting the results. The minor axis is related to the between-item variability whereas the major axis is related to the mean squared error (referred to here as Error Mean Square).The ellipse illustrates the size of both relative to each
	other. 
	
	
	Consequently Bartko's ellipse provides a visual aid to determining the
	relationship between variances. 
	Furthermore, the ellipse provides a visual aid to determining the relationship
	between the variance of the means $Var(a_{i})$ and the variance of the differences $Var(d_{i})$. If $\mbox{var}(a)$ is greater than $\mbox{var}(d)$, the orientation of the ellipse is horizontal. Conversely if $\mbox{var}(a)$ is less than $\mbox{var}(d)$, the orientation of the ellipse is vertical. The more horizontal the ellipse, the greater the degree of agreement between the two methods being tested.
	
	
	%(Furthermore \citet{Bartko}
	%proposes formal testing procedures, that shall be discussed in due
	%course.)
	Bartko states that the ellipse can, inter alia, be used to detect the presence of outliers (furthermore
	\citet{Bartko} proposes formal testing procedures, that shall be discussed in due course). 
	The Bland-Altman plot for the Grubbs data, complemented by Bartko's ellipse, is depicted in Figure ~\ref{GrubbsBartko1}.
	The fourth observation is shown to be outside the bounds of the ellipse, indicating that it is a potential outlier.
	
	
	\begin{centering}
		\begin{figure}[h!]
			% Requires \usepackage{graphicx}
			\includegraphics[width=130mm]{images/GrubbsBartko.jpeg}
			\caption{Bartko's Ellipse For Grubbs' Data.}
			\label{GrubbsBartko1}
		\end{figure}
	\end{centering}
	
	The limitations of using bivariate approaches to outlier detection
	in the Bland-Altman plot can demonstrated using Bartko's ellipse.
	A covariate is added to the `F vs C' comparison that has a
	difference value equal to the inter-method bias, and an average
	value that markedly deviates from the rest of the average values
	in the comparison, i.e. 786. Table 1.8 depicts a $95\%$ confidence
	ellipse for this manipulated data set. By inspection of the
	confidence interval, a conclusion would be reached that this extra
	covariate is an outlier, in spite of the fact that this
	observation is wholly consistent with the conclusion of the
	Bland-Altman plot.
	
	%\begin{figure}[h!]
	%  % Requires \usepackage{graphicx}
	%  \includegraphics[width=130mm]{GrubbsBartko2.jpeg}
	%  \caption{Bartko's Ellipse For Grubbs' Data, with an extra covariate.}\label{GrubbsBartko2}
	%\end{figure}
	
	
	Importantly, outlier classification must be informed by the logic of the
	data's formulation. In the Bland-Altman plot, the horizontal displacement of any
	observation is supported by two independent measurements. Any
	observation should not be considered an outlier on the basis of a
	noticeable horizontal displacement from the main cluster, as in
	the case with the extra covariate. Conversely, the fourth
	observation, from the original data set, should be considered an
	outlier, as it has a noticeable vertical displacement from the
	rest of the observations.
	\newpage
	
	\begin{figure}[h!]
		% Requires \usepackage{graphicx}
		\includegraphics[width=130mm]{images/GrubbsBartko2.jpeg}
		\caption{Bartko's Ellipse For Grubbs' Data, with an extra covariate.}\label{GrubbsBartko2}
	\end{figure}
	
	In the Bland-Altman plot, the horizontal displacement of any point on the plot is supported by two independent measurements. Any point should not be considered an outlier on the basis of a noticeable horizontal displacement from the main cluster, as in the case with the extra co-variate. Conversely, the fourth point, from the original data set, should be considered an
	outlier, as it has a noticeable vertical displacement from the rest of the observations.
	\newpage
	


	
	\section{Blackwood Bradley Model} 
	
	Bradley and Blackwood have developed a regression based approach
	assessing the agreement.
	
	
	
	
	\newpage
	\section{Blackwood Bradley Model} This is a regression based
	approach that performs a simultaneous test for the equivalence of
	means and variances of the respective methods.\\We have identified
	this approach  to be examined to see if it can be used as a
	foundation for a test perform a test on
	means and variances individually.\\
	\begin{equation}
	D = (X_{1}-X_{2})
	\end{equation}
	\begin{equation}
	M = (X_{1} + X_{2}) /2
	\end{equation}
	The Bradley Blackwood Procedure fits D on M as follows:\\
	\begin{equation}
	D = \beta_{0} + \beta_{1}M
	\end{equation}
	\\Both beta values, the intercept and slope, are derived from the respective means and
	standard deviations of their respective data sets.\\
	We determine if the respective means and variances are equal if
	both beta values are simultaneously equal to zero. The Test is
	conducted using an F test, calculated from the results of a
	regression of D on M.
	\\
	Russell et al have suggested this method be used in conjunction
	with a paired t-test , with estimates of slope and intercept.
	Bradley and Blackwood have developed a regression based approach
	assessing the agreement.
	\\
	The Bradley Blackwood test is a simultaneous test for bias and
	precision. They propose a regression approach which fits D on M,
	where D is the difference and average of a pair of results.
	
	


	\section{Blackwood Bradley Model} This is a regression based
	approach that performs a simultaneous test for the equivalence of
	means and variances of the respective methods.\\We have identified
	this approach  to be examined to see if it can be used as a
	foundation for a test perform a test on
	means and variances individually.\\
	\begin{equation}
		D = (X_{1}-X_{2})
	\end{equation}
	\begin{equation}
		M = (X_{1} + X_{2}) /2
	\end{equation}
	The Bradley Blackwood Procedure fits D on M as follows:\\
	\begin{equation}
		D = \beta_{0} + \beta_{1}M
	\end{equation}
	\\Both beta values, the intercept and slope, are derived from the respective means and
	standard deviations of their respective data sets.\\
	We determine if the respective means and variances are equal if
	both beta values are simultaneously equal to zero. The Test is
	conducted using an F test, calculated from the results of a
	regression of D on M.
	\\
	Russell et al have suggested this method be used in conjunction
	with a paired t-test , with estimates of slope and intercept.
	Bradley and Blackwood have developed a regression based approach
	assessing the agreement.
	\\
	The Bradley Blackwood test is a simultaneous test for bias and
	precision. They propose a regression approach which fits D on M,
	where D is the difference and average of a pair of results.
	
	
	



	\section{Blackwood -Bradley Model} 
	
	\citet{BB89} have developed a regression based procedure for
	assessing the agreement. This approach performs a simultaneous test for the equivalence of
	means and variances of the respective methods. Using simple linear
	regression of the differences of each pair against the sums, a
	line is fitted to the model, with estimates for intercept and
	slope ($\hat{\beta}_{0}$ and $\hat{\beta}_{1}$).
	%We have identified
	%this approach  to be examined to see if it can be used as a %foundation for a test perform a test on
	%means and variances individually.
	\begin{equation}
		D = (X_{1}-X_{2})
	\end{equation}
	\begin{equation}
		M = (X_{1} + X_{2}) /2
	\end{equation}
	The Bradley Blackwood Procedure fits D on M as follows:\\
	\begin{equation}
		D = \beta_{0} + \beta_{1}M
	\end{equation}
	This technique offers a formal simultaneous hypothesis test for the
	mean and variance of two paired data sets.  The null
	hypothesis of this test is that the mean ($\mu$) and variance
	($\sigma^{2}$) of both data sets are equal if the slope and
	intercept estimates are equal to zero(i.e $\sigma^{2}_{1} =
	\sigma^{2}_{2}$ and $\mu_{1}=\mu_{2}$ if and only if $\beta_{0}=
	\beta_{1}=0$ )
	
	A test statistic is then calculated from the regression analysis
	of variance values \citep{BB89} and is distributed as `$F$' random
	variable. The degrees of freedom are $\nu_{1}=2$ and $\nu_{1}=n-2$
	(where $n$ is the number of pairs). The critical value is chosen
	for $\alpha\%$ significance with those same degrees of freedom.
	\citet{Bartko} amends this approach for use in method
	comparison studies, using the averages of the pairs, as opposed to
	the sums, and their differences. This approach can facilitate
	simultaneous usage of test with the Bland-Altman approach.
	Bartko's test statistic take the form:
	\[ F.test = \frac{(\Sigma d^{2})-SSReg}{2MSReg}
	\]
	% latex table generated in R 2.6.0 by xtable 1.5-5 package
	% Mon Aug 31 15:53:51 2009
	\begin{table}[h!]
		\begin{center}
			\begin{tabular}{lrrrrr}
				\hline
				& Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
				\hline
				Averages & 1 & 0.04 & 0.04 & 0.74 & 0.4097 \\
				Residuals & 10 & 0.60 & 0.06 &  &  \\
				\hline
			\end{tabular}
			\caption{Regression ANOVA of case-wise differences and averages
				for Grubbs Data}
		\end{center}
	\end{table}
	%(calculate using R code $qf(0.95,2,10)$).
	
	For the Grubbs data, $\Sigma d^{2}=5.09 $, $SSReg = 0.60$ and
	$MSreg=0.06$ Therefore the test statistic is $37.42$, with a
	critical value of $4.10$. Hence the means and variance of the
	Fotobalk and Counter chronometers are assumed to be simultaneously
	equal.
	
	Importantly, this approach determines whether there is both
	inter-method bias and precision present, or alternatively if there
	is neither present. It has previously been demonstrated that there
	is a inter-method bias present, but as this procedure does not
	allow for separate testing, no conclusion can be drawn on the
	comparative precision of both methods.
	
	\section{Bartko's Bradley-Blackwood Test}
	This is a regression based approach that performs a simulataneous
	test for the equivalence of means and variances of the respective
	methods.\\
	\begin{equation}
	D = (X_{1}-X_{2})
	\end{equation}
	\begin{equation}
	M = (X_{1} + X_{2}) /2
	\end{equation}
	The Bradley Blackwood Procedure fits D on M as follows:\\
	\begin{equation}
	D = \beta_{0} + \beta_{1}M
	\end{equation}
	\\Both beta values, the intercept and slope, are derived from the respective means and
	standard deviations of their respective data sets.\\
	We determine if the respective means and variances are equal if
	both beta values are simultaneously equal to zero. The Test is
	conducted using an F test, calculated from the results of a
	regression of D on M.
	\\We have identified this approach  to be examined to see if it can
	be used as a foundation for a test perform a test on means and
	variances individually.\\
	Russell et al have suggested this method be used in conjunction
	with a paired t-test , with estimates of slope and intercept.
	
	subsection{t-test}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%  Blackwood Bradley Model         %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	
	%----------------------------------------------------------------------------%

	\section{Bartko's Bradley-Blackwood Test}
	This is a regression based approach that performs a simulataneous
	test for the equivalence of means and variances of the respective
	methods.\\
	\begin{equation}
	D = (X_{1}-X_{2})
	\end{equation}
	\begin{equation}
	M = (X_{1} + X_{2}) /2
	\end{equation}
	The Bradley Blackwood Procedure fits D on M as follows:\\
	\begin{equation}
	D = \beta_{0} + \beta_{1}M
	\end{equation}
	\\Both beta values, the intercept and slope, are derived from the respective means and
	standard deviations of their respective data sets.\\
	We determine if the respective means and variances are equal if
	both beta values are simultaneously equal to zero. The Test is
	conducted using an F test, calculated from the results of a
	regression of D on M.
	\\We have identified this approach  to be examined to see if it can
	be used as a foundation for a test perform a test on means and
	variances individually.\\
	Russell et al have suggested this method be used in conjunction
	with a paired t-test , with estimates of slope and intercept.
	
	subsection{t-test}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%  Blackwood Bradley Model         %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\section{Bland-Altman correlation test}
	
	The approach proposed by \citet{BA83} is a formal test on the
	Pearson correlation coefficient of case-wise differences and means ($\rho_{AD}$). According to the authors, this test is equivalent
	to the `Pitman Morgan Test'. For the Grubbs data, the correlation coefficient estimate ($r_{AD}$) is 0.2625, with a 95\% confidence
	interval of (-0.366, 0.726) estimated by Fishers `$r$ to $z$' transformation \citep*{Cohen}. The null hypothesis ($\rho_{AD}$ =0)
	fail to be rejected. Consequently the null hypothesis of equal variances of each method would also fail to be rejected. There has
	no been no further mention of this particular test in \citet{BA86}, although \citet{BA99} refers to Spearman's rank
	correlation coefficient. \citet{BA99} state that they ` do not see a place for methods of analysis based on hypothesis testing'.
	
	
	\section{Identifiability}
	\citet{DunnSEME} highlights an important issue regarding using models such as structural equation modelling, which is the identifiability problem. This comes as a
	result of there being too many parameters to be estimated. Therefore assumptions about some parameters, or estimators used, must be made so that others can be estimated. For example, in the literature, the variance ratio $\lambda=\frac{\sigma^{2}_{1}}{\sigma^{2}_{2}}$
	must often be assumed to be equal to $1$ \citep{linnet98}. \citet{DunnSEME} considers approaches based on two methods with single measurements on each subject as inadequate for a serious
	study on the measurement characteristics of the methods. This is because there would not be enough data to allow for a meaningful
	analysis. There is, however, a counter-argument that in many practical settings it is very difficult to get replicate observations when, for example, the measurement method requires invasive medical
	procedure.
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Bartko's BB
	\citet{BB89} offer a formal simultaneous hypothesis test for the mean and variance of paired data sets. This approach is based upon regressing the differences of each pair on the sum of each pair, a
	line is fitted to the model, with estimates for intercept and
	slope ($\hat{\beta}_{0}$ and $\hat{\beta}_{1}$). The null
	hypothesis of this test is that the mean ($\mu$) and variance
	($\sigma^{2}$) of both data sets are equal if the slope and
	intercept estimates are equal to zero (i.e $\sigma^{2}_{1} =
	\sigma^{2}_{2}$ and $\mu_{1}=\mu_{2}$ if and only if $\beta_{0}=
	\beta_{1}=0$ )
	
	A test statistic is then calculated from the regression analysis
	of variance values \citep{BB89} and is distributed as `$F$' random
	variable. The degrees of freedom are $\nu_{1}=2$ and $\nu_{2}=n-2$
	(where $n$ is the number of pairs). 
	\citet{Bartko} amends this approach for use in method
	comparison studies, using the averages of the pairs, as opposed to
	the sums, and their differences. This approach can facilitate
	simultaneous usage of test with the Bland-Altman approach.
	Bartko's test statistic take the form:
	\[ F.test = \frac{(\Sigma d^{2})-SSReg}{2MSReg}
	\]
	% latex table generated in R 2.6.0 by xtable 1.5-5 package
	% Mon Aug 31 15:53:51 2009
	\begin{table}[ht]
		\begin{center}
			\begin{tabular}{lrrrrr}
				\hline
				& Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
				\hline
				Averages & 1 & 0.04 & 0.04 & 0.74 & 0.4097 \\
				Residuals & 10 & 0.60 & 0.06 &  &  \\
				\hline
			\end{tabular}
			\caption{Regression ANOVA of case-wise differences and averages
				for Grubbs Data}
		\end{center}
	\end{table}
	%(calculate using R code $qf(0.95,2,10)$).
	
	For the Grubbs data, $\Sigma d^{2}=5.09 $, $SSReg = 0.60$ and $MSreg=0.06$. Therefore the test statistic is $3.742$, with a critical value of $4.10$. Hence the means and variance of the
	Fotobalk and Counter chronometers are assumed to be simultaneously equal.
	
	Importantly, this methodology determines whether there is both inter-method bias and precision present, or alternatively if there
	is neither present. It has previously been demonstrated that there is a inter-method bias present, but as this procedure does not allow for separate testing, no conclusion can be drawn on the comparative precision of both methods.
	
	
	
	%This application of the
	%Grubbs method presumes the existence of this condition, and necessitates
	%replication of observations by means external to and independent of the first
	%means. The Grubbs estimators method is based on the laws of propagation of
	%error. By making three independent simultaneous measurements on the same
	%physical material, it is possible by appropriate mathematical manipulation of
	%the sums and differences of the associated variances to obtain a valid
	%estimate of the precision of the primary means. Application of the Grubbs
	%estimators procedure to estimation of the precision of an apparatus uses
	%the results of a physical test conducted in such a way as to obtain a series
	%of sets of three independent observations.
	
	section{Bartko's Bradley-Blackwood Test}
	This is a regression based
	approach that performs a simultaneous test for the equivalence of
	means and variances of the respective methods.We have identified
	this approach  to be examined to see if it can be used as a
	foundation for a test perform a test on
	means and variances individually.
	\begin{equation}
		D = (X_{1}-X_{2})
	\end{equation}
	\begin{equation}
		M = (X_{1} + X_{2}) /2
	\end{equation}
	The Bradley Blackwood Procedure fits D on M as follows:\\
	\begin{equation}
		D = \beta_{0} + \beta_{1}M
	\end{equation}
	\begin{itemize}
		\item The Bradley Blackwood test is a simultaneous test for bias and
		precision. They propose a regression approach which fits D on M,
		where D is the difference and average of a pair of results.
		\item Both beta values, the intercept and slope, are derived from the respective means and
		standard deviations of their respective data sets.
		\item We determine if the respective means and variances are equal if
		both beta values are simultaneously equal to zero. The Test is
		conducted using an F test, calculated from the results of a
		regression of D on M.
		\item We have identified this approach  to be examined to see if it can
		be used as a foundation for a test perform a test on means and
		variances individually.
		\item Russell et al have suggested this method be used in conjunction
		with a paired t-test , with estimates of slope and intercept.
	\end{itemize}
	%subsection{t-test}
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%  Blackwood Bradley Model         %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

	\section{Bradley-Blackwood Test (Kevin Hayes Talk)}
	%--------------------------------------------------------------------------------%
	% KH - UW
	
	This work considers the problem of testing $\mu_1$ = $\mu_2$ and $\sigma^2_1 = \sigma^2_2$ using a random sample from a bivariate normal distribution with parameters $(\mu_1, \mu_2, \sigma^2_1, \sigma^2_2, \rho)$. 
	
	The new contribution is a decomposition of the Bradley-Blackwood test statistic (\textit{Bradley and Blackwood, 1989})for the simultaneous test of {$\mu_1$ = $\mu_2$; $\sigma^2_1 = \sigma^2_2$}  as a sum of two statistics. 
	
	One is equivalent to the Pitman-Morgan (\textit{Pitman, 1939; Morgan, 1939}) test statistic 
	for $\sigma^2_1 = \sigma^2_2$ and the other one is a new alternative to the standard paired-t test of $\mu_D = \mu_1 = \mu_2 = 0$. 
	
	Surprisingly, the classic Student paired-t test makes no assumptions about the equality (or otherwise) of the 
	variance parameters. 
	
	The power functions for these tests are quite easy to derive, and show that when $\sigma^2_1 = \sigma^2_2$, 
	the paired t-test has a slight advantage over the new alternative in terms of power, but when $\sigma^2_1 \neq \sigma^2_2$, the 
	new test has substantially higher power than the paired-t test.
	
	While Bradley and Blackwood provide a test on the joint hypothesis of equal means and equal variances their regression based approach does not separate these two issues.
	
	The rejection of the joint hypothesis may be 
	due to two groups with unequal means and unequal variances; unequal means and equal variances, or equal means and unequal variances. We propose an approach for resolving this (model selection) problem in a manner controlling the magnitudes of the relevant type I error probabilities.
	
	
	\section{Regression Methods for Method Comparison}
	Conventional regression models are estimated using the ordinary
	least squares (OLS) technique, and are referred to as `Model I
	regression' \citep{CornCoch,ludbrook97}. A key feature of Model I
	models is that the independent variable is assumed to be measured
	without error. However this assumption invalidates simple linear
	regression for use in method comparison studies, as both methods
	must be assumed to be measured with error \citep{BA83,ludbrook97}.
	
	The use of regression models that assumes the presence of error in both variables $X$ and $Y$ have been proposed for use instead
	\citep{CornCoch,ludbrook97}. These methodologies are collectively known as `Model II regression'. They differ in the method used to
	estimate the parameters of the regression.
	
	Regression estimates depend on formulation of the model. A formulation with one method considered as the $X$ variable will yield different estimates for a formulation where it is the $Y$
	variable. With Model I regression, the models fitted in both cases will entirely different and inconsistent. However with Model II
	regression, they will be consistent and complementary.
	
	Regression approaches are useful for a making a detailed examination of the biases across the range of measurements, allowing bias to be decomposed into fixed bias and proportional bias.
	Fixed bias describes the case where one method gives values that are consistently different to the other across the whole range. Proportional
	bias describes the difference in measurements getting progressively greater, or smaller, across the range of measurements. A measurement method may have either an attendant fixed bias or proportional bias, or both. \citep{ludbrook97}. Determination of these biases shall be discussed in due course.
	
	
	
	%================================================================================================= %
	\section{Deming Regression}
	
	As stated previously, the fundamental flaw of simple linear regression is that it allows for measurement error in one variable only. This causes a downward biased slope estimate.
	
	Deming regression is a regression fitting approach that assumes error in both variables. Deming regression is recommended by \citet*{CornCoch} as the
	preferred Model II regression for use in method comparison studies.
	The sum of squared distances from measured sets of values to the regression line is minimized at an angles specified by the ratio $\lambda$ of the residual variance of both variables. I
	When $\lambda$ is one, the angle is 45 degrees. In ordinary linear regression, the distances are minimized in the vertical directions \citep{linnet99}.
	In cases involving only single measurements by each method, $\lambda$ may be unknown and is therefore assumes a value of one. While this will produce biased estimates, they are less biased than ordinary linear regression.
	
	The Bland Altman Plot is uninformative about the comparative influence of proportional bias and fixed bias. Model II approaches, such as Deming regression,  can provide independent tests for
	both types of bias.
	
	For a given $\lambda$, \citet{Kummel} derived the following estimate that would later be used for the Deming regression slope
	parameter. The intercept estimate $\alpha$ is simply estimated in the same way as in conventional linear
	regression, by using the identity $\bar{Y}-\hat{\beta}\bar{X}$;
	\begin{equation}
		\hat{\beta} =\quad \frac{S_{yy} - \lambda S_{xx}+[(S_{yy} -
			\lambda S_{xx})^{2}+ 4\lambda S^{2}_{xy}]^{1/2}}{2S_{xy}}
	\end{equation},
	with $\lambda$ as the variance ratio. As stated previously $\lambda$ is often unknown, and therefore must be assumed to equal one. \citet{CarollRupert} states that Deming
	regression is acceptable only when the precision ratio ($\lambda$,in their paper as $\eta$) is correctly specified, but in practice this is often not the case, with the $\lambda$ being underestimated. Several candidate models, with varying variance ratios may be fitted, and estimates of the slope and intercept are produced. However no model selection information is available to determine the best fitting model.
	
	As with conventional regression methodologies, Deming regression calculates an estimate for both the slope and intercept for the
	fitted line, and standard errors thereof. Therefore there is sufficient information to carry out hypothesis tests on both
	estimates, that are informative about presence of fixed and proportional bias.
	
	A $95\%$ confidence interval for the intercept estimate can be used to test the intercept, and hence fixed bias, is equal to
	zero. This hypothesis is accepted if the confidence interval for the estimate contains the value $0$ in its range. Should this be,
	it can be concluded that fixed bias is not present. Conversely, if the hypothesis is rejected, then it is concluded that the
	intercept is non zero, and that fixed bias is present.
	
	Testing for proportional bias is a very similar procedure. The
	$95\%$ confidence interval for the slope estimate can be used to
	test the hypothesis that the slope is equal to $1$. This
	hypothesis is accepted if the confidence interval for the estimate
	contains the value $1$ in its range. If the hypothesis is
	rejected, then it is concluded that the slope is significant
	different from $1$ and that a proportional bias exists.
	
	For convenience, a new data set shall be introduced to demonstrate
	Deming regression. Measurements of transmitral volumetric flow
	(MF) by doppler echocardiography, and left ventricular stroke
	volume (SV) by cross sectional echocardiography in 21 patients
	with aortic valve disease are tabulated in \citet{zhang}. This
	data set features in the discussion of method comparison studies
	in \citet[p.398]{AltmanBook} .
	
	
	% latex table generated in R 2.6.0 by xtable 1.5-5 package
	% Tue Sep 01 13:31:17 2009
	\begin{table}[h!]
		\begin{center}
			\begin{tabular}{|c|c|c||c|c|c||c|c|c|}
				\hline
				Patient & MF  & SV  & Patient & MF  & SV  & Patient & MF  & SV \\
				&($cm^{3}$)&  ($cm^{3}$) & &($cm^{3}$)&  ($cm^{3}$) & &($cm^{3}$)&  ($cm^{3}$)
				\\
				\hline
				1 & 47 & 43 &  8 & 75 & 72 &  15 & 90 & 82 \\
				2 & 66 & 70 & 9 & 79 & 92 &  16 & 100 & 100 \\
				3 & 68 & 72 & 10 & 81 & 76 & 17 & 104 & 94 \\
				4 & 69 & 81 & 11 & 85 & 85 &  18 & 105 & 98 \\
				5 & 70 & 60 & 12 & 87 & 82 & 19 & 112 & 108 \\
				6 & 70 & 67 & 13 & 87 & 90 & 20 & 120 & 131 \\
				7 & 73 & 72 & 14 & 87 & 96 &  21 & 132 & 131 \\
				
				\hline
			\end{tabular}
			\caption{Transmitral volumetric flow(MF) and left ventricular
				stroke volume (SV) in 21 patients. (Zhang et al 1986)}
		\end{center}
	\end{table}
	
	
	\begin{figure}[h!]
		% Requires \usepackage{graphicx}
		\includegraphics[width=130mm]{images/ZhangDeming.jpeg}
		\caption{Deming Regression For Zhang's Data}\label{ZhangDeming}
	\end{figure}
	
	
	\citet{CarollRupert} states that Deming's
	regression is acceptable only when the precision ratio ($\lambda$,
	in their paper as $\eta$) is correctly specified, but in practice
	this is often not the case, with the $\lambda$ being
	underestimated.
	\newpage
		\section{Deming Regression}
		
		As stated previously, the fundamental flaw of simple linear regression is that it allows for measurement error in one variable only. This causes a downward biased slope estimate.
		
		Deming regression is a regression fitting approach that assumes error in both variables. Deming regression is recommended by \citet*{CornCoch} as the
		preferred Model II regression for use in method comparison
		studies.
		The sum of squared distances from measured sets of values to the regression line is minimized at an angles specified by the ratio $\lambda$ of the residual variance of both variables. I
		When $\lambda$ is one, the angle is 45 degrees. In ordinary linear regression, the distances are minimized in the vertical directions \citep{linnet99}.
		In cases involving only single measurements by each method, $\lambda$ may be unknown and is therefore assumes a value of one. While this will bias the estimates, it is less biased than ordinary linear regression.
		
		The Bland Altman Plot is
		uninformative about the comparative influence of proportional bias
		and fixed bias. Model II approaches, such as Deming regression,  can provide independent tests for
		both types of bias.
		
		For a given $\lambda$, \citet{Kummel} derived the following
		estimate that would later be used for the Deming regression slope
		parameter. The intercept estimate $\alpha$
		is simply estimated in the same way as in conventional linear
		regression, by using the identity $\bar{Y}-\hat{\beta}\bar{X}$;
		\begin{equation}
		\hat{\beta} =\quad \frac{S_{yy} - \lambda S_{xx}+[(S_{yy} -
			\lambda S_{xx})^{2}+ 4\lambda S^{2}_{xy}]^{1/2}}{2S_{xy}}
		\end{equation},
		with $\lambda$ as the variance ratio. As stated previously $\lambda$ is often unknown, and therefore must be assumed to equal one. \citet{CarollRupert} states that Deming
		regression is acceptable only when the precision ratio ($\lambda$,in their paper as $\eta$) is correctly specified, but in practice this is often not the case, with the $\lambda$ being underestimated. Several candidate models, with varying variance ratios may be fitted, and estimates of the slope and intercept are produced. However no model selection information is available to determine the best fitting model.
		
		As with conventional regression methodologies, Deming regression
		calculates an estimate for both the slope and intercept for the
		fitted line, and standard errors thereof. Therefore there is
		sufficient information to carry out hypothesis tests on both
		estimates, that are informative about presence of fixed and
		proportional bias.
		
		A $95\%$ confidence interval for the intercept estimate can be
		used to test the intercept, and hence fixed bias, is equal to
		zero. This hypothesis is accepted if the confidence interval for
		the estimate contains the value $0$ in its range. Should this be,
		it can be concluded that fixed bias is not present. Conversely, if
		the hypothesis is rejected, then it is concluded that the
		intercept is non zero, and that fixed bias is present.
		
		Testing for proportional bias is a very similar procedure. The
		$95\%$ confidence interval for the slope estimate can be used to
		test the hypothesis that the slope is equal to $1$. This
		hypothesis is accepted if the confidence interval for the estimate
		contains the value $1$ in its range. If the hypothesis is
		rejected, then it is concluded that the slope is significant
		different from $1$ and that a proportional bias exists.
		
		For convenience, a new data set shall be introduced to demonstrate
		Deming regression. Measurements of transmitral volumetric flow
		(MF) by doppler echocardiography, and left ventricular stroke
		volume (SV) by cross sectional echocardiography in 21 patients
		with aortic valve disease are tabulated in \citet{zhang}. This
		data set features in the discussion of method comparison studies
		in \citet[p.398]{AltmanBook} .
		
		
		% latex table generated in R 2.6.0 by xtable 1.5-5 package
		% Tue Sep 01 13:31:17 2009
		\begin{table}[h!]
			\begin{center}
				\begin{tabular}{|c|c|c||c|c|c||c|c|c|}
					\hline
					Patient & MF  & SV  & Patient & MF  & SV  & Patient & MF  & SV \\
					&($cm^{3}$)&  ($cm^{3}$) & &($cm^{3}$)&  ($cm^{3}$) & &($cm^{3}$)&  ($cm^{3}$)
					\\
					\hline
					1 & 47 & 43 &  8 & 75 & 72 &  15 & 90 & 82 \\
					2 & 66 & 70 & 9 & 79 & 92 &  16 & 100 & 100 \\
					3 & 68 & 72 & 10 & 81 & 76 & 17 & 104 & 94 \\
					4 & 69 & 81 & 11 & 85 & 85 &  18 & 105 & 98 \\
					5 & 70 & 60 & 12 & 87 & 82 & 19 & 112 & 108 \\
					6 & 70 & 67 & 13 & 87 & 90 & 20 & 120 & 131 \\
					7 & 73 & 72 & 14 & 87 & 96 &  21 & 132 & 131 \\
					
					\hline
				\end{tabular}
				\caption{Transmitral volumetric flow(MF) and left ventricular
					stroke volume (SV) in 21 patients. (Zhang et al 1986)}
			\end{center}
		\end{table}
		
		%\begin{figure}[h!]
		%	% Requires \usepackage{graphicx}
		%	\includegraphics[width=130mm]{ZhangDeming.jpeg}
		%	\caption{Deming Regression For Zhang's Data}\label{ZhangDeming}
		%\end{figure}
		
		
		\citet{CarollRupert} states that Deming's
		regression is acceptable only when the precision ratio ($\lambda$,
		in their paper as $\eta$) is correctly specified, but in practice
		this is often not the case, with the $\lambda$ being
		underestimated.
		\newpage
	\section{Other Types of Studies}
	\citet{lewis} categorize method comparison studies into three
	different types.  The key difference between the first two is
	whether or not a `gold standard' method is used. In situations
	where one instrument or method is known to be `accurate and
	precise', it is considered as the`gold standard' \citep{lewis}. A
	method that is not considered to be a gold standard is referred to
	as an `approximate method'. In calibration studies they are
	referred to a criterion methods and test methods respectively.
	
	
	\textbf{1. Calibration problems}. The purpose is to establish a
	relationship between methods, one of which is an approximate
	method, the other a gold standard. The results of the approximate
	method can be mapped to a known probability distribution of the
	results of the gold standard \citep{lewis}. (In such studies, the
	gold standard method and corresponding approximate method are
	generally referred to a criterion method and test method
	respectively.) \citet*{BA83} make clear that their methodology is
	not intended for calibration problems.
	
	\bigskip \textbf{2. Comparison problems}. When two approximate
	methods, that use the same units of measurement, are to be
	compared. This is the case which the Bland-Altman methodology is
	specfically intended for, and therefore it is the most relevant of
	the three.
	
	\bigskip \textbf{3. Conversion problems}. When two approximate
	methods, that use different units of measurement, are to be
	compared. This situation would arise when the measurement methods
	use 'different proxies', i.e different mechanisms of measurement.
	\citet{lewis} deals specifically with this issue. In the context
	of this study, it is the least relevant of the three.
	
	\citet[p.47]{DunnSEME} cautions that`gold standards' should not be
	assumed to be error free. `It is of necessity a subjective
	decision when we come to decide that a particular method or
	instrument can be treated as if it was a gold standard'. The
	clinician gold standard , the sphygmomanometer, is used as an
	example thereof.  The sphygmomanometer `leaves considerable room
	for improvement' \citep{DunnSEME}. \citet{pizzi} similarly
	addresses the issue of glod standards, `well-established gold
	standard may itself be imprecise or even unreliable'.
	
	
	The NIST F1 Caesium fountain atomic clock is considered to be the
	gold standard when measuring time, and is the primary time and
	frequency standard for the United States. The NIST F1 is accurate
	to within one second per 60 million years \citep{NIST}.
	
	Measurements of the interior of the human body are, by definition,
	invasive medical procedures. The design of method must balance the
	need for accuracy of measurement with the well-being of the
	patient. This will inevitably lead to the measurement error as
	described by \citet{DunnSEME}. The magnetic resonance angiogram,
	used to measure internal anatomy,  is considered to the gold
	standard for measuring aortic dissection. Medical test based upon
	the angiogram is reported to have a false positive reporting rate
	of 5\% and a false negative reporting rate of 8\%. This is
	reported as sensitivity of 95\% and a specificity of 92\%
	\citep{ACR}.
	
	In literature they are, perhaps more accurately, referred to as
	`fuzzy gold standards' \citep{phelps}. Consequently when one of the methods is
	essentially a fuzzy gold standard, as opposed to a `true' gold
	standard, the comparison of the criterion and test methods should
	be consider in the context of a comparison study, as well as of a
	calibration study.
	
	\newpage
	
	\section{Methods of assessing agreement}
	
	\begin{enumerate}
		\item Pearson's Correlation Coefficient\item Intraclass
		correlation coefficient \item Bland Altman Plot \item Bartko's
		Ellipse (1994) \item Blackwood Bradley Test \item Lin's
		Reproducibility Index \item Luiz Step function
	\end{enumerate}
	
	Bland and Altman attend to the issue of repeated measures in
	$1996$.
	\\
	Repeated measurements on several subjects can be used to quantify
	measurement error, the variation between measurements of the same
	quantity on the same individual.
	\\
	Bland and Altman discuss two metrics for measurement error; the
	within-subject standard deviation ,and the correlation
	coefficient.
	
	The above plot incorporates both the conventional limits of
	agreement ( the inner pair of dashed lines), the `t' limits of
	agreement ( the outer pair of dashed lines) centred around the
	inter-method bias (indicated by the full line). This plot is
	intended for expository purposes only, as the sample size is
	small.
	
	
	
	
	

	\section{Bland Altman Plots In Literature}
	\citet{mantha} contains a study the use of Bland Altman plots of
	44 articles in several named journals over a two year period. 42
	articles used Bland Altman's limits of agreement, wit the other
	two used correlation and regression analyses. \citet{mantha}
	remarks that 3 papers, from 42 mention predefined maximum width
	for limits of agreement which would not impair medical care.
	
	The conclusion of \citet{mantha} is that there are several
	inadequacies and inconsistencies in the reporting of results ,and
	that more standardization in the use of Bland Altman plots is
	required. The authors recommend the prior determination of limits
	of agreement before the study is carried out. This contention is
	endorsed by \citet{lin}, which makes a similar recommendation for
	the sample size, noting that\emph{sample sizes required either was
		not mentioned or no rationale for its choice was given}.
	
	\begin{quote}
		In order to avoid the appearance of "data dredging", both the
		sample size and the (limits of agreement) should be specified and
		justified before the actual conduct of the trial. \citep{lin}
	\end{quote}
	
	\citet{Dewitte} remarks that the limits of agreement should be
	compared to a clinically acceptable difference in measurements.
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%4 Inappropriate assessment of Agreement       %%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	
	\section{Gold Standard} This is considered to be the most
	accurate measurement of a particular parameter.

	\section{Agreement} Bland and Altman (1986) define Perfect
	agreement as 'The case where all of the pairs of rater data lie
	along the line of equality'. The Line of Equality is defined as
	the 45 degree line passing through the origin, or X=Y on a XY
	plane.
	
	\section{Lack Of Agreement}
	\begin{enumerate}
		\item Constant Bias\item Proportional Bias
	\end{enumerate}
	
	\section*{Constant Bias} This is a form of systematic
	deviations estimated as the average difference between the test
	and the reference method
	
	
	\section*{Proportional Bias} Two methods may agree on
	average, but they may exhibit differences over a range of

	\section{Bland Altman plots using 'Gold Standard' raters}
	According to Bland and Altman, one should use the methodology
	previous outlined, even when one of the raters is a Gold Standard.
	
	
	\section{Bias Detection}
	further to this method, the presence of constant bias may be
	indicated if the average value differences is not equal to zero.
	Bland and Altman does, however, indicate the indication of absence
	of bias does not provide sufficient information to allow a
	judgement as to whether or not one method can be substituted for
	another.
	
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%---------------------------------------------%
\chapter{Repeated Measurements and Repeatability}
	
	
	
	\section{Definition of Replicate measurements}
	Further to \citet{BA99}, a formal definition is required of what exactly replicate measurements are
	
	\emph{By replicates we mean two or more measurements on the same
		individual taken in identical conditions. In general this requirement means that the
		measurements are taken in quick succession.}
	
	Roy accords with Bland and Altman?s definition of a replicate, as being two or more measurements on the same individual under identical conditions. Roy allows the assumption that replicated measurements are equi-correlated. Roy allows unequal numbers of replicates.
	
	Replicate measurements are linked over time. However the method can be easily extended to cover situations where they are not linked over time.
	%----------------------------------------------------------------------------%
	\section{Model for replicate measurements}
	
	We generalize the single measurement model for the replicate measurement case, by additionally specifying replicate values. Let $y_{mir}$ be the $r-$th replicate measurement for subject ``i" made by method ``m". Further to \citet{barnhart} fixed effect can be expressed with a single term $\alpha_{mi}$, which incorporate the true value $\mu_i$.
	
	\[ y_{mir} = \mu_{i} + \alpha_{m} + e_{mir}  \]
	
	Combining fixed effects \citep{barnhart}, we write,
	
	\[ y_{mir} = \alpha_{mi} + e_{mir}.\]
	
	The following assumptions are required
	
	\begin{itemize}
		\item $e_{mir}$ is independent of the fixed effects with mean $\mbox{E}(e_{mir}) = 0$.
		\item Further to \citet{barnhart} between-item and within-item variances $\mbox{Var}(\alpha_{mi}) = \sigma^2_{Bm}$ and $\mbox{Var}(e_{mir}) = \sigma^2_{Wm}$
		%	\item In keeping with \citet{Roy}, these variance shall be considered as part of the between-item variance covariance matrix $\boldsymbol{D}$ and the within-item variance covariance matrix  $\boldsymbol{\Sigma}$
		%	respectively, and will be denoted accordingly ( i.e. $d^2_{m}$ and $\sigma^2_{m}$).
		%	\item Additionally, the total variability of method "m", denoted $\omega^2_m$ is the sum of the within-item and between-item variabilities.
		%	
		%	\[ \omega^2_m = d^2_{m}+ \sigma^2_{m} \]
		
	\end{itemize}
	\section{Carstensen's Model}
	
	
	
	\citet{BXC2004} presents a model to describe the relationship between a value of measurement and its
	real value. The non-replicate case is considered first, as it is the context of the Bland Altman plots. This model assumes that inter-method bias is the only difference between the two methods.
	
	A measurement $y_{mi}$ by method $m$ on individual $i$ is formulated as follows;
	\begin{equation}
		y_{mi}  = \alpha_{m} + \mu_{i} + e_{mi} \qquad  e_{mi} \sim
		\mathcal{N}(0,\sigma^{2}_{m})
	\end{equation}
	The differences are expressed as $d_{i} = y_{1i} - y_{2i}$. For the replicate case, an interaction term $c$ is added to the model, with an associated variance component. All the random effects are assumed independent, and that all replicate measurements are assumed to be exchangeable within each method.
	
	\begin{equation}
		y_{mir}  = \alpha_{m} + \mu_{i} + c_{mi} + e_{mir}, \qquad  e_{mi}
		\sim \mathcal{N}(0,\sigma^{2}_{m}), \quad c_{mi} \sim \mathcal{N}(0,\tau^{2}_{m}).
	\end{equation}
	%----
	
	Of particular importance is terms of the model, a true value for item $i$ ($\mu_{i}$).  The fixed effect of Roy's model comprise of an intercept term and fixed effect terms for both methods, with no reference to the true value of any individual item. A distinction can be made between the two models: Roy's model is a standard LME model, whereas Carstensen's model is a more complex additive model.
	
	\bigskip
	\section{Two Way ANOVA}
	
	\citet{BXC2008} develop their model from a standard two-way analysis of variance model, reformulated for the case of replicate measurements, with random effects terms specified as appropriate. 
	Their model describing $y_{mir} $, again the $r$th replicate measurement on the $i$th item by the $m$th method ($m=1,2,$ $i=1,\ldots,N,$ and $r = 1,\ldots,n$), can be written as
	\begin{equation}\label{BXC-model}
		y_{mir}  = \alpha_{m} + \mu_{i} + a_{ir} + c_{mi} + \epsilon_{mir}.
	\end{equation}
	The fixed effects $\alpha_{m}$ and $\mu_{i}$  represent the intercept for method $m$ and the `true value' for item $i$ respectively. The random-effect terms comprise an item-by-replicate interaction term $a_{ir} \sim \mathcal{N}(0,\varsigma^{2})$, a method-by-item interaction term $c_{mi} \sim \mathcal{N}(0,\tau^{2}_{m}),$ and model error terms $\varepsilon \sim \mathcal{N}(0,\varphi^{2}_{m}).$ All random-effect terms are assumed to be independent.
	For the case when replicate measurements are assumed to be exchangeable for item $i$, $a_{ir}$ can be removed.
	
	The model expressed in (2) describes measurements by $m$ methods, where $m = \{1,2,3\ldots\}$. Based on the model expressed in (2), \citet{BXC2008} compute the limits of agreement as
	\[
	\alpha_1 - \alpha_2 \pm 2 \sqrt{ \tau^2_1 +  \tau^2_2 +  \varphi^2_1 +  \varphi^2_2 }
	\]
	\citet{BXC2008} notes that, for $m=2$,  separate estimates of $\tau^2_m$ can not be obtained. To overcome this, the assumption of equality, i.e. $\tau^2_1 = \tau^2_2$ is required.
	
	
	%----------------------------------------------------------------------------
	\section{Statistical Model For Replicate Measurements}
	Let $y_{Aij}$ and $y_{Bij}$ be the $j$th repeated observations of the variables of interest $A$ and $B$ taken on the $i$th subject. The number of repeated measurements for each variable may differ for each individual.
	Both variables are measured on each time points. Let $n_{i}$ be the number of observations for each variable, hence $2\times n_{i}$ observations in total.
	
	It is assumed that the pair $y_{Aij}$ and $y_{Bij}$ follow a bivariate normal distribution.
	\begin{eqnarray}
		\left(
		\begin{array}{c}
			y_{Aij} \\
			y_{Bij} \\
		\end{array}
		\right) \sim \mathcal{N}(
		\boldsymbol{\mu}, \boldsymbol{\Sigma})\mbox{   where } \boldsymbol{\mu} = \left(
		\begin{array}{c}
			\mu_{A} \\
			\mu_{B} \\
		\end{array}
		\right)
	\end{eqnarray}
	The matrix $\boldsymbol{\Sigma}$ represents the variance component matrix between response variables at a given time point $j$.
	\begin{equation}
		\boldsymbol{\Sigma} = \left( \begin{array}{cc}
			\sigma^2_{A} & \sigma_{AB} \\
			\sigma_{AB} & \sigma^2_{B}\\
		\end{array}\right)
	\end{equation}
	$\sigma^2_{A}$ is the variance of variable $A$, $\sigma^2_{B}$ is the variance of variable $B$ and $\sigma_{AB}$ is the covariance of the two variable. It is assumed that $\boldsymbol{\Sigma}$ does not depend on a particular time point, and is the same over all time points.
	
	\section{Exchangeable and Linked measurements}
	\section{Sampling Scheme : Linked and Unlinked Replicates}
	Measurements taken in quick succession by the same observer using the same instrument on the same subject can be considered true replicates. \citet{ARoy2009} notes that some measurements may not be `true' replicates.
	
	Roy's methodology assumes the use of `true replicates'. However data may not be collected in this way. In such cases, the correlation matrix on the replicates may require a different structure, such as the autoregressive order one $AR(1)$ structure. However determining MLEs with such a structure would be computational intense, if possible at all.
	
	
	
	\emph{
		One important feature of replicate observations is that they should be independent
		of each other. In essence, this is achieved by ensuring that the observer makes each
		measurement independent of knowledge of the previous value(s). This may be difficult
		to achieve in practice.} (Check who said this
	)
	%----------------------------------------------------------------------------%
	
	
	%-----------------------------------------------------------------------------------------------------%
	\section{Replicate measurements}
	\citet{ARoy2009} accords with Bland and Altman?s definition of a replicate, as being two or more measurements on the same individual under identical conditions.
	Roy allows the assumption that replicated measurements are equi-correlated.
	Roy allows unequal numbers of replicates.
	
	Replicate measurements are linked over time. However the method can be easily extended to cover situations where they are not linked over time.
	
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	In this model , the variances of the random effects must depend on
	$m$, since the different methods do not necessarily measure on the
	same scale, and different methods naturally must be assumed to
	have different variances. \citet{BXC2004} attends to the issue of
	comparative variances.
	
	\newpage
	\citet{BA99} also remark that an important feature of replicate observations is that they should be independent
	of each other. This issue is addressed by \citet{BXC2010}, in terms of exchangeability and linkage. Carstenen advises that repeated measurements come in two \emph{substantially different} forms, depending on the circumstances of their measurement: exchangable and linked.
	
	Repeated measurements are said to be exchangeable if no relationship exists between successive measurements across measurements. If the condition of exchangeability exists, a group of measurement of the same item determined by the same method can be re-arranged in any permutation without prejudice to proper analysis. There is no reason to believe that the true value of the underlying variable has changed over the course of the measurements.
	
	Exchangeable repeated measurements can be treated as true replicates. For the purposes of method comparison studies the following remarks can be made. The $r-$th measurement made by method $1$ has no special correspondence to the $r-$th measurement made by method $2$, and consequently any pairing of repeated measurements are as good as each other.
	
	
	%----------------------------------------------------------------------------%
	
	Repeated measurements are said to be linked if a direct correspondence exists between successive measurements across measurements, i.e. pairing. Such measurements are commonly made with a time interval between them, but simultaneously for both methods. Paired measurements are exchangeable, but individual measurements are not.
	
	If the paired measurements are taken
	in a short period of time so that no real systemic changes can take place on each item, they can be considered true replicates.
	Should enough time elapse for systemic changes, linked repeated measurements can not be treated as true replicates.
	
	
	\section{Repeated Measurements in LME models}
	
	In many statistical analyzes, the need to determine parameter estimates where multiple measurements are available on each of a set of variables often arises. Further to \citet{lam}, \citet{hamlett} performs an analysis of the correlation of replicate measurements, for two variables of interest, using LME models.
	
	Let $y_{Aij}$ and $y_{Bij}$ be the $j$th repeated observations of the variables of interest $A$ and $B$ taken on the $i$th subject. The number of repeated measurements for each variable may differ for each individual.
	Both variables are measured on each time points. Let $n_{i}$ be the number of observations for each variable, hence $2\times n_{i}$ observations in total.
	
	It is assumed that the pair $y_{Aij}$ and $y_{Bij}$ follow a bivariate normal distribution.
	\begin{eqnarray*}
		\left(
		\begin{array}{c}
			y_{Aij} \\
			y_{Bij} \\
		\end{array}
		\right) \sim \mathcal{N}(
		\boldsymbol{\mu}, \boldsymbol{\Sigma})\mbox{   where } \boldsymbol{\mu} = \left(
		\begin{array}{c}
			\mu_{A} \\
			\mu_{B} \\
		\end{array}
		\right)
	\end{eqnarray*}
	
	The matrix $\Sigma$ represents the variance component matrix between response variables at a given time point $j$.
	
	\[
	\boldsymbol{\Sigma} = \left( \begin{array}{cc}
	\sigma^2_{A} & \sigma_{AB} \\
	\sigma_{AB} & \sigma^2_{B}\\
	\end{array}   \right)
	\]
	
	$\sigma^2_{A}$ is the variance of variable $A$, $\sigma^2_{B}$ is the variance of variable $B$ and $\sigma_{AB}$ is the covariance of the two variable. It is assumed that $\boldsymbol{\Sigma}$ does not depend on a particular time point, and is the same over all time points.
	
	%------------------------------------------------------------------------------%
	
	
	\section{Linked replicates}
	
	\citet{BXC2008} proposes the addition of an random effects term to their model when the replicates are linked. This term is used to describe the `item by replicate' interaction, which is independent of the methods. This interaction is a source of variability independent of the methods. Therefore failure to account for it will result in variability being wrongly attributed to the methods.
	
	\citet{BXC2008} introduces a second data set; the oximetry study. This study done at the Royal Children�s Hospital in
	Melbourne to assess the agreement between co-oximetry and pulse oximetry in small babies.
	
	In most cases, measurements were taken by both method at three different times. In some cases there are either one or two pairs of measurements, hence the data is unbalanced. \citet{BXC2008} describes many of the children as being very sick, and with very low oxygen saturations levels. Therefore it must be assumed that a biological change can occur in interim periods, and measurements are not true replicates.
	
	\citet{BXC2008} demonstrate the necessity of accounting for linked replicated by comparing the limits of agreement from the `oximetry' data set using a model with the additional term, and one without. When the interaction is accounted for the limits of agreement are (-9.62,14.56). When the interaction is not accounted for, the limits of agreement are (-11.88,16.83). It is shown that the failure to include this additional term results in an over-estimation of the standard deviations of differences.
	
	Limits of agreement are determined using Roy's methodology, without adding any additional terms, are found to be consistent with the `interaction' model; $(-9.562, 14.504 )$. Roy's methodology assumes that replicates are linked. However, following Carstensen's example, an addition interaction term is added to the implementation of Roy's model to assess the effect, the limits of agreement estimates do not change. However there is a conspicuous difference in within-subject matrices of Roy's model and the modified model (denoted $1$ and $2$ respectively);
	\begin{equation}
		\hat{\boldsymbol{\Lambda}}_{1}= \left(\begin{array}{cc}
			16.61 &	11.67\\
			11.67 & 27.65 \end{array}\right) \qquad
		\boldsymbol{\hat{\Lambda}}_{2}= \left( \begin{array}{cc}
			7.55 & 2.60 \\
			2.60 & 18.59 \end{array} \right). 
	\end{equation}
	
	\noindent (The variance of the additional random effect in model $2$ is $3.01$.)
	
	\citet{akaike} introduces the Akaike information criterion ($AIC$), a model 
	selection tool based on the likelihood function. Given a data set, candidate models
	are ranked according to their AIC values, with the model having the lowest AIC being considered the best fit.Two candidate models can said to be equally good if there is a difference of less than $2$ in their AIC values.
	
	The Akaike information criterion (AIC) for both models are $AIC_{1} = 2304.226$ and $AIC_{2} = 2306.226$ , indicating little difference in models. The AIC values for the Carstensen `unlinked' and `linked' models are $1994.66$ and $1955.48$ respectively, indicating an improvement by adding the interaction term.
	
	The $\boldsymbol{\hat{\Lambda}}$ matrices are informative as to the difference between Carstensen's unlinked and linked models. For the oximetry data, the covariance terms (given above as 11.67 and 2.6 respectively ) are of similar magnitudes to the variance terms. Conversely for the `fat' data the covariance term ($-0.00032$) is negligible. When the interaction term is added to the model, the covariance term remains negligible. (For the `fat' data, the difference in AIC values is also approximately $2$).
	
	To conclude, Carstensen's models provided a rigorous way to determine limits of agreement, but don't provide for the computation of $\boldsymbol{\hat{D}}$ and $\boldsymbol{\hat{\Lambda}}$. Therefore the test's proposed by \citet{roy} can not be implemented. Conversely, accurate limits of agreement as determined by Carstensen's model may also be found using Roy's method. Addition of the interaction term erodes the capability of Roy's methodology to compare candidate models, and therefore shall not be adopted.
	
	Finally, to complement the blood pressure (i.e.`J vs S') method comparison from the previous section (i.e.`J vs S'), the limits of agreement are $15.62 \pm 1.96 \times 20.33 = (-24.22, 55.46)$.)
	\newpage
	
	\section{Coefficient of Repeatability}
	\section{Repeatability}
	As mentioned previously, \citet{Barnhart} emphasizes the importance of repeatability as part of an overall method comparison study. The coefficient of repeatability was proposed by \citet{BA99}, and is referenced in subsequent papers, such as \citet{BXC2008}. The coefficient of repeatability is a measure of how well a
	measurement method agrees with itself over replicate measurements
	\citep{BA99}. The coefficient of repeatability is a measure of how well a
	measurement method agrees with itself over replicate measurements
	\citep{BA99}. Once the the standard deviations of the differences between the two measurements (in some texts called the residual standard deviation or within-item variability) $sigma_m$ is determined, the
	computation of the coefficients of repeatability for both methods
	is straightforward. The coefficient is calculated from the (in some texts called the residual standard deviation) as  $1.96 \times \sqrt{2} \times \sigma_m$ = $2.83 \sigma_m$).
	
	\section{Coefficient of Repeatability}
	The coefficient of repeatability is a measure of how well a
	measurement method agrees with itself over replicate measurements
	\citep{BA99}. Once the within-item variability is known, the
	computation of the coefficients of repeatability for both methods
	is straightforward.
	
	
	%------------------------------------------------------------------------------%
	
	\section{Repeatability coefficient}
	\citet{BA99} introduces the repeatability coefficient for a method, which is defined as the upper limits of a prediction interval for the absolute difference between two measurements by the same
	method on the same item under identical circumstances \citep{BXC2008}.
	
	$\sigma^2_{x}$ is the within-subject variance of method $x$. The repeatability coefficient is $2.77 \sigma_{x}$ (i.e. $1.96 \times \sqrt{2} \sigma_{x}$). For $95\%$ of subjects, two replicated measurement by the same method will be within this repeatability coefficient.
	

	\section{Replicate Measurements}
	
	Thus far, the formulation for comparison of two measurement
	methods is one where one measurement by each method is taken on
	each subject. Should there be two or more measurements by each
	methods, these measurement are known as `replicate measurements'.
	\citet{BXC2008} recommends the use of replicate measurements, but
	acknowledges the additional computational complexity.
	
	\citet*{BA86} address this problem by offering two different
	approaches. The premise of the first approach is that replicate
	measurements can be treated as independent measurements. The
	second approach is based upon using the mean of the each group of
	replicates as a representative value of that group. Using either
	of these approaches will allow an analyst to estimate the inter
	method bias.
	
	%\section{Mean of Replicates Limits of Agreement}
	
	However, because of the removal of the effects of the replicate
	measurements error, this would cause the estimation of the
	standard deviation of the differences to be unduly small.
	\citet*{BA86} propose a correction for this.
	
	\citet{BXC2008} takes issue with the limits of agreement based on
	mean values of replicate measurements, in that they can only be interpreted as prediction
	limits for difference between means of repeated measurements by
	both methods, as opposed to the difference of all measurements.
	Incorrect conclusions would be caused by such a misinterpretation.
	\citet{BXC2008} demonstrates how the limits of agreement
	calculated using the mean of replicates are `much too narrow as
	prediction limits for differences between future single
	measurements'. This paper also comments that, while treating the
	replicate measurements as independent will cause a downward bias
	on the limits of agreement calculation, this method is preferable
	to the `mean of replicates' approach.
	
	
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\newpage

	\section{What is Repeatability}
	The quality of repeatability is the ability of a measurement method to give consistent results for a particular subject. That is to say that a measurement will agree with prior and subsequent measurements of the same subject.
		\section{Repeatability}
		Repeatability is the ability of a measurement method to give consistent results for a particular subject, i.e. a measurement will agree with prior and subsequent measurements of the same subject. \citet{Barnhart} emphasizes the importance of repeatability as part of an overall method comparison study, a view endorsed by \citet{BXC2008}. Before there can be good agreement between two methods, a method must have good agreement with itself. If one method has poor repeatability in the sense of considerable
		variability, then agreement between two methods is bound to be
		poor \citep{ARoy2009}. \citet{Barnhart} remarks that it is important to report repeatability when assessing
		measurement, because it measures the purest form of random error
		not influenced by other factors, while further remarking `\textit{curiously replicate measurements are rarely made in method comparison studies, so that an important aspect of comparability is often overlooked}. \citet{BA99} strongly recommends the simultaneous estimation of repeatability and agreement be collecting replicated data.
		However \citet{ARoy2009} notes the lack of convenience in such calculations. 	Repeatability is defined by the \citet{IUPAC} as `\textit{the closeness of agreement between independent results obtained with the same method on identical test material, under the same conditions (same
			operator, same apparatus, same laboratory and after short intervals of time)}'  and is determined by taking multiple measurements on a series of subjects.
		
		
		
		% %	Test-retest variability is practically used, for example, in medical monitoring of conditions.
		
		A measurement is said to be repeatable when this variation is smaller than some pre-specified limit. In these situations, there is often a predetermined ``critical difference", and for differences in monitored values that are smaller than this critical difference, the possibility of pre-test variability as a sole cause of the difference may be considered in addition to, for examples, changes in diseases or treatments. 
		
		
		The British Standards Institute (1979) defines a coefficient of repeatability  as \emph{the value below which the difference between two single test results may be expected to lie within a specified probability.} In the absence of other indications, the probability is 95\%.
		
		\section{Repeatability and Gold Standards}
		Currently the phrase `gold standard' describes the most accurate method of measurement available. No other criteria are set out. Further to \citet{dunnSEME}, various gold standards have a varying levels of repeatability. Dunn cites the example of the sphygmomanometer, which is prone to measurement error. Consequently it can be said that a measurement method can be the `gold standard', yet have poor repeatability. 
		
		% % % Bronze Standard
		\citet{dunnSEME} recognizes  this problem. Hence, if the most accurate method is considered to have poor repeatability, it is referred to as a ``bronze standard".  Again, no formal definition of a `bronze standard' exists.
		
		The coefficient of repeatability may provide the basis of formulation a formal definition of a `gold standard'. For example, by determining the ratio of $CR$ to the sample mean $\bar{X}$. Advisably the sample size should specified in advance. A gold standard may be defined as the method with the lowest value of $\lambda = CR /\bar{X}$ with $\lambda < 0.1\%$. Similarly, a silver standard may be defined as the method with the lowest value of $\lambda $ with $0.1\% \leq \lambda < 1\%$. Such thresholds are solely for expository purposes.
		
	\section{Repeatability}
	Repeatability (or \textit{test-retest reliability})  describes the variation in measurements taken by a single method of measurement on the same item and under the same conditions. 
	A less-than-perfect test-retest reliability causes test-retest variability. Such variability can be caused by, for example, intra-individual variability and intra-observer variability. 
	A measurement may be said to be repeatable when this variation is smaller than some agreed limit.
	
	Test-retest variability is practically used, for example, in medical monitoring of conditions. In these situations, there is often a predetermined "critical difference", and for differences in monitored values that are smaller than this critical difference, the possibility of pre-test variability as a sole cause of the difference may be considered in addition to, for examples, changes in diseases or treatments.
	
	According to the \textit{Guidelines for Evaluating and Expressing the Uncertainty of NIST Measurement Results}, the following conditions need to be fulfilled in the establishment of repeatability:
	\begin{itemize}
		\item	the same measurement procedure
		\item	the same observer
		\item	the same measuring instrument, used under the same conditions
		\item	the same location
		\item	repetition over a short period of time.
		\item  same objectives
	\end{itemize}
	\bigskip
	
	Repeatability is defined by the \textbf{IUPAC} as `\textit{the closeness of agreement between independent results obtained with the same method on identical test material, under the same conditions (same
		operator, same apparatus, same laboratory and after short intervals of time)}'  and is determined by taking multiple measurements on a series of subjects.
	
	A measurement method can be said to have a good level of repeatability if there is consistency in repeated measurements on the same subject using that method. Conversely, a method has poor repeatability if there is considerable variation in repeated measurements.
	
	
	
	%-----------------------------------------------------------------------------------------------------%
	\newpage
	\section{Importance of Repeatability in MCS}
	
	
	
	Barnhart emphasizes the importance of repeatability as part of an overall method comparison study. Before there can be good agreement between two methods, a method must have good agreement with itself. The coefficient of repeatability , as proposed by Bland \& Altman (1999) is an important feature of both Carstensen's and Roy's methodologies. The coefficient is calculated from the residual standard deviation (i.e. $1.96 \times \sqrt{2} \times \sigma_m$ = $2.83 \sigma_m$).
	
	
	\citet{Barnhart} emphasizes the importance of repeatability as part of an overall method comparison study. Before there can be good agreement between two methods, a method must have good agreement with itself. The coefficient of repeatability , as proposed by \citet{BA99} is an important feature of both Carstensen's and Roy's methodologies. The coefficient is calculated from the residual standard deviation (i.e. $1.96 \times \sqrt{2} \times \sigma_m$ = $2.83 \sigma_m$).
	
	\bigskip
	
	\citet{BA99} strongly recommends the simultaneous estimation of repeatability and agreement be collecting replicated data. \citet{ARoy2009} notes the lack of convenience in such calculations.
	It is important to report repeatability when assessing measurement, because it measures the purest form of random error not influenced by other factors \citep{Barnhart}.	
	
	%% Who Said Next Line
	importance of repeatability' curiously replicate measurements are rarely made in method comparison studies, so that an important aspect of comparability is often overlooked.
	
	Repeatability is important in the context of method comparison because the repeatability of two methods influence the amount of agreement which is possible between those methods. If one method has poor repeatability, the agreement is bound to be poor. If both methods have poor repeatability, agreement is even worse. If one method has poor repeatability in the sense of considerable variability, then agreement between two methods is bound to be poor \citep{ARoy2009}.
	
	\citet{barnhart} and \citet{roy} highlight the importance of reporting repeatability in method comparison, because it measures the purest random error not influenced by any external factors. Statistical procedures on within-subject variances of two methods are equivalent to tests on their respective repeatability coefficients. A formal test is introduced by \citet{roy}, which will discussed in due course.
	
	%--------------------------------------------------------------------%
	%\section{Bland and Altman 1999}
	As noted by Bland and Altman 1999, the repeatability of two methods of measurement can  potentially limit
	Repeatability (using Bland-Altman plot)
	The Bland-Altman plot may also be used to assess a method?s repeatability by comparing repeated measurements using one single measurement method on a sample of items.
	The plot can then also be used to check whether the variability or precision of a method is related to the size of the characteristic being measured.
	Since for the repeated measurements the same method is used, the mean difference should be zero.
	Therefore the Coefficient of Repeatability (CR) can be calculated as 1.96 (often rounded to 2) times the standard deviation of the case-wise differences.
	
	\section{Coefficient of Repeatability}
	The coefficient of repeatability is a measure of how well a
	measurement method agrees with itself over replicate measurements
	\citep{BA99}. Once the within-item variability is known, the
	computation of the coefficients of repeatability for both methods
	is straightforward.
	
	The British standards Insitute [$1979$] define a coefficient of
	repeatability  as \emph{the value below which the difference between two single test results....may be expected to lie within a specified probability.} Unless otherwise instructed, the
	probability is assumed to be $95\%$. 
	
	The Bland Altman method offers a measurement on the repeatability of the methods. The \emph{Coefficient of Repeatability} (CR) can be calculated as 1.96 (or 2) times the standard deviations of the differences between the two measurements ($d_2$ and $d_1$).
	
	
	
	
	
	%	If one method has poor repeatability in the sense of considerable variability, then agreement between two methods is bound to be poor \citep{ARoy2009}.
	
	
	
	
	
	
	\section{Repeatability coefficient from LME Models}
	\citet{BA99} introduces the repeatability coefficient for a method, which is defined as the upper limits of a prediction interval for the absolute difference between two measurements by the same
	method on the same item under identical circumstances \citep{BXC2008}.
	
	$\sigma^2_{x}$ is the within-subject variance of method $x$. The repeatability coefficient is $2.77 \sigma_{x}$ (i.e. $1.96 \times \sqrt{2} \sigma_{x}$). For $95\%$ of subjects, two replicated measurement by the same method will be within this repeatability coefficient.
	
	%% \section{Note 1: Coefficient of Repeatability}
	
	
	
	%------------------------------------------------------------------------------------------%
	\section{Repeatability in Bland-Altman Blood Data Analysis}
	\begin{itemize}
		\item Two readings by the same method will be within $1.96
		\sqrt{2} \sigma_w $ or $2.77 \sigma_w $ for 95\% of subjects. Thisvalue is called the repeatability coefficient.
		
		\item For observer J using the sphygmomanometer $ \sigma_w = \sqrt{37.408} = 6.116$ and so the repeatability coefficient is
		$2:77 \times 6.116 = 16:95$ mmHg.
		
		\item For the machine S,$ \sigma_w = \sqrt{83.141} = 9.118$ and the repeatability coefficient is $2:77 \times 9.118 = 25.27$ mmHg.
		
		\item Thus, the repeatability of the machine is 50\% greater than that of the observer.
	\end{itemize}
	%-------------------------------------------------------------------%
	\section{Carstensen}
	\begin{itemize}
		\item The limits of agreement are not always the only issue of
		interest � the assessment of method specific repeatability and
		reproducibility are of interest in their own right.
		
		\item Repeatability can only be assessed when replicate
		measurements by each method are available.
		
		\item The repeatability coefficient for a method is defined as the
		upper limits of a prediction interval for the absolute difference
		between two measurements by the same method on the same item under
		identical circumstances.
		
		\item If the standard deviation of a measurement is $\sigma$ the
		repeatability coefficient is $2\times\sqrt{2} \sigma = 2.83\times
		\sigma \approx 2.8 \sigma$.
		
		
		\item The repeatability of measurement methods is calculated
		differently under the two models \item Under the model assuming
		exchangeable replicates (1), the repeatability is based only on
		the residual standard deviation, i.e. $2.8\sigma_m$
		
		
		\item Under the model for linked replicates (2) there are two
		possibilities depending on the circumstances.
		
		\item If the variation between replicates within item can be
		considered a part of the repeatability it will be $2.8 \sqrt{
			\omega^2 + \sigma^2_m}$.
		
		\item However, if replicates are taken under substantially
		different circumstances, the variance component $\omega^2$ may be
		considered irrelevant in the repeatability and one would therefore
		base the repeatability on the measurement errors alone, i.e. use
		$2.8 \sigma_m$.
	\end{itemize}
	
	
	
	%\section{Reproducibility}
	% 
	%It is advisable to be able to distinguish between Repeatability and a similar concept ?Reproducibility?. Reproducibility is
	
	
	
	
	
	
	
	
	
	%%========================================================================%
	%% Phase Next Section Out
	%% Where did this come from
	
	\newpage
	
	%--------------------------------------------------------------------%
	
	%--------------------------------------------------------------------%
	\section{Notes from BXC Book (chapter 9)}
	The assessment of method-specific repeatability and reproducibility is of interest in its own right.
	Repeatability and reproducibility can only be assessed when replicate measurements by each method are available.
	If replicate measurements by a method are available, it is simple to estimate the measurement error for a method, using a model with fixed effects for item, then taking the residual standard deviation as measurement error standard deviation.
	However, if replicates are linked, this may produce an estimate that biased upwards.
	The repeatability coefficient (or simply repeatability) for a method is defined as the upper limit of a
	prediction interval for the absolute difference between two measurements by the same method on the same
	item under identical circumstances (see above conditions)
	
	\[y_{mir}  = \alpha_{m} + \beta_m( \mu_i + a_{ir} + c_{mi}) + e_{mir}\]
	
	The variation between measurements under identical circumstances.
	

	
	
	\section{Definition of Replicate measurements}
	Further to \citet{BA99}, a formal definition is required of what exactly replicate measurements are
	
	\emph{By replicates we mean two or more measurements on the same
		individual taken in identical conditions. In general this requirement means that the
		measurements are taken in quick succession.}
	
	Roy accords with Bland and Altman?s definition of a replicate, as being two or more measurements on the same individual under identical conditions. Roy allows the assumption that replicated measurements are equi-correlated. Roy allows unequal numbers of replicates.
	
	Replicate measurements are linked over time. However the method can be easily extended to cover situations where they are not linked over time.
	%----------------------------------------------------------------------------%
	\section{Model for replicate measurements}
	
	We generalize the single measurement model for the replicate measurement case, by additionally specifying replicate values. Let $y_{mir}$ be the $r-$th replicate measurement for subject ``i" made by method ``m". Further to \citet{barnhart} fixed effect can be expressed with a single term $\alpha_{mi}$, which incorporate the true value $\mu_i$.
	
	\[ y_{mir} = \mu_{i} + \alpha_{m} + e_{mir}  \]
	
	Combining fixed effects \citep{barnhart}, we write,
	
	\[ y_{mir} = \alpha_{mi} + e_{mir}.\]
	
	The following assumptions are required
	
	\begin{itemize}
		\item $e_{mir}$ is independent of the fixed effects with mean $\mbox{E}(e_{mir}) = 0$.
		\item Further to \citet{barnhart} between-item and within-item variances $\mbox{Var}(\alpha_{mi}) = \sigma^2_{Bm}$ and $\mbox{Var}(e_{mir}) = \sigma^2_{Wm}$
		%	\item In keeping with \citet{Roy}, these variance shall be considered as part of the between-item variance covariance matrix $\boldsymbol{D}$ and the within-item variance covariance matrix  $\boldsymbol{\Sigma}$
		%	respectively, and will be denoted accordingly ( i.e. $d^2_{m}$ and $\sigma^2_{m}$).
		%	\item Additionally, the total variability of method "m", denoted $\omega^2_m$ is the sum of the within-item and between-item variabilities.
		%	
		%	\[ \omega^2_m = d^2_{m}+ \sigma^2_{m} \]
		
	\end{itemize}
	\section{Carstensen's Model}
	
	
	
	\citet{BXC2004} presents a model to describe the relationship between a value of measurement and its
	real value. The non-replicate case is considered first, as it is the context of the Bland Altman plots. This model assumes that inter-method bias is the only difference between the two methods.
	
	A measurement $y_{mi}$ by method $m$ on individual $i$ is formulated as follows;
	\begin{equation}
		y_{mi}  = \alpha_{m} + \mu_{i} + e_{mi} \qquad  e_{mi} \sim
		\mathcal{N}(0,\sigma^{2}_{m})
	\end{equation}
	The differences are expressed as $d_{i} = y_{1i} - y_{2i}$. For the replicate case, an interaction term $c$ is added to the model, with an associated variance component. All the random effects are assumed independent, and that all replicate measurements are assumed to be exchangeable within each method.
	
	\begin{equation}
		y_{mir}  = \alpha_{m} + \mu_{i} + c_{mi} + e_{mir}, \qquad  e_{mi}
		\sim \mathcal{N}(0,\sigma^{2}_{m}), \quad c_{mi} \sim \mathcal{N}(0,\tau^{2}_{m}).
	\end{equation}
	%----
	
	Of particular importance is terms of the model, a true value for item $i$ ($\mu_{i}$).  The fixed effect of Roy's model comprise of an intercept term and fixed effect terms for both methods, with no reference to the true value of any individual item. A distinction can be made between the two models: Roy's model is a standard LME model, whereas Carstensen's model is a more complex additive model.
	
	\bigskip
	\section{Two Way ANOVA}
	
	\citet{BXC2008} develop their model from a standard two-way analysis of variance model, reformulated for the case of replicate measurements, with random effects terms specified as appropriate. 
	Their model describing $y_{mir} $, again the $r$th replicate measurement on the $i$th item by the $m$th method ($m=1,2,$ $i=1,\ldots,N,$ and $r = 1,\ldots,n$), can be written as
	\begin{equation}\label{BXC-model}
		y_{mir}  = \alpha_{m} + \mu_{i} + a_{ir} + c_{mi} + \epsilon_{mir}.
	\end{equation}
	The fixed effects $\alpha_{m}$ and $\mu_{i}$  represent the intercept for method $m$ and the `true value' for item $i$ respectively. The random-effect terms comprise an item-by-replicate interaction term $a_{ir} \sim \mathcal{N}(0,\varsigma^{2})$, a method-by-item interaction term $c_{mi} \sim \mathcal{N}(0,\tau^{2}_{m}),$ and model error terms $\varepsilon \sim \mathcal{N}(0,\varphi^{2}_{m}).$ All random-effect terms are assumed to be independent.
	For the case when replicate measurements are assumed to be exchangeable for item $i$, $a_{ir}$ can be removed.
	
	The model expressed in (2) describes measurements by $m$ methods, where $m = \{1,2,3\ldots\}$. Based on the model expressed in (2), \citet{BXC2008} compute the limits of agreement as
	\[
	\alpha_1 - \alpha_2 \pm 2 \sqrt{ \tau^2_1 +  \tau^2_2 +  \varphi^2_1 +  \varphi^2_2 }
	\]
	\citet{BXC2008} notes that, for $m=2$,  separate estimates of $\tau^2_m$ can not be obtained. To overcome this, the assumption of equality, i.e. $\tau^2_1 = \tau^2_2$ is required.
	
	
	%----------------------------------------------------------------------------
	\section{Statistical Model For Replicate Measurements}
	Let $y_{Aij}$ and $y_{Bij}$ be the $j$th repeated observations of the variables of interest $A$ and $B$ taken on the $i$th subject. The number of repeated measurements for each variable may differ for each individual.
	Both variables are measured on each time points. Let $n_{i}$ be the number of observations for each variable, hence $2\times n_{i}$ observations in total.
	
	It is assumed that the pair $y_{Aij}$ and $y_{Bij}$ follow a bivariate normal distribution.
	\begin{eqnarray}
		\left(
		\begin{array}{c}
			y_{Aij} \\
			y_{Bij} \\
		\end{array}
		\right) \sim \mathcal{N}(
		\boldsymbol{\mu}, \boldsymbol{\Sigma})\mbox{   where } \boldsymbol{\mu} = \left(
		\begin{array}{c}
			\mu_{A} \\
			\mu_{B} \\
		\end{array}
		\right)
	\end{eqnarray}
	The matrix $\boldsymbol{\Sigma}$ represents the variance component matrix between response variables at a given time point $j$.
	\begin{equation}
		\boldsymbol{\Sigma} = \left( \begin{array}{cc}
			\sigma^2_{A} & \sigma_{AB} \\
			\sigma_{AB} & \sigma^2_{B}\\
		\end{array}\right)
	\end{equation}
	$\sigma^2_{A}$ is the variance of variable $A$, $\sigma^2_{B}$ is the variance of variable $B$ and $\sigma_{AB}$ is the covariance of the two variable. It is assumed that $\boldsymbol{\Sigma}$ does not depend on a particular time point, and is the same over all time points.
	
	\section{Exchangeable and Linked measurements}
	\section{Sampling Scheme : Linked and Unlinked Replicates}
	Measurements taken in quick succession by the same observer using the same instrument on the same subject can be considered true replicates. \citet{ARoy2009} notes that some measurements may not be `true' replicates.
	
	Roy's methodology assumes the use of `true replicates'. However data may not be collected in this way. In such cases, the correlation matrix on the replicates may require a different structure, such as the autoregressive order one $AR(1)$ structure. However determining MLEs with such a structure would be computational intense, if possible at all.
	
	
	
	\emph{
		One important feature of replicate observations is that they should be independent
		of each other. In essence, this is achieved by ensuring that the observer makes each
		measurement independent of knowledge of the previous value(s). This may be difficult
		to achieve in practice.} (Check who said this
	)
	%----------------------------------------------------------------------------%
	
	
	%-----------------------------------------------------------------------------------------------------%
	\section{Replicate measurements}
	\citet{ARoy2009} accords with Bland and Altman?s definition of a replicate, as being two or more measurements on the same individual under identical conditions.
	Roy allows the assumption that replicated measurements are equi-correlated.
	Roy allows unequal numbers of replicates.
	
	Replicate measurements are linked over time. However the method can be easily extended to cover situations where they are not linked over time.
	
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	In this model , the variances of the random effects must depend on
	$m$, since the different methods do not necessarily measure on the
	same scale, and different methods naturally must be assumed to
	have different variances. \citet{BXC2004} attends to the issue of
	comparative variances.
	
	\newpage
	\citet{BA99} also remark that an important feature of replicate observations is that they should be independent
	of each other. This issue is addressed by \citet{BXC2010}, in terms of exchangeability and linkage. Carstenen advises that repeated measurements come in two \emph{substantially different} forms, depending on the circumstances of their measurement: exchangable and linked.
	
	Repeated measurements are said to be exchangeable if no relationship exists between successive measurements across measurements. If the condition of exchangeability exists, a group of measurement of the same item determined by the same method can be re-arranged in any permutation without prejudice to proper analysis. There is no reason to believe that the true value of the underlying variable has changed over the course of the measurements.
	
	Exchangeable repeated measurements can be treated as true replicates. For the purposes of method comparison studies the following remarks can be made. The $r-$th measurement made by method $1$ has no special correspondence to the $r-$th measurement made by method $2$, and consequently any pairing of repeated measurements are as good as each other.
	
	
	%----------------------------------------------------------------------------%
	
	Repeated measurements are said to be linked if a direct correspondence exists between successive measurements across measurements, i.e. pairing. Such measurements are commonly made with a time interval between them, but simultaneously for both methods. Paired measurements are exchangeable, but individual measurements are not.
	
	If the paired measurements are taken
	in a short period of time so that no real systemic changes can take place on each item, they can be considered true replicates.
	Should enough time elapse for systemic changes, linked repeated measurements can not be treated as true replicates.
	
	
	\newpage
	\bibliographystyle{chicago}
	\bibliography{DB-txfrbib}
	\section{The Technology Acceptance Model}
	Davis (1989) proposes the TAM model, which suggests an hypothesis as to why users may adopt particular technologies, and not others. 
	According to this theory, when users are presented with a new 
	technology, two important factors will influence their decision about how and when they will adopt it.
	\begin{description}
		\item[Perceived usefulness (PU)] - This was defined by Fred Davis as "the degree to which a person believes that using a particular system would enhance his or her job performance".
		\item[Perceived ease-of-use (PEOU)] - Davis defined this as "the degree to which a person believes that using a particular system would be free from effort" 
	\end{description}
	
	Davis's explanations of these term can be rephrased for application to statistical analysis. 
	Perceived Use could refer to the degree to which an user would deem a particular statistical method would properly establish the results of an analaysis. In the case of method comparison studies, proper indication of agreement, or lack thereof.
	
	
	Perceived ease-of-use requires only applying the context of a satistical problem. A very modest statistical skill set is the only prerequistive for constructing a Bland-Altman plot, and computing limits of agreement. The main building blocks 
	are simple descriptive, statistics and a knowledge of the normal distribution. These are topics that feature in almost every undergraduate statistics courses. Furthermore \citet{kikozak2014including} recommends including the Bland-Altman method itself in undergraduate teaching.
	%---------------------------------------------%
	
	In short, the user perceives the Bland-Altman methodology to be an easy-to-implement technique, that will properly address the question of agreement.
	
	Conversely the Survival plot is a derivative of the Kaplan-Meier Curve, a non-parametric graphical technique that features in Survival Analysis. This subject area is a well known domain of statistics, but would be encountered 
	on curriculums of specialist courses. 
	
	The Mountain Plot is formally called the empirical folder cumulative distribution plot. While not particularly hard to render, the procedure is not straight-forward for the casual user. Currently there is only one software implementation, \textbf{\textit{medcalc.be}} toolkit.
		%\newpage
		%\section{Agreement Indices}
		%\citet{Barnhart} provided an overview of several agreement
		%indices, including the limits of agreement. Other approaches, such
		%as mean squared deviation, the tolerance deviation index and
		%coverage probability are also discussed.
\end{document}

