\documentclass[12pt, a4paper]{report}
\usepackage{epsfig}
\usepackage{subfigure}
%\usepackage{amscd}
\usepackage{amssymb}
\usepackage{graphicx}
%\usepackage{amscd}
\usepackage{amssymb}
%\usepackage{subfiles}
\usepackage{framed}
% \usepackage{subfiles}
\usepackage{amsthm, amsmath}
\usepackage{amsbsy}
\usepackage{framed}
\usepackage[usenames]{color}
\usepackage{listings}
\lstset{% general command to set parameter(s)
basicstyle=\small, % print whole listing small
keywordstyle=\color{red}\itshape,
% underlined bold black keywords
commentstyle=\color{blue}, % white comments
stringstyle=\ttfamily, % typewriter type for strings
showstringspaces=false,
numbers=left, numberstyle=\tiny, stepnumber=1, numbersep=5pt, %
frame=shadowbox,
rulesepcolor=\color{black},
,columns=fullflexible
} %
%\usepackage[dvips]{graphicx}
\usepackage{natbib}
\bibliographystyle{chicago}
\usepackage{vmargin}
% left top textwidth textheight headheight
% headsep footheight footskip
\setmargins{3.0cm}{2.5cm}{15.5 cm}{22cm}{0.5cm}{0cm}{1cm}{1cm}
\renewcommand{\baselinestretch}{1.5}
\pagenumbering{arabic}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{ill}[theorem]{Example}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{axiom}{Axiom}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{notation}{Notation}
\theoremstyle{remark}
\newtheorem{remark}{Remark}[section]
\newtheorem{example}{Example}[section]
\renewcommand{\thenotation}{}
\renewcommand{\thetable}{\thesection.\arabic{table}}
\renewcommand{\thefigure}{\thesection.\arabic{figure}}
\title{Research notes: linear mixed effects models}
\author{ } \date{ }


\begin{document}

	\tableofcontents

\chapter{LME Models in Method Comparison Studies}
	
\section{LME Models in Method Comparison Studies}
	
When repeated measurements are available for calculating the limits of agreement, it is desirable to use all available data to compare the two methods. The classical Bland-Altman method was developed for two sets of measurements done on one occasion, but is inadequate for replicate measurement data. 
	
\citet{BA99} addressed this issue by suggesting several computationally simple approaches.  One proposed approach is to calculate the mean for each method on each subject and use these pairs of means to compare the two methods. Their second approach is to treat each measurement separately. The estimate of bias will be unaffected using this approach, but the estimate of the standard deviation of the differences will be too small, because of the reduction of the effect of repeated measurement error \citep{BXC2004,BXC2008}. 
	
	\citet{BXC2008} recommends that replicate measurements be used for each method, but recognizes that resulting data are more difficult to analyze. To this end, they recommend the use of LME models as a suitable framework, a view shared by \citet{ARoy2009} etc.
	%\citet{ARoy2009} uses an LME model approach to provide a set of formal tests for method comparison studies.
	
	%\citet{BXC2008} demonstrate statistical flaws with two approaches proposed by \citet{BA99} for the purpose of calculating the variance of the inter-method bias when replicate measurements are available.
	
	%\citet{BXC2008} demonstrated how the limits of agreement calculated solely from the mean of replicates are `much too narrow as
	%prediction limits for differences between future single measurements'. Carstensen attends to this issue also, adding that another approach would be to treat each repeated measurement separately. 
	
	%This paper also comments that, while treating the
	%replicate measurements as independent will cause a downward bias on the limits of agreement calculation, this method is preferable to the `mean of replicates' approach. 
	
	
	\citet{BXC2008} extends the well established Bland-Altman methodology for the case of replicate measurements on each item by using LME models, to allow for a more statistically rigourous approach to computing appropriate estimates for the variance of the inter-method bias, based upon the variance component estimates derived from the LME models. As their interest mainly lies in extending the Bland-Altman approach, other formal tests are not considered.  
	
	%Measures of repeatability, a
	%characteristic of individual methods of measurements, are also
	%derived using this method.
	
%================================================================%
	
	\subsection{Computing Limits of Agreement with LME Methods}

	\citet{BXC2004} and \citet{BXC2008} uses an LME model to compute limits of agreement where replicate measurements are available on each item, proposing an approach for comparing two or more methods of measurement based on linear mixed effects models. 
	
	Their interest lies in generalizing the popular limits-of-agreement (LOA) methodology advocated by \citet{BA86} to take proper cognizance of the replicate measurements, by computing an appropriate estimate for the standard deviation of case-wise differences, so as to determine the limits of agreement.
		\citet{BXC2008} took issue with the limits of agreement based on mean values of replicate measurements, in that they can only be interpreted as prediction limits for difference between means of repeated measurements by both methods, as opposed to the difference of all measurements.
	Incorrect conclusions would be caused by such a misinterpretation.
	
	
	%================================================================%
	
	\subsection{Carstensen's LME Framework for Method Comparison}
	
	%These authors advocate a LME model for the purpose of comparing two methods of measurement where replicate measurements are available on each item. 
	% Their interest lies in generalizing the limits-of-agreement (LOA) method developed by \citet{BA86} to take proper cognizance of the replicate measurements. 
\citet{BXC2004} proposed LME models for deriving conversion calculations similar to Deming's regression, and for estimating variance components for measurements by different methods.
	
\citet{BXC2008} recommend a fitted LME model to obtain appropriate estimates for the variance of the inter-method bias.  Estimation of repeatability is included in this framework, but other formal tests are not considered.
	
\citet{BXC2008} develop this approach is that of a standard two-way mixed effects ANOVA with replicate measurements, reformulated for the case of replicate measurements, with random effects terms specified as appropriate. With regards to specifying the variance terms, \citet{BXC2008} remarks that using their approach is common, remarking that \emph{the only slightly non-standard (meaning ``not often used") feature is the differing residual variances between methods }\citep{BXC2010}.
	
	
	
	%Carstensen specifies the variance of the interaction terms as being univariate normally distributed. As such, $\mathrm{Cov}(c_{mi}, c_{m^\prime i})= 0.$
=======
%\tableofcontents
%\newpage
\chapter{LME Models in Method Comparison Studies}

\section{LME Models in Method Comparison Studies}

When repeated measurements are available for calculating the limits of agreement, it is desirable to use all available data to compare the two methods. The classical Bland-Altman method was developed for two sets of measurements done on one occasion, but is inadequate for replicate measurement data.

\citet{BA99} addressed this issue by suggesting several computationally simple approaches.  One proposed approach is to calculate the mean for each method on each subject and use these pairs of means to compare the two methods. Their second approach is to treat each measurement separately.
The estimate of bias will be unaffected using this approach, but the estimate of the standard deviation of the differences will be too small, because of the reduction of the effect of repeated measurement error \citep{BXC2004,BXC2008}.

\citet{BXC2008} recommends that replicate measurements be used for each method, but recognizes that resulting data are more difficult to analyze. To this end, they recommend the use of LME models as a suitable framework, a view shared by \citet{ARoy2009} etc.
%\citet{ARoy2009} uses an LME model approach to provide a set of formal tests for method comparison studies.

%\citet{BXC2008} demonstrate statistical flaws with two approaches proposed by \citet{BA99} for the purpose of calculating the variance of the inter-method bias when replicate measurements are available.

%\citet{BXC2008} demonstrated how the limits of agreement calculated solely from the mean of replicates are `much too narrow as
%prediction limits for differences between future single measurements'. Carstensen attends to this issue also, adding that another approach would be to treat each repeated measurement separately.

%This paper also comments that, while treating the
%replicate measurements as independent will cause a downward bias on the limits of agreement calculation, this method is preferable to the `mean of replicates' approach.


\citet{BXC2008} extends the well established Bland-Altman methodology for the case of replicate measurements on each item by using LME models, to allow for a more statistically rigourous approach to computing appropriate estimates for the variance of the inter-method bias, based upon the variance component estimates derived from the LME models. As their interest mainly lies in extending the Bland-Altman approach, other formal tests are not considered.

%Measures of repeatability, a
%characteristic of individual methods of measurements, are also
%derived using this method.


%================================================================%

\subsection{Computing Limits of Agreement with LME Methods }

\citet{BXC2004} uses an LME model to compute limits of agreement where replicate measurements are available on each item, proposing an approach for comparing two or more methods of measurement based on linear mixed effects models, an approach extended by \citet{BXC2008}.

Their interest lies in generalizing the popular limits-of-agreement (LOA) methodology advocated by \citet{BA86} to take proper cognizance of the replicate measurements, by computing an appropriate estimate for the standard deviation of case-wise differences, so as to determine the limits of agreement.
\citet{BXC2008} took issue with the limits of agreement based on mean values of replicate measurements, in that they can only be interpreted as prediction limits for difference between means of repeated measurements by both methods, as opposed to the difference of all measurements.
Incorrect conclusions would be caused by such a misinterpretation.


%================================================================%

\subsection{Carstensen's LME Framework for Method Comparison}

%These authors advocate a LME model for the purpose of comparing two methods of measurement where replicate measurements are available on each item.
% Their interest lies in generalizing the limits-of-agreement (LOA) method developed by \citet{BA86} to take proper cognizance of the replicate measurements.
\citet{BXC2004} proposed LME models for deriving conversion calculations similar to Deming's regression, and for
estimating variance components for measurements by different methods.

\citet{BXC2008} recommend a fitted LME model to obtain appropriate estimates for the variance of the inter-method bias.  Estimation of repeatability is included in this framework, but other formal tests are not considered.



\citet{BXC2008} develop this approach is that of a standard two-way mixed effects ANOVA with replicate measurements, reformulated for the case of replicate measurements, with random effects terms specified as appropriate. With regards to specifying the variance terms, \citet{BXC2008} remarks that using their approach is common, remarking that \emph{the only slightly non-standard (meaning ``not often used") feature is the differing residual variances between methods }\citep{BXC2010}.



%Carstensen specifies the variance of the interaction terms as being univariate normally distributed. As such, $\mathrm{Cov}(c_{mi}, c_{m^\prime i})= 0.$


%The model is constructed to describe the relationship between a value of measurement and its real value. The non-replicate case is considered first, as it is the context of the Bland-Altman plots. This model assumes that inter-method bias is the only difference between the two methods.
%

\citet{BXC2004} presents a model to describe the relationship between a value of measurement and its real value. The non-replicate case is considered first, as it is the context of the Bland Altman plots. This model assumes that inter-method bias is the only difference between the two methods. A measurement $y_{mi}$ by method $m$ on individual $i$ is formulated as follows:
\begin{equation}
y_{mi}  = \alpha_{m} + \beta_m\mu_{i} + \epsilon_{mi}.
\end{equation}
Here the terms $\alpha_{m}$ and $\mu_{i}$ represent the fixed effect for method $m$ and a true value for item $i$ respectively.  The $\beta_{m}$ term follow from \citet{DunnSEME}, expressing constant and proportional bias respectively, in the presence of a real value $\mu_{i}.$ We will just consider the case where $\beta=1$ presently. The random error term for each response is denoted $\epsilon_{mi}$ with $\mathrm{E}(\epsilon_{mi})=0$ and $\mathrm{Var}(\epsilon_{mi})=\sigma^2_m$.
>>>>>>> a2f6c64bed72d1c25fc27f9237e0bc1750daf02c
 
\subsection{Test For Inter-Method Bias in the LME Frameworks}
 Two methods can be considered to be in agreement if criteria based upon these tests are met. Firstly, a practitioner would investigate whether a significant inter-method bias is present between the methods, as this is the source of disagreement between two methods of measurement that is most easily identified. A formal test for the hypothesis $\operatorname{H_1} : \mu_1 = \mu_2$ can be implemented by examining the fixed effects of the LME model, equivalent to a conventional paired $t-$test. Estimates for the fixed effects yield the inter-method bias, typically accompanied by the necessary test statistic and $p-$value in programming software output. Inference for inter-method bias follows from well-established methods and, as such, will only be noted when describing examples.
% This is common to classical linear models, and interpretation of the results should pose not difficulty to a trained practitioner.

\subsection*{Replicate Measurement Case}

\citet{BXC2008} proposes the addition of an random effects term to their model when the replicates are linked. For the replicate case, an interaction term $c$ is added to the model, with an associated variance component. This term is used to describe the `item by replicate' interaction, $a_{ir}$, which is independent of the methods. This interaction is a source of variability independent of the methods. Therefore failure to account for it will result in variability being wrongly attributed to the methods.

\citet{BXC2008} uses both to demonstrate the importance of using an interaction term. Failure to take the replication structure into account results in over-estimation of the limits of agreement.

The measurement $y_{mi}$ by method $m$ on individual $i$ the measurement $y_{mir} $ is the $r$th replicate measurement on the $i$th item by the $m$th method, where $m=1,2,\ldots,M$ $i=1,\ldots,N,$ and $r = 1,\ldots,n_i$ is formulated as follows;

% \begin{equation}
% y_{mir}  = \alpha_{m} + \beta_{m}\mu_{i} + c_{mi} + e_{mir} \qquad
% ( e_{mi} \sim N(0,\sigma^{2}_{m}), c_{mi} \sim N(0,\tau^{2}_{m}))
% \end{equation}

\begin{equation}
y_{mir}  = \alpha_{m} + \mu_{i} + c_{mi} + a_{ir} + \epsilon_{mir},
\label{BXC-full}
\end{equation}
The random error term for each response is denoted $\epsilon_{mir}$ with $\mathrm{E}(\epsilon_{mir})=0$ and $\mathrm{Var}(\epsilon_{mir})=\sigma^2_m$. Between-subject variation for method $m$ is given by $d^2_{m}$ (in the author's notation $\tau^2_m$) and within-subject variation is given by $\sigma^2_{m}$.

The random-effect terms comprise an item-by-replicate interaction term $a_{ir} \sim \mathcal{N}(0,\sigma^{2})$, a method-by-item interaction term $c_{mi} \sim N(0,\tau^{2}_{m})$. $\epsilon_{mir}$ is the residual associated with each observation, with $\varepsilon_{mir} \sim N(0,\varphi^{2}_{m})$.

$c_{mi}$ is a interaction term to account for replicate, and $\epsilon_{mir}$ is the residual associated with each observation. Since variances are specific to each method, this model can be
fitted separately for each method. The $c_{mi}$ term represent random effect parameters corresponding to the two methods, having $\mathrm{E}(c_{mi})= 0$ with $\mathrm{Var}(c_{mi})=\tau^2_m$. \citet{BXC2008} specifies the variance of the interaction terms as being univariate normally distributed. As such, $\mathrm{Cov}(c_{mi}, c_{m^\prime i})= 0.$

This formulation doesn't require the data set to be balanced. When the design is balanced and there is no ambiguity we can set $n_i=n$. However, the model does require a sufficient large number of replicates and measurements to overcome the problem of identifiability. The import of which is that more than two methods of measurement may be required to carry out the analysis. There is also the assumptions that observations of measurements by particular methods are exchangeable within subjects. The quality of exchangeability means that future samples from a population behaves like earlier samples.

%\citet{BXC2004} describes the above model as a `functional model',
%similar to models described by \citet{Kimura}, but without any
%assumptions on variance ratios. A functional model is . An
%alternative to functional models is structural modelling


\subsection*{Simplified Model}
All the random effects are assumed independent, and that all replicate measurements are assumed to be exchangeable within each method. For the case when replicate measurements are assumed to be exchangeable for item $i$, $a_{ir}$ can be removed.Equation \ref{BXC-full} can be re-expressed as

\begin{equation}
y_{mir}  = \alpha_{m} + \mu_{i} + c_{mi} + \epsilon_{mir},
\end{equation}
with all of the component terms defined as they were before.

Modern software packages can be used to fit models accordingly. The best linear unbiased predictor (BLUP) for a specific subject $i$ measured with method $m$ has the form $BLUP_{mir} = \hat{\alpha_{m}} +
\hat{\beta_{m}}\mu_{i} + c_{mi}$, under the assumption that the
$\mu$s are the true item values.



%\citet{BXC2004} uses the above formula to predict observations for
%a specific individual $i$ by method $m$;
%
%\begin{equation}BLUP_{mir} = \hat{\alpha_{m}} + \hat{\beta_{m}}\mu_{i} +
%c_{mi}. \end{equation} Under the assumption that the $\mu$s are
%the true item values, this would be sufficient to estimate
%parameters. When that assumption doesn't hold, regression
%techniques (known as updating techniques) can be used additionally
%to determine the estimates.
%
%The assumption of exchangeability can
%be unrealistic in certain situations. \citet{BXC2004} provides an
%amended formulation which includes an extra interaction term=, $
%d_{mr} \sim N(0,\omega^{2}_{m}$, to account for this.

%\citet{BXC2004} uses the above formula to predict observations for
%a specific individual $i$ by method $m$;

% \subsection{Carstensen's LOAs}
%==================================================================== %
\subsection{Computation of Limits of Agreement in LME models}


\citet{BXC2008} demonstrates how to compute the limits of agreement for two methods in the case of linked measurements. By specifying a model with interaction terms, surplus sources of variability are excluded from the computation. Consequently the limits of agreement are not unduly wide, which would have been the case if the measurements were treated as true replicates.

<<<<<<< HEAD
\begin{equation}
y_{mir}  = \alpha_{m} + \mu_{i} + c_{mi} + \epsilon_{mir}, \qquad  e_{mi}
\sim \mathcal{N}(0,\sigma^{2}_{m}), \quad c_{mi} \sim \mathcal{N}(0,\tau^{2}_{m}).
\end{equation}		
	\citet{BXC2008} presents a simplified, but more tractable, model:
	\begin{equation}
		y_{mir}  = \alpha_{m} + \mu_{i} + c_{mi} + e_{mir} \qquad ( e_{mi}
		\sim N(0,\sigma^{2}_{m}), c_{mi} \sim N(0,\tau^{2}_{m}))
	\label{BXC-simple}
	\end{equation}
	Modern software packages can be used to fit models accordingly. The best linear unbiased predictor (BLUP) for a specific subject $i$ measured with method $m$ has the form $BLUP_{mir} = \hat{\alpha_{m}} +
	\hat{\beta_{m}}\mu_{i} + c_{mi}$, under the assumption that the
	$\mu$s are the true item values.
	
	
	
	%\citet{BXC2004} uses the above formula to predict observations for
	%a specific individual $i$ by method $m$;
	%
	%\begin{equation}BLUP_{mir} = \hat{\alpha_{m}} + \hat{\beta_{m}}\mu_{i} +
	%c_{mi}. \end{equation} Under the assumption that the $\mu$s are
	%the true item values, this would be sufficient to estimate
	%parameters. When that assumption doesn't hold, regression
	%techniques (known as updating techniques) can be used additionally
	%to determine the estimates. 
	%
	%The assumption of exchangeability can
	%be unrealistic in certain situations. \citet{BXC2004} provides an
	%amended formulation which includes an extra interaction term=, $
	%d_{mr} \sim N(0,\omega^{2}_{m}$, to account for this.
	
	%\citet{BXC2004} uses the above formula to predict observations for
	%a specific individual $i$ by method $m$;
	
	% \subsection{Carstensen's LOAs}
	%==================================================================== %
	\subsection{Computation of Limits of Agreement in LME models}
	
	
\citet{BXC2008} demonstrates how to compute the limits of agreement for two methods in the case of linked measurements. As a surplus source of variability is excluded from the computation, the limits of agreement are not unduly wide, which would have been the case if the measurements were treated as true replicates.








	
=======
>>>>>>> a2f6c64bed72d1c25fc27f9237e0bc1750daf02c

\citet{BXC2008} proposed a technique to calculate prediction intervals in the presence of replicate measurements, overcoming problems associated with Bland-Altman approach in this regard. The following model (in the authors own notation) is
formulated as follows, where $y_{mir}$ is the $r$th replicate
measurement on subject $i$ with method $m$. The differences are expressed as $d_{i} = y_{1i} - y_{2i}$. \citet{BXC2008} compute the limits of agreement as
\begin{equation}
\hat{\alpha}_1 - \hat{\alpha}_2 \pm \pm 2 \sqrt{ \tau^2_1 +  \tau^2_2 +  \varphi^2_1 +  \varphi^2_2 }
\label{BXC-LOA-1}
\end{equation}
\citet{BXC2008} states a model where the variation between items for method $m$ is captured by $\tau_m$ (our notation $d^2_m$) and the within-item variation by $\sigma_m$. \citet{BXC2008} notes that, for $m=2$, separate estimates of $\tau^2_m$ can not be obtained.  When only two methods are compared, \citet{BXC2008} notes that separate estimates of $\tau^2_m$ can not be obtained due to the model over-specification. To overcome this, the assumption of equality, i.e. $\tau^2_1 = \tau^2_2$, is required, with the average value $\tau^2$ used in practice. Equation\ref{BXC-LOA-1} can be re-epxressed as follows
\begin{equation}
\hat{\alpha}_1 - \hat{\alpha}_2 \pm \sqrt{2 \hat{\tau}^2 + \hat{\sigma}^2_1 + \hat{\sigma}^2_2}
\end{equation}

Importantly the covariance terms in both variability matrices are zero, so no covariance components are present.



\subsubsection*{Matrices}
The between-subject variability ${D}$ and within-subject variability ${\Sigma}$ can be presented in matrix form,\[
{D} = \left(%
\begin{array}{cc}
d^2_{A}& 0 \\
0 & d^2_{B} \\
\end{array}%
\right)=\left(%
\begin{array}{cc}
d^2& 0 \\
0 & d^2\\
\end{array}%
\right),
\hspace{1.5cm}
{\Sigma} = \left(%
\begin{array}{cc}
\sigma^2_{A}& 0 \\
0 & \sigma^2_{B} \\
\end{array}%
\right).
\]

The variance for method $m$ is $d^2_{m}+\sigma^2_{m}$. Limits of agreement are determined using the standard deviation of the case-wise differences between the sets of measurements by two methods $A$ and $B$, given by
\begin{equation}
\mbox{var} (y_{A}-y_{B}) = 2d^2 + \sigma^2_{A}+ \sigma^2_{B}.
\end{equation}



%%\subsection{Carstensen Methods}
%%
%%
%%
%%
%%
%%% \frametitle{Computing LoAs from LME models}
%%\emph{
%%One important feature of replicate observations is that they should be independentof each other. In essence, this is achieved by ensuring that the observer makes each
%%measurement independent of knowledge of the previous value(s). This may be difficult
%%to achieve in practice.}
%%



\section{Roy's LME Framework for Method Comparison }
\citet{Barnhart} sets out three criteria for two methods to be considered in agreement: no significant bias, no difference in the between-subject variabilities, and no significant difference in the within-subject variabilities.


Lack of agreement may be identified by disagreement in overall variabilities. This lack of agreement may be due to differing between-item variabilities, differing within-item variabilities, or both. \citet{ARoy2009} proposes a suite of hypothesis tests for assessing the agreement of two methods of measurement, when replicate measurements are obtained for each item, using a LME approach. The formulation previously presented by \citet{ARoy2009} usefully facilitates a series of significance tests that assess if and where such differences arise. These tests are comprised of a formal test for the equality of between-item variances.


For the purposes of comparing two methods of measurement, \citet{ARoy2009} presents a framework utilizing LME models. The tests are implemented by fitting a specific LME model, and three variations thereof, to the data. These three variant models introduce equality constraints that act as null hypothesis cases.

In addition to computing the inter-method bias, three significance tests are carried out on the respective formulations to make a judgement on whether or not two methods are in agreement. The difference in the models are specifically in how the covariance matrices are constructed, using either an unstructured form or a compound symmetry form. This is a key component of this testing process.

This approach provides for the formal testing of inter-method bias, between-subject variability and within-subject variability of two methods. The formulation contains a Kronecker product covariance structure in a doubly multivariate setup. By doubly multivariate set up, Roy means that the information on each patient or item is multivariate at two levels, the number of methods and number of replicated measurements. Further to \citet{lam}, it is assumed that the replicates are linked over time. However it is easy to modify to the unlinked case.

\citet{ARoy2009} uses the same definition of replicate measurement as \citet{BA99}; measurements taken in quick succession by the same observer using the same instrument on the same subject can be considered true replicates under identical conditions.
\citet{ARoy2009} notes that some measurements may not be `true' replicates, as data can not be collected in this way. In such cases, the correlation matrix on the replicates may require a different structure, such as the autoregressive order one $AR(1)$ structure. However determining MLEs with such a structure would be computational intense, if possible at all.
<<<<<<< HEAD
	
	\citet{ARoy2009} proposes a suite of hypothesis tests for assessing the agreement of two methods of measurement, when replicate measurements are obtained for each item, using a LME approach. The tests are implemented by fitting a specific LME model, and three variations thereof, to the data. These three variant models introduce equality constraints that act as null hypothesis cases.
	
	In addition to computing the inter-method bias, three significance tests are carried out on the respective formulations to make a judgement on whether or not two methods are in agreement. The difference in the models are specifically in how the the $D$ and $\Sigma$ matrices are constructed, using either an unstructured form or a compound symmetry form. 
	
	
	Four candidates models are fitted to the data. The first model is compared against each of three other models successively. These tests are the pairwise comparison of candidate models, one formulated without constraints, the other with a constraint.
	
	The tests are implemented by fitting a four variants of a specific LME model to the data. For the purpose of comparing models, one of the models acts as a reference model while the three other variant are nested models that introduce equality constraints to serves as null hypothesis cases. The framework uses a linear mixed effects regression fit using a combination of symmetric and compound symmetry (CS) correlation structure the variance covariance matrices.
	

	
	For these tests, four candidate LME models are constructed. The differences in the models are specifically in how the the $D$ and $\Lambda$ matrices are constructed, using either an unstructured form or a compound symmetry form. To illustrate these differences, consider a generic matrix $A$,
	
	\[
	{A} = \left( \begin{array}{cc}
	a_{11} & a_{12}  \\
	a_{21} & a_{22}  \\
	\end{array}\right).
	\]
	
	A symmetric matrix allows the diagonal terms $a_{11}$ and $a_{22}$ to differ. The compound symmetry structure requires that both of these terms be equal, i.e $a_{11} = a_{22}$.
	
	
	\subsection{Model Specification for Roy's Hypotheses Tests}
	The LME model underpinning Roy's approach can be written
	\begin{equation}
		y_{mir} = \beta_{0} + \beta_{m} + b_{mi} + \epsilon_{mir}.
		\label{ARoy2009-model}
	\end{equation}
	Here $\beta_0$ and $\beta_m$ are fixed-effect terms representing, respectively, a model intercept and an overall effect for method $m.$ The model can be reparameterized by gathering the $\beta$ terms together into (fixed effect) intercept terms $\alpha_m=\beta_0+\beta_m.$ The $b_{1i}$ and $b_{2i}$ terms are correlated random effect parameters having $\mathrm{E}(b_{mi})=0$ with $\mathrm{Var}(b_{mi})=g^2_m$ and $\mathrm{Cov}(b_{1i}, b_{2 i})=g_{12}.$ The random error term for each response is denoted $\epsilon_{mir}$ having $\mathrm{E}(\epsilon_{mir})=0$, $\mathrm{Var}(\epsilon_{mir})=\sigma^2_m$, $\mathrm{Cov}(\epsilon_{1ir}, \epsilon_{2 ir})=\sigma_{12}$, $\mathrm{Cov}(\epsilon_{mir}, \epsilon_{mir^\prime})= 0$ and $\mathrm{Cov}(\epsilon_{1ir}, \epsilon_{2 ir^\prime})= 0.$ Additionally these parameter are assumed to have Gaussian distribution. Two methods of measurement are in complete agreement if the null hypotheses $\mathrm{H}_1\colon \alpha_1 = \alpha_2$ and $\mathrm{H}_2\colon \sigma^2_1 = \sigma^2_2 $ and $\mathrm{H}_3\colon g^2_1= g^2_2$ hold simultaneously. \citet{ARoy2009} uses a Bonferroni correction to control the familywise error rate for tests of $\{\mathrm{H}_1, \mathrm{H}_2, \mathrm{H}_3\}$ and account for difficulties arising due to multiple testing. Additionally, Roy combines $\mathrm{H}_2$ and $\mathrm{H}_3$ into a single testable hypothesis $\mathrm{H}_4\colon \omega^2_1=\omega^2_2,$ where $\omega^2_m = \sigma^2_m + g^2_m$ represent the overall variability of method $m.$
	%Disagreement in overall variability may be caused by different between-item variabilities, by different within-item variabilities, or by both.
	
	%If the exact cause of disagreement between the two methods is not of interest, then the overall variability test $H_4$ %is an alternative to testing $H_2$ and $H_3$ separately.
	
	%\citet{ARoy2009} proposes a novel method using the LME model with Kronecker product covariance structure in a doubly multivariate set-up to assess the agreement between a new method and an established method with unbalanced data and with unequal replications for different subjects.

	
	\subsection{Formulation of the Response Vector}
	Information of individual $i$ is recorded in a response vector ${y}_{i}$. The response vector is constructed by stacking the response of the $2$ responses at the first instance, then the $2$ responses at the second instance, and so on. Therefore the response vector is a $2n_{i} \times 1$ column vector.
	The covariance matrix of ${y_{i}}$ is a $2n_{i} \times 2n_{i}$ positive definite matrix ${\Omega}_{i}$.
	
	Consider the case where three measurements are taken by both methods $A$ and $B$, ${y}_{i}$ is a $6 \times 1$ random vector describing the $i$th subject.
	\[
	{y}_{i} = (y_{i}^{A1},y_{i}^{B1},y_{i}^{A2},y_{i}^{B2},y_{i}^{A3},y_{i}^{B3}) \prime
	\]
	
	The response for $i$th subject can be written as
	\[ y_i = \beta_0 + \beta_1x_{i1} + \beta_2x_{i2} + b_{1i}z_{i1}  + b_{2i}z_{i2} + \epsilon_i \]
	
	In order to express Roy's LME model in matrix notation we gather all $2n_i$ observations specific to item $i$ into a single vector  ${y}_{i} = (y_{1i1},y_{2i1},y_{1i2},\ldots,y_{mir},\ldots,y_{1in_{i}},y_{2in_{i}})^\prime.$ 
	The response vector ${y_{i}}$ can be formulated as an LME model according to Laird-Ware form.
	\begin{equation}
		{y_{i}} = {X_{i}\beta}  + {Z_{i}b_{i}} + {\epsilon_{i}}\\
\label{ARoy2009-model2}
	\end{equation}
with ${b_{i}} \sim \mathcal{N}({0,D})$ and ${\epsilon_{i}} \sim \mathcal{N}({0,R_{i}})$. Information on the fixed effects are contained in a three dimensional vector ${\beta} = (\beta_{0},\beta_{1},\beta_{2})\prime$. For computational purposes $\beta_{2}$ is conventionally set to zero. Consequently ${\beta}$ is the solutions of the means of the two methods, i.e. $E({y}_{i})  = {X}_{i}{\beta}$. The variance covariance matrix $\boldsymbol{D}$ is a general $2 \times 2$ matrix, while $\boldsymbol{R}_{i}$ is a $2n_{i} \times 2n_{i}$ matrix.
	
	%------------------------------------------------------------------------------%
	
	\subsection{Likelihood Ratio Tests}
	The first model acts as an alternative hypothesis to be compared against each of three other models, acting as null hypothesis models, successively. The models are compared using the likelihood ratio test. 
	
	The first candidate model is compared to each of the three other models successively. It is the alternative model in each of the three tests, with the other three models acting as the respective null models. The models are compared using the likelihood ratio test, a general method for comparing nested models fitted by ML \citep{Lehmann2006} \textit{Lehmann (2006)}.
	
	Likelihood ratio tests are a class of tests based on the comparison of the values of the likelihood functions of two candidate models. LRTs can be used to test hypotheses about covariance parameters or fixed effects parameters in the context of LMEs. The test statistic for the likelihood ratio test is the difference of the log-likelihood functions, multiplied by $-2$.
	The probability distribution of the test statistic is approximated by the $\chi^2$ distribution with ($\nu_{1} - \nu_{2}$) degrees of freedom, i.e. the difference between the degrees of freedom of models 1 and 2 respectively. 
	
	
	
	\subsection{Roy's Tests of Variances}
	
	
	
	
	\citet{ARoy2009} proposes a series of three tests on the variance components of an LME model. For these tests, four candidate models are fitted to the data, each differing by various constraints applied to the variance covariance matrices. 
	
	
	
	
	Three tests of hypothesis are provided, appropriate for evaluating the agreement between the two methods of measurement under this sampling scheme. 
	
Joint consideration of second and third criteria is enabled by a formal test for the equality of overall variances, $\operatorname{H_4} : \omega^2_1 = \omega^2_2$ is also presented. Disagreement in overall variability may be caused by different between-item variabilities, by different within-item variabilities, or by both.  If the exact cause of disagreement between the two methods is not of interest, then the overall variability test $H_4$ is an alternative to testing $H_2$ and $H_3$ separately.
=======
>>>>>>> a2f6c64bed72d1c25fc27f9237e0bc1750daf02c






\subsection{Model Specification for Roy's Hypotheses Tests}
The LME model underpinning Roy's approach can be written
\begin{equation}\label{ARoy2009-model}
y_{mir} = \beta_{0} + \beta_{m} + b_{mi} + \epsilon_{mir}.
\end{equation}
Here $\beta_0$ and $\beta_m$ are fixed-effect terms representing, respectively, a model intercept and an overall effect for method $m.$ The model can be reparameterized by gathering the $\beta$ terms together into (fixed effect) intercept terms $\alpha_m=\beta_0+\beta_m.$ The $b_{1i}$ and $b_{2i}$ terms are correlated random effect parameters having $\mathrm{E}(b_{mi})=0$ with $\mathrm{Var}(b_{mi})=d^2_m$ and $\mathrm{Cov}(b_{1i}, b_{2 i})=d_{12}.$ The random error term for each response is denoted $\epsilon_{mir}$ having $\mathrm{E}(\epsilon_{mir})=0$, $\mathrm{Var}(\epsilon_{mir})=\sigma^2_m$, $\mathrm{Cov}(\epsilon_{1ir}, \epsilon_{2 ir})=\sigma_{12}$, $\mathrm{Cov}(\epsilon_{mir}, \epsilon_{mir^\prime})= 0$ and $\mathrm{Cov}(\epsilon_{1ir}, \epsilon_{2 ir^\prime})= 0.$ Additionally these parameter are assumed to have Gaussian distribution. Two methods of measurement are in complete agreement if the null hypotheses $\mathrm{H}_1\colon \alpha_1 = \alpha_2$ and $\mathrm{H}_2\colon \sigma^2_1 = \sigma^2_2 $ and $\mathrm{H}_3\colon d^2_1= d^2_2$ hold simultaneously. \citet{ARoy2009} uses a Bonferroni correction to control the familywise error rate for tests of $\{\mathrm{H}_1, \mathrm{H}_2, \mathrm{H}_3\}$ and account for difficulties arising due to multiple testing. Additionally, Roy combines $\mathrm{H}_2$ and $\mathrm{H}_3$ into a single testable hypothesis $\mathrm{H}_4\colon \omega^2_1=\omega^2_2,$ where $\omega^2_m = \sigma^2_m + d^2_m$ represent the overall variability of method $m.$
%Disagreement in overall variability may be caused by different between-item variabilities, by different within-item variabilities, or by both.

%If the exact cause of disagreement between the two methods is not of interest, then the overall variability test $H_4$ %is an alternative to testing $H_2$ and $H_3$ separately.

%\citet{ARoy2009} proposes a novel method using the LME model with Kronecker product covariance structure in a doubly multivariate set-up to assess the agreement between a new method and an established method with unbalanced data and with unequal replications for different subjects.


\subsection{Formulation of the Response Vector}
Information of individual $i$ is recorded in a response vector ${y}_{i}$. The response vector is constructed by stacking the response of the $2$ responses at the first instance, then the $2$ responses at the second instance, and so on. Therefore the response vector is a $2n_{i} \times 1$ column vector.
The covariance matrix of ${y_{i}}$ is a $2n_{i} \times 2n_{i}$ positive definite matrix $\boldsymbol{\Omega}_{i}$.

Consider the case where three measurements are taken by both methods $A$ and $B$, ${y}_{i}$ is a $6 \times 1$ random vector describing the $i$th subject.
\[
{y}_{i} = (y_{i}^{A1},y_{i}^{B1},y_{i}^{A2},y_{i}^{B2},y_{i}^{A3},y_{i}^{B3}) \prime
\]

The response for $i$th subject can be written as
\[ y_i = \beta_0 + \beta_1x_{i1} + \beta_2x_{i2} + b_{1i}z_{i1}  + b_{2i}z_{i2} + \epsilon_i \]

In order to express Roy's LME model in matrix notation we gather all $2n_i$ observations specific to item $i$ into a single vector  ${y}_{i} = (y_{1i1},y_{2i1},y_{1i2},\ldots,y_{mir},\ldots,y_{1in_{i}},y_{2in_{i}})^\prime.$
The response vector ${y_{i}}$ can be formulated as an LME model according to classical Laird-Ware form.

\begin{equation}
{y_{i}} = {X_{i}\beta}  + {Z_{i}b_{i}} + {\epsilon_{i}},
\end{equation}
with ${b_{i}} \sim \mathcal{N}({0,\boldsymbol{D}})$ and 
${\epsilon_{i}} \sim \mathcal{N}({0,\boldsymbol{R_{i}}})$.
Information on the fixed effects are contained in a three dimensional vector ${\beta} = (\beta_{0},\beta_{1},\beta_{2})\prime$. For computational purposes $\beta_{2}$ is conventionally set to zero. Consequently ${\beta}$ is the solutions of the means of the two methods, i.e. $E({y}_{i})  = {X}_{i}{\beta}$. The variance covariance matrix $\boldsymbol{D}$ is a general $2 \times 2$ matrix, while $\boldsymbol{R}_{i}$ is a $2n_{i} \times 2n_{i}$ matrix.





For these tests, four candidate LME models are constructed. The differences in the models are specifically in how the the $D$ and $\Sigma$ matrices are constructed, using either an unstructured form or a compound symmetry form. To illustrate these differences, consider a generic matrix $A$,
%------------------------------------------------------------------------------%
Four candidates models are fitted to the data. The first model is compared against each of three other models successively. These tests are the pairwise comparison of candidate models, one formulated without constraints, the other with a constraint.

The tests are implemented by fitting a four variants of a specific LME model to the data. For the purpose of comparing models, one of the models acts as a reference model while the three other variant are nested models that introduce equality constraints to serves as null hypothesis cases. The framework uses a linear mixed effects regression fit using a combination of symmetric and compound symmetry (CS) correlation structure the variance covariance matrices.
\[
{A} = \left( \begin{array}{cc}
a_{11} & a_{12}  \\
a_{21} & a_{22}  \\
\end{array}\right).
\]

A symmetric matrix allows the diagonal terms $a_{11}$ and $a_{22}$ to differ. The compound symmetry structure requires that both of these terms be equal, i.e $a_{11} = a_{22}$.

\subsection{Likelihood Ratio Tests}
The first model acts as an alternative hypothesis to be compared against each of three other models, acting as null hypothesis models, successively. The models are compared using the likelihood ratio test, a general method for comparing nested models fitted by ML \citep{Lehmann2006} \textit{Lehmann (2006)}.

Likelihood ratio tests are a class of tests based on the comparison of the values of the likelihood functions of two candidate models. LRTs can be used to test hypotheses about covariance parameters or fixed effects parameters in the context of LMEs. The test statistic for the likelihood ratio test is the difference of the log-likelihood functions, multiplied by $-2$.
The probability distribution of the test statistic is approximated by the $\chi^2$ distribution with ($\nu_{1} - \nu_{2}$) degrees of freedom, i.e. the difference between the degrees of freedom of models 1 and 2 respectively.



\subsection{Roy's Tests of Variances}


\citet{ARoy2009} proposes a series of three tests on the variance components of an LME model, appropriate for evaluating the agreement between the two methods of measurement under this sampling scheme. For these tests, four candidate models are fitted to the data, each differing by various constraints applied to the variance covariance matrices.

Two methods can be considered to be in agreement if criteria based upon these techniques are met. Additionally Roy makes reference to the overall correlation coefficient of the two methods, which is determinable from variance estimates.

Conversely, the tests of variability required detailed explanation. Each test is performed by fitting two candidate models, according with the null and alternative hypothesis respectively. The distinction between the models arise in the specification in one, or both, of the variance-covariance matrices. % A likelihood ratio test can then be used to compare these respective fits.

Joint consideration of second and third criteria is enabled by a formal test for the equality of overall variances, $\operatorname{H_4} : \omega^2_1 = \omega^2_2$ is also presented. Disagreement in overall variability may be caused by different between-item variabilities, by different within-item variabilities, or by both.  If the exact cause of disagreement between the two methods is not of interest, then the overall variability test $H_4$ is an alternative to testing $H_2$ and $H_3$ separately.


\subsubsection{Variability Test 1}
The first test determines of $H_{2}: d_{1}  = d_{2}$, whether or not both methods $A$ and $B$ have the same between-subject variability, further to the second of Roy's criteria.

This test is facilitated by constructing a model specifying a symmetric form for $D$ (i.e. the alternative model) and comparing it with a model that has compound symmetric form for $\boldsymbol{\hat{D}}$ (i.e. the null model). For this test $\boldsymbol{\hat{\Sigma}}$ has a symmetric form for both models, and will be the same for both.

The first test allows of the comparison the begin-subject variability of two methods. Similarly, the second test assesses the within-subject variability of two methods. A third test is a test that compares the overall variability of the two methods. Other important aspects of the method comparison study are consequent. The limits of agreement are computed using the results of the first model.

\subsubsection{Variability Test 2}

This test determines whether or not both methods have the same within-subject variability, i.e. $H_{0}: \sigma_{1}  = \sigma_{2}$ thus enabling a decision on the third of Roy's criteria.

This model is performed in the same manner as the first test, only reversing the roles of ${\hat{\boldsymbol{D}}}$ and $\boldsymbol{\hat{\Sigma}}$. The null model is constructed a symmetric form for ${\hat{\Sigma}}$ while the alternative model uses a compound symmetry form. This time ${\hat{\boldsymbol{D}}}$ has a symmetric form for both models, and will be the same for both.

As the within-subject variabilities are fundamental to the coefficient of repeatability, this variability test likelihood ratio test is equivalent to testing the equality of two coefficients of repeatability of two methods. In presenting the results of this test, \citet{ARoy2009} includes the coefficients of repeatability for both methods.


\subsubsection{Variability Test 3}
%Roy also integrates $\mathrm{H}_2$ and $\mathrm{H}_3$ into a single testable
%   hypothesis $\mathrm{H}_4\colon \omega^2_1=\omega^2_2,$ where $\omega^2_m =
%  \sigma^2_m + d^2_m$ represent the overall variability of method $m.$
\citet{ARoy2009} further proposes examination of the the overall variability by considering the second and third criteria be examined jointly. Should both the second and third criteria be fulfilled, then the overall variabilities of both methods would be equal. An examination of this topic is useful because a method for computing Limits of Agreement follows from here.
<<<<<<< HEAD
	
 \citet{ARoy2009} denotes the overall variability as ${\mbox{Block-}\Omega_{i}}$, defining it as the addition of estimate of the between-subject variance covariance matrix $\hat{D}$ and the within-subject variance covariance matrix $\hat{\Sigma}$, i.e. Block $\Omega_{i} = \hat{D} + \hat{\Sigma}$,
	\begin{equation}
\mbox{Block } {\Omega}_i = \left(\begin{array}{cc}
		\omega^2_1  & \omega_{12} \\
		\omega_{12} & \omega^2_2 \\
		\end{array}  \right)
		=  \left(
		\begin{array}{cc}
		d^2_1  & d_{12} \\
		d_{12} & d^2_2 \\
		\end{array} \right)+
		\left(
		\begin{array}{cc}
		\sigma^2_1  & \sigma_{12} \\
		\sigma_{12} & \sigma^2_2 \\
		\end{array}\right)
\end{equation}
The null model is constructed a symmetric form for both ${\hat{D}}$ and ${\hat{\Lambda}}$ while the alternative model uses a compound symmetry form for both.
	
\subsection{Computing Limits of Agreement Using Roy's Model}
	\citet{ARoy2009} has demonstrated a method whereby $d^2_{x}$ and $d^2_{y}$ can be estimated separately. Also covariance terms are present in both ${D}$ and ${\Sigma}$. Using Roy's approach, the variance of case-wise difference in measurements can be determined from Block-${\Omega}_{i}$. Hence limits of agreement can be computed. The computation of the limits of agreement require that the variance of the difference of measurements. This variance is easily computable from the estimate of the ${\mbox{Block-}\Omega_{i}}$ matrix.
	The variance of differences is easily computable from the variance estimates in the ${\mbox{Block-}\Omega_{i}}$ matrix, i.e.
	\[
	\mathrm{Var}(y_1 - y_2) = \sqrt{ \omega^2_1 + \omega^2_2 - 2\omega_{12}}.
	\]
	Lack of agreement can arise if there is a disagreement in overall variabilities. 
	%-------------------------------------------------------------------------------------%
	
	The limits of agreement computed by Roy's method are derived from the variance covariance matrix for overall variability.
	This matrix is the sum of the between subject VC matrix and the within-subject Variance Covariance matrix.
	For Carstensen's `fat' data, the limits of agreement computed using Roy's
	method are consistent with the estimates given by \citet{BXC2008}; $0.044884  \pm 1.96 \times  0.1373979 = (-0.224,  0.314).$
	
	
	
	

	

%=========================================================================================================== %

\subsection{Correlation}
Bivariate correlation coefficients have been shown to be of limited use in method comparison studies \citep{BA86}. However, recently correlation analysis has been developed to cope with repeated measurements, enhancing their potential usefulness. 

Roy's tests are complemented by the ability to the overall correlation coefficient of the two methods, which are estimable from variance estimates. Two methods can be considered to be in agreement if criteria based upon these tests are met. Inference for inter-method bias follows from well-established methods and, as such, will only be noted when describing examples.
=======

The estimated overall variance covariance matrix Block-$\boldsymbol{\Omega_{i}}$' is the addition of estimate of the between-subject variance covariance matrix ${\hat{\boldsymbol{D}}}$ and the within-subject variance covariance matrix $\boldsymbol{\hat{\Sigma}}$.

\begin{equation}
\mbox{Block-}\boldsymbol{\Omega_{i}} = \boldsymbol{\hat{D}} + \boldsymbol{\hat{\Sigma}}
\end{equation}
Overall variability between the two methods ($\Omega$) is sum of between-subject ($D$) and within-subject variability ($\boldsymbol{\Sigma}$),
\citet{ARoy2009} denotes the overall variability as ${\mbox{Block-} \Omega_{i}}$. The overall variation for methods $1$ and $2$ are given by

\begin{equation}\mbox{Block } {\Omega}_i = \left(\begin{array}{cc}
\omega^2_1  & \omega_{12} \\
\omega_{12} & \omega^2_2 \\
\end{array}  \right)
=  \left(
\begin{array}{cc}
d^2_1  & d_{12} \\
d_{12} & d^2_2 \\
\end{array} \right)+
\left(
\begin{array}{cc}
\sigma^2_1  & \sigma_{12} \\
\sigma_{12} & \sigma^2_2 \\
\end{array}\right)
\end{equation}


The null model is constructed a symmetric form for both $\boldsymbol{\hat{D}}$ and ${\hat{\Sigma}}$ while the alternative model uses a compound symmetry form for both.

%=========================================================================================================== %

\section{Correlation}
Bivariate correlation coefficients have been shown to be of limited use in method comparison studies \citep{BA86}. However,
recently correlation analysis has been developed to cope with repeated measurements, enhancing their potential usefulness.
Roy's tests are complemented by the ability to the overall correlation coefficient of the two methods, which are estimable from variance estimates.
>>>>>>> a2f6c64bed72d1c25fc27f9237e0bc1750daf02c


In addition to the variability tests, \citet{ARoy2009} advises that it is preferable that a correlation of greater than $0.82$ exist for two methods to be considered interchangeable. However if two methods fulfil all the other conditions for agreement, failure to comply with this one can be overlooked, and demonstrates that placing undue importance to it can lead to incorrect conclusions.

\citet{ARoy2009} remarks that current computer implementations (e.g. PROC MIXED) only gives overall correlation coefficients, but not their variances. Similarly variance are not determinable in \texttt{R} as yet either. Consequently it is not possible to carry out inferences based on all overall correlation coefficients.
%===========================================================================================================%
\subsection{Formal Testing for Covariances} %(Off-Diagonal Components in Roy's Model)

The within-item variability is specified as follows, where $x$ and $y$ are the methods of measurement in question.
\[ \left(
\begin{array}{cc}
\sigma^2_x & \sigma_{xy} \\
\sigma_{xy} & \sigma^2_y \\
\end{array}
\right)
\]

<<<<<<< HEAD
$\sigma^2_x$ and $\sigma^2_y$ describe the level of measurement error associated with each of the measurement methods for a given item. Attention must be given to the off-diagonal elements of the matrix. 

It is intuitive to consider the measurement error of the two methods as independent of each other. A formal test can be performed to test the hypothesis that the off-diagonal terms are zero.
%\[ \left(
%\begin{array}{cc}
%\sigma^2_x & \sigma_{xy} \\
%\sigma_{xy} & \sigma^2_y \\
%\end{array}
%\right) vs \left(
%\begin{array}{cc}
%\sigma^2_x & 0 \\
%0 & \sigma^2_y \\
%\end{array}
%\right)
%\]

=======
$\sigma^2_x$ and $\sigma^2_y$ describe the level of measurement error associated with each of the measurement methods for a given item. Attention must be given to the off-diagonal elements of the matrix. It is intuitive to consider the measurement error of the two methods as independent of each other. A formal test can be performed to test the hypothesis that the off-diagonal terms are zero.


>>>>>>> a2f6c64bed72d1c25fc27f9237e0bc1750daf02c
As it is pertinent to the difference between the two described methodologies, the facilitation of a formal test would be useful. Extending the approach proposed by \citet{ARoy2009}, the test for overall covariance can be formulated as $\operatorname{H_5} : \sigma_{xy} = 0$.

As with the tests for variability, this test is performed by comparing a pair of model fits corresponding to the null and alternative hypothesis. In addition to testing the overall covariance, similar tests can be formulated for both the component variabilities if necessary.

%------------------------------------------------------------------------------------%


\subsection{Computing Limits of Agreement Using Roy's Model}
\citet{ARoy2009} has demonstrated a method whereby $d^2_{A}$ and $d^2_{B}$ can be estimated separately. Also covariance terms are present in both $\boldsymbol{D}$ and $\boldsymbol{\Sigma}$. Using Roy's approach, the variance of case-wise difference in measurements can be determined from Block-$\boldsymbol{\Omega}_{i}$. Hence limits of agreement can be computed. The computation of the limits of agreement require that the variance of the difference of measurements. This variance is easily computable from the estimate of the ${\mbox{Block - } \Omega_{i}}$ matrix.
The variance of differences is easily computable from the variance estimates in the ${\mbox{Block - } \Omega_{i}}$ matrix, i.e.
\begin{equation}
\mathrm{Var}(y_1 - y_2) = \sqrt{ \omega^2_1 + \omega^2_2 - 2\omega_{12}}.
\label{Roy-LOA}
\end{equation}
Lack of agreement can arise if there is a disagreement in overall variabilities.
%-------------------------------------------------------------------------------------%

The limits of agreement computed by Roy's method are derived from the variance covariance matrix for overall variability.
This matrix is the sum of the between subject VC matrix and the within-subject Variance Covariance matrix.
For Carstensen's `fat' data, the limits of agreement computed using Roy's
method are consistent with the estimates given by \citet{BXC2008}; $0.045  \pm 1.96 \times  0.137 = (-0.224,  0.314).$








\section{Extension of Roy's Technique}
Roy's methodology is constructed to compare two methods in the presence of replicate measurements. Necessarily it is worth examining whether this methodology can be adapted for different circumstances.

An implementation of Roy's methodology, whereby three or more methods are used, is not feasible due to computational restrictions. Specifically there is a failure to reach convergence before the iteration limit is reached. This may be due to the presence of additional variables, causing the problem of non-identifiability. In the case of two variables, it is required to estimate two variance terms and four correlation terms, six in all. For the case of three variabilities, three variance terms must be estimated as well as nine correlation terms, twelve in all. In general for $n$ methods has $2 \times T_{n}$ variance terms, where $T_n$ is the triangular number for $n$, i.e. the addition analogue of the factorial. Hence the computational complexity quite increases substantially for every increase in $n$.

Should an implementation be feasible, further difficulty arises when interpreting the results. The fundamental question is whether two methods have close agreement so as to be interchangeable. When three methods are present in the model, the null hypothesis is that all three methods have the same variability relevant to the respective tests. The outcome of the analysis will either be that all three are interchangeable or that all three are not interchangeable.

The tests would not be informative as to whether any two of those three were interchangeable, or equivalently if one method in particular disagreed with the other two. Indeed it is easier to perform three pair-wise comparisons separately and then to combine the results.



\subsection{Application of Roy's Approach For Non-Replicate Measurements}

Roy's methodology is not suitable for the case of single measurements because it follows from the decomposition for the covariance matrix of the response vector $y_{i}$, as presented in \citet{hamlett}. The decomposition depends on the estimation of correlation terms, which would be absent in the single measurement case. Indeed there can be no within-subject variability if there are no repeated terms for it to describe. There would only be the covariance matrix of the measurements by both methods, which doesn't require the use of LME models. To conclude, simpler existing methodologies, such as Deming regression, would be the correct approach where there only one measurements by each method.

\section{Differences Between Approaches}

<<<<<<< HEAD
Both \citet{BXC2008} and \citet{ARoy2009} present methodologies to compute the limits of agreement based on LME models. In many cases the limits of agreement derived from this method accord with each other. However, in other cases dissimilarities emerge.
=======
\section{Differences Between Approaches}
>>>>>>> a2f6c64bed72d1c25fc27f9237e0bc1750daf02c

The presence of the true value term $\mu_i$ gives rise to an important difference between these approaches. The fixed effect of Roy's model comprise of an intercept term and fixed effect terms for both methods, with no reference to the true value of any individual item; the model in (\ref{ARoy2009-model}) requires two fixed effect parameters, i.e. the means of the two methods, for any number of items $N$.

<<<<<<< HEAD
Conversely the model in (\ref{BXC-simple}) requires $N+2$ fixed effects. Allocating fixed effects to each item $i$ by (\ref{BXC-simple}) accords with earlier work on comparing methods of measurement, such as \citet{Grubbs48}. However allocation of fixed effects in ANOVA models suggests that the group of items is itself of particular interest, rather than as a representative sample used of the overall population. However this approach seems contrary to the purpose of LOAs as a prediction interval for a population of items. 
=======
Importantly, Carstensen's underlying model differs from Roy's model in some key respects, and therefore a prior discussion of Carstensen's model is required. The method of computation is the
same as Roy's model, but with the covariance estimates set to zero.
>>>>>>> a2f6c64bed72d1c25fc27f9237e0bc1750daf02c

Arguably, \citet{ARoy2009} uses a more intuitive approach, treating the observations as a random sample population, and allocating random effects accordingly. In other words, this model considers the group of items being measured as a sample taken from a population. Therefore a distinction can be made between the two models: Roy's model is a standard LME model, whereas Carstensen's model is a more complex additive model.

Another important difference is that (\ref{BXC-model}) requires that particular assumptions be applied, specifically that the off-diagonal elements of the between-item and within-item variability matrices are zero. By extension the
overall variability off-diagonal elements are also zero. Therefore the variance covariance matrices for between-item and within-item variability are respectively.

<<<<<<< HEAD
	
 
=======
%---Key difference 1---The True Value
In cases where there is negligible covariance between methods, the limits of agreement computed using Roy's model accord with those computed using Carstensen's model. In cases where some degree of
covariance is present between the two methods, the limits of agreement computed using models will differ. In the presented
example, it is shown that Roy's LOAs are lower than those of Carstensen, when covariance is present.

\citet{BXC2008} also presents a methodology to compute the limits of agreement based on LME models. In many cases the limits of agreement derived from this method accord with those to Roy's model. However, in other cases dissimilarities emerge. An explanation for this differences can be found by considering how the respective models account for covariance in the observations.

The presence of the true value term $\mu_i$ gives rise to an important difference between Carstensen's and Roys's models. The fixed effect of Roy's model comprise of an intercept term and fixed effect terms for both methods, with no reference to the true value of any individual item. In other words, Roy considers the group of items being measured as a sample taken from a population. Therefore a distinction can be made between the two models: Roy's model is a standard LME model, whereas Carstensen's model is a more complex additive model.

%Of particular importance is terms of the model, a true value for item $i$ ($\mu_{i}$).  The fixed effect of Roy's model comprise of an intercept term and fixed effect terms for both methods, with no reference to the true value of any individual item. A distinction can be made between the two models: Roy's model is a standard LME model, whereas Carstensen's model is a more complex additive model.

Allocating fixed effects to each item $i$ by (\ref{BXC-simple}) accords with earlier work on comparing methods of measurement, such as \citet{Grubbs48}.

However allocation of fixed effects in ANOVA models suggests that the group of items is itself of particular interest, rather than as a representative sample used of the overall population. However this approach seems contrary to the purpose of LOAs as a prediction interval for a population of items.

There is a substantial difference in the number of fixed parameters used by the respective models; the model in \citet{ARoy2009} requires two fixed effect parameters, i.e. the means of the two methods, for any number of items $N$, whereas the model using the Carstensen Model requires $N+2$ fixed effects. Allocating fixed effects to each item $i$ using Carstensen's model accords with earlier work on comparing methods of measurement, such as \citet{Grubbs48}.

Conversely, \citet{ARoy2009} uses a more intuitive approach, treating the observations as a random sample population, and allocating random effects accordingly. Specifying the relevant terms using a bivariate normal distribution, Roy's model allows for both between-method and within-method covariance. \citet{BXC2008} formulate a model whereby random effects have univariate normal distribution, and no allowance is made for correlation between observations.

In contrast to Roy's model, Carstensen's model requires that commonly used assumptions be applied, specifically that the off-diagonal elements of the between-item and within-item variability matrices are zero. By extension the overall variability off-diagonal elements are also zero. Therefore the variance covariance matrices for
between-item and within-item variability are respectively.

\[{D} = \left(
\begin{array}{cc}
d^1_2  & 0 \\
0 & d^2_2 \\
\end{array}
\right) \;\;\;\; {\Sigma} = \left(
\begin{array}{cc}
\sigma^1_2  & 0 \\
0 & \sigma^2_2 \\
\end{array}
\right) \]
As a consequence, Carstensen's method does not allow for a formal test of the between-item variability.

A consequence of this is that the between-method and within-method covariance are zero. In cases where there is negligible covariance between methods, the limits of agreement computed using Roy's model accord with those computed using model described by \citet{BXC2008}. In cases where some degree of covariance is present between the two methods, the limits of agreement computed using models will differ. In the presented example, it is shown that Roy's LoAs are lower than those of Carstensen, when covariance is present.

\[\left(\begin{array}{cc}
\omega^2_1  & 0 \\
0 & \omega^2_2 \\
\end{array}  \right)
=  \left(
\begin{array}{cc}
\tau^2  & 0 \\
0 & \tau^2 \\
\end{array} \right)+
\left(
\begin{array}{cc}
\sigma^2_1  & 0 \\
0 & \sigma^2_2 \\
\end{array}\right)
\]

>>>>>>> a2f6c64bed72d1c25fc27f9237e0bc1750daf02c

Specifying the relevant terms using a bivariate normal distribution, Roy's model allows for both between-method and within-method covariance. \citet{BXC2008} formulate a model whereby random effects have univariate normal distribution, and no allowance is made for correlation between observations.

<<<<<<< HEAD



In cases where there is negligible covariance between methods, the limits of agreement computed using \ref{ARoy2009-model} accord with those computed using \ref{BXC-simple}. In cases where some degree of covariance is present between the two methods, the limits of agreement computed will differ between models. In the presented example, it is shown that Roy's LOAs are lower than those of Carstensen, when covariance is present.

Finally, implementation requires that the between-item variances are estimated as the same value: $d^2_1 = d^2_2 = d^2$. Necessarily Carstensen's method does not allow for a formal test of the between-item variability.




\[{D} = \left(
\begin{array}{cc}
d^1_2  & 0 \\
0 & d^2_2 \\
\end{array}
\right) \;\;\;\; {\Sigma} = \left(
\begin{array}{cc}
\sigma^1_2  & 0 \\
0 & \sigma^2_2 \\
\end{array}
\right) \]
As a consequence, Carstensen's method does not allow for a formal test of the between-item variability.
=======

>>>>>>> a2f6c64bed72d1c25fc27f9237e0bc1750daf02c


\[\left(\begin{array}{cc}
\omega^2_1  & 0 \\
0 & \omega^2_2 \\
\end{array}  \right)
=  \left(
\begin{array}{cc}
d^2  & 0 \\
0 & d^2 \\
\end{array} \right)+
\left(
\begin{array}{cc}
\sigma^2_1  & 0 \\
0 & \sigma^2_2 \\
\end{array}\right)
\]
<<<<<<< HEAD
=======
In cases where the off-diagonal terms in the overall variability
matrix are close to zero, the limits of agreement due to \citet{BXC2008} are very similar to the limits of agreement that follow from the general model.


%================================================================= %


\subsection{Comparing MCS Approaches}


>>>>>>> a2f6c64bed72d1c25fc27f9237e0bc1750daf02c


<<<<<<< HEAD
%Of particular importance is terms of the model, a true value for item $i$ ($\mu_{i}$).  
	
%	Finally, to complement the blood pressure (i.e.`J vs S') method comparison from the previous section (i.e.`J vs S'), the limits of agreement are $15.62 \pm 1.96 \times 20.33 = (-24.22, 55.46)$.)
	
	Carstensen presents two models. One for the case where the replicates, and a second for when they are linked.
	Carstensen's model does not take into account either between-item or within-item covariance between methods.\\
	In the presented example, it is shown that Roys's LoAs are lower than those of Carstensen.
	
	
	
	
	\[\left(\begin{array}{cc}
	\omega^1_2  & 0 \\
	0 & \omega^2_2 \\
	\end{array}  \right)
	=  \left(
	\begin{array}{cc}
	\tau^2  & 0 \\
	0 & \tau^2 \\
	\end{array} \right)+
	\left(
	\begin{array}{cc}
	\sigma^2_1  & 0 \\
	0 & \sigma^2_2 \\
	\end{array}\right)
	\]
	
	Carstensen's approach is that of a standard two-way mixed effects ANOVA with replicate measurements.
	

	

%========================================================================================= %
\section{Conclusion}
\citet{BXC2008} and \citet{ARoy2009} highlight the need for method comparison methodologies suitable for use in the presence of replicate measurements. \citet{ARoy2009} presents a comprehensive methodology for assessing the agreement of two methods, for replicate measurements. This methodology has the added benefit of overcoming the problems of unbalanced data and unequal numbers of replicates. 

Implementation of the methodology, and interpretation of the results, is relatively easy for practitioners who have only basic statistical training. Furthermore, it can be shown that widely used existing methodologies, such as the limits of agreement, can be incorporated into Roy's methodology.


	\citet{BXC2008} remark that modern statistical computation, such as that used for LME models, greatly improve the efficiency of calculation compared to previous `by-hand' approaches, as advocated in \citet{BA99}, describing them as tedious, unnecessary and outdated. Instead estimates for required LME parameters can be read directly from program output. Furthermore, using computer approaches removes associated constraints, such as the need for the design to be perfectly balanced.
	
	
	
	Limits of agreement are used extensively for assessing agreement, because they are intuitive and easy to use. Their prevalence in literature has meant that they are now the best known measurement for agreement, and therefore any newer methodology would benefit by making reference to them.
	
		
	\citet{ARoy2009} formulated a very powerful method of assessing the agreement of two methods of measurement, with replicate measurements, also using LME models. This approach does not directly address the issue of limits of agreement, but does allow for an alternative approach to computing LoAs using LME Models. 
	%Therefore, for the sake of consistency, a data set will be simulated based on the Blood Data that will allow for extra variables, and an exploration shall be provided in the appendices.
	
	
	\addcontentsline{toc}{section}{Bibliography}
	\bibliographystyle{chicago}
	\bibliography{2017bib}
=======
Finally, to complement the blood pressure (i.e.`J vs S') method comparison from the previous section (i.e.`J vs S'), the limits of agreement are $15.62 \pm 1.96 \times 20.33 = (-24.22, 55.46)$.)

In the presented example, it is shown that Roys's LoAs are lower than those of Carstensen.



%========================================================================================= %
\section{Conclusion}
\citet{BXC2008} and \citet{ARoy2009} highlight the need for method comparison methodologies suitable for use in the presence of replicate measurements. \citet{ARoy2009} presents a comprehensive methodology for assessing the agreement of two methods, for replicate measurements. This methodology has the added benefit of overcoming the problems of unbalanced data and unequal numbers of replicates. Implementation of the methodology, and interpretation of the results, is relatively easy for practitioners who have only basic statistical training. 

Limits of agreement are used extensively for assessing agreement, because they are intuitive and easy to use. Their prevalence in literature has meant that they are now the best known measurement for agreement, and therefore any newer methodology would benefit by making reference to them.

\citet{BXC2008} remark that modern statistical computation, such as that used for LME models, greatly improve the efficiency of calculation compared to previous `by-hand' approaches, as advocated in \citet{BA99}, describing them as tedious, unnecessary and outdated. Instead estimates for required LME parameters can be read directly from program output. Furthermore, using computer approaches removes associated constraints, such as the need for the design to be perfectly balanced.

\citet{ARoy2009} formulated a very powerful method of assessing the agreement of two methods of measurement, with replicate measurements, also using LME models. This approach does not directly address the issue of limits of agreement, but does allow for an alternative approach to computing LoAs using LME Models.
%Therefore, for the sake of consistency, a data set will be simulated based on the Blood Data that will allow for extra variables, and an exploration shall be provided in the appendices.
 Furthermore, it can be shown that widely used existing methodologies, such as the limits of agreement, can be incorporated into Roy's methodology.





\addcontentsline{toc}{section}{Bibliography}
\bibliographystyle{chicago}
\bibliography{2017bib}
>>>>>>> a2f6c64bed72d1c25fc27f9237e0bc1750daf02c
\end{document}



