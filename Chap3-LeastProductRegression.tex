\documentclass[Chap3amain.tex]{subfiles}
\begin{document}
%------------------------------------------------------------------------------------%

\subsection{Least Product Regression}

\begin{itemize}
\item Least Product Regression , also known as 'Model II regression'
caters for cases in which random error is attached to both
dependent and independent variables. Ludbrook cites this
methodology as being pertinent to Method comparison studies.

\item 
The sum of the products of the vertical and horizontal deviations
of the x,y values from the line is minimized.

\item 
Least products regression analysis is considered suitable for
calibrating one method against another.Ludbrook comments that it
is also a sensitive technique for detecting and distinguishing
fixed and proportional bias between methods.

\item 
Proposed as an alternative to Bland \& Altman methodology ,this
method is also known as 'Geometric Mean Regression' and 'Reduced
Major Axis Regression'.
\end{itemize}
%%------------------------------------------------------------------------------------%%

\subsubsection{Difference with Least Squares Regression}
Least-products regression can lead to inflated SEEs and estimates
that do not tend to their true values an N approaches infinity
(Draper and Smith, 1998).



\subsection{Ordinary Least Product Regression}
\citet{ludbrook97} states that the grouping structure can be
straightforward, but there are more complex data sets that have a
hierarchical(nested) model.
\\
\\
Observations between groups are independent, but observations
within each groups are dependent because they belong to the same
subpopulation. Therefore there are two sources of variation:
between-group and within-group variance.
 \vspace{5 mm} \noindent Mean correction is a method of reducing
bias.

\end{document}
